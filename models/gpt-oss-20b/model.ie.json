{
  "weights_bin": "model.ie.bin",
  "tensors": [
    {
      "name": "model.layers.0.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 0,
      "nbytes": 5760
    },
    {
      "name": "model.layers.0.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 5760,
      "nbytes": 184320
    },
    {
      "name": "model.layers.0.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 190080,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.0.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 132900480,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.0.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 141194880,
      "nbytes": 368640
    },
    {
      "name": "model.layers.0.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 141563520,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.0.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 406984320,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.0.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 423573120,
      "nbytes": 64
    },
    {
      "name": "model.layers.0.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 423573184,
      "nbytes": 184320
    },
    {
      "name": "model.layers.0.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 423757504,
      "nbytes": 5760
    },
    {
      "name": "model.layers.0.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 423763264,
      "nbytes": 1024
    },
    {
      "name": "model.layers.0.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 423764288,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.0.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 426713408,
      "nbytes": 5760
    },
    {
      "name": "model.layers.0.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 426719168,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.0.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 450312128,
      "nbytes": 8192
    },
    {
      "name": "model.layers.0.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 450320320,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.0.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 473913280,
      "nbytes": 128
    },
    {
      "name": "model.layers.0.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 473913408,
      "nbytes": 1024
    },
    {
      "name": "model.layers.0.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 473914432,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.1.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 476863552,
      "nbytes": 5760
    },
    {
      "name": "model.layers.1.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 476869312,
      "nbytes": 184320
    },
    {
      "name": "model.layers.1.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 477053632,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.1.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 609764032,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.1.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 618058432,
      "nbytes": 368640
    },
    {
      "name": "model.layers.1.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 618427072,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.1.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 883847872,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.1.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 900436672,
      "nbytes": 64
    },
    {
      "name": "model.layers.1.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 900436736,
      "nbytes": 184320
    },
    {
      "name": "model.layers.1.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 900621056,
      "nbytes": 5760
    },
    {
      "name": "model.layers.1.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 900626816,
      "nbytes": 1024
    },
    {
      "name": "model.layers.1.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 900627840,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.1.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 903576960,
      "nbytes": 5760
    },
    {
      "name": "model.layers.1.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 903582720,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.1.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 927175680,
      "nbytes": 8192
    },
    {
      "name": "model.layers.1.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 927183872,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.1.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 950776832,
      "nbytes": 128
    },
    {
      "name": "model.layers.1.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 950776960,
      "nbytes": 1024
    },
    {
      "name": "model.layers.1.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 950777984,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.10.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 953727104,
      "nbytes": 5760
    },
    {
      "name": "model.layers.10.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 953732864,
      "nbytes": 184320
    },
    {
      "name": "model.layers.10.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 953917184,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.10.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 1086627584,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.10.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 1094921984,
      "nbytes": 368640
    },
    {
      "name": "model.layers.10.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 1095290624,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.10.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 1360711424,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.10.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 1377300224,
      "nbytes": 64
    },
    {
      "name": "model.layers.10.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 1377300288,
      "nbytes": 184320
    },
    {
      "name": "model.layers.10.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 1377484608,
      "nbytes": 5760
    },
    {
      "name": "model.layers.10.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 1377490368,
      "nbytes": 1024
    },
    {
      "name": "model.layers.10.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 1377491392,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.10.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 1380440512,
      "nbytes": 5760
    },
    {
      "name": "model.layers.10.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 1380446272,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.10.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 1404039232,
      "nbytes": 8192
    },
    {
      "name": "model.layers.10.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 1404047424,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.10.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 1427640384,
      "nbytes": 128
    },
    {
      "name": "model.layers.10.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 1427640512,
      "nbytes": 1024
    },
    {
      "name": "model.layers.10.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 1427641536,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.11.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 1430590656,
      "nbytes": 5760
    },
    {
      "name": "model.layers.11.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 1430596416,
      "nbytes": 184320
    },
    {
      "name": "model.layers.11.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 1430780736,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.11.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 1563491136,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.11.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 1571785536,
      "nbytes": 368640
    },
    {
      "name": "model.layers.11.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 1572154176,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.11.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 1837574976,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.11.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 1854163776,
      "nbytes": 64
    },
    {
      "name": "model.layers.11.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 1854163840,
      "nbytes": 184320
    },
    {
      "name": "model.layers.11.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 1854348160,
      "nbytes": 5760
    },
    {
      "name": "model.layers.11.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 1854353920,
      "nbytes": 1024
    },
    {
      "name": "model.layers.11.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 1854354944,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.11.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 1857304064,
      "nbytes": 5760
    },
    {
      "name": "model.layers.11.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 1857309824,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.11.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 1880902784,
      "nbytes": 8192
    },
    {
      "name": "model.layers.11.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 1880910976,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.11.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 1904503936,
      "nbytes": 128
    },
    {
      "name": "model.layers.11.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 1904504064,
      "nbytes": 1024
    },
    {
      "name": "model.layers.11.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 1904505088,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.12.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 1907454208,
      "nbytes": 5760
    },
    {
      "name": "model.layers.12.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 1907459968,
      "nbytes": 184320
    },
    {
      "name": "model.layers.12.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 1907644288,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.12.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 2040354688,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.12.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 2048649088,
      "nbytes": 368640
    },
    {
      "name": "model.layers.12.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 2049017728,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.12.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 2314438528,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.12.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 2331027328,
      "nbytes": 64
    },
    {
      "name": "model.layers.12.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 2331027392,
      "nbytes": 184320
    },
    {
      "name": "model.layers.12.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 2331211712,
      "nbytes": 5760
    },
    {
      "name": "model.layers.12.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 2331217472,
      "nbytes": 1024
    },
    {
      "name": "model.layers.12.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 2331218496,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.12.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 2334167616,
      "nbytes": 5760
    },
    {
      "name": "model.layers.12.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 2334173376,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.12.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 2357766336,
      "nbytes": 8192
    },
    {
      "name": "model.layers.12.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 2357774528,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.12.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 2381367488,
      "nbytes": 128
    },
    {
      "name": "model.layers.12.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 2381367616,
      "nbytes": 1024
    },
    {
      "name": "model.layers.12.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 2381368640,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.13.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 2384317760,
      "nbytes": 5760
    },
    {
      "name": "model.layers.13.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 2384323520,
      "nbytes": 184320
    },
    {
      "name": "model.layers.13.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 2384507840,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.13.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 2517218240,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.13.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 2525512640,
      "nbytes": 368640
    },
    {
      "name": "model.layers.13.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 2525881280,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.13.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 2791302080,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.13.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 2807890880,
      "nbytes": 64
    },
    {
      "name": "model.layers.13.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 2807890944,
      "nbytes": 184320
    },
    {
      "name": "model.layers.13.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 2808075264,
      "nbytes": 5760
    },
    {
      "name": "model.layers.13.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 2808081024,
      "nbytes": 1024
    },
    {
      "name": "model.layers.13.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 2808082048,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.13.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 2811031168,
      "nbytes": 5760
    },
    {
      "name": "model.layers.13.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 2811036928,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.13.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 2834629888,
      "nbytes": 8192
    },
    {
      "name": "model.layers.13.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 2834638080,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.13.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 2858231040,
      "nbytes": 128
    },
    {
      "name": "model.layers.13.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 2858231168,
      "nbytes": 1024
    },
    {
      "name": "model.layers.13.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 2858232192,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.14.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 2861181312,
      "nbytes": 5760
    },
    {
      "name": "model.layers.14.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 2861187072,
      "nbytes": 184320
    },
    {
      "name": "model.layers.14.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 2861371392,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.14.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 2994081792,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.14.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 3002376192,
      "nbytes": 368640
    },
    {
      "name": "model.layers.14.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 3002744832,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.14.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 3268165632,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.14.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 3284754432,
      "nbytes": 64
    },
    {
      "name": "model.layers.14.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 3284754496,
      "nbytes": 184320
    },
    {
      "name": "model.layers.14.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 3284938816,
      "nbytes": 5760
    },
    {
      "name": "model.layers.14.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 3284944576,
      "nbytes": 1024
    },
    {
      "name": "model.layers.14.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 3284945600,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.14.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 3287894720,
      "nbytes": 5760
    },
    {
      "name": "model.layers.14.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 3287900480,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.14.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 3311493440,
      "nbytes": 8192
    },
    {
      "name": "model.layers.14.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 3311501632,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.14.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 3335094592,
      "nbytes": 128
    },
    {
      "name": "model.layers.14.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 3335094720,
      "nbytes": 1024
    },
    {
      "name": "model.layers.14.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 3335095744,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.15.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 3338044864,
      "nbytes": 5760
    },
    {
      "name": "model.layers.15.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 3338050624,
      "nbytes": 184320
    },
    {
      "name": "model.layers.15.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 3338234944,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.15.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 3470945344,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.15.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 3479239744,
      "nbytes": 368640
    },
    {
      "name": "model.layers.15.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 3479608384,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.15.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 3745029184,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.15.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 3761617984,
      "nbytes": 64
    },
    {
      "name": "model.layers.15.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 3761618048,
      "nbytes": 184320
    },
    {
      "name": "model.layers.15.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 3761802368,
      "nbytes": 5760
    },
    {
      "name": "model.layers.15.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 3761808128,
      "nbytes": 1024
    },
    {
      "name": "model.layers.15.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 3761809152,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.15.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 3764758272,
      "nbytes": 5760
    },
    {
      "name": "model.layers.15.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 3764764032,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.15.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 3788356992,
      "nbytes": 8192
    },
    {
      "name": "model.layers.15.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 3788365184,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.15.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 3811958144,
      "nbytes": 128
    },
    {
      "name": "model.layers.15.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 3811958272,
      "nbytes": 1024
    },
    {
      "name": "model.layers.15.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 3811959296,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.16.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 3814908416,
      "nbytes": 5760
    },
    {
      "name": "model.layers.16.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 3814914176,
      "nbytes": 184320
    },
    {
      "name": "model.layers.16.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 3815098496,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.16.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 3947808896,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.16.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 3956103296,
      "nbytes": 368640
    },
    {
      "name": "model.layers.16.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 3956471936,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.16.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 4221892736,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.16.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 4238481536,
      "nbytes": 64
    },
    {
      "name": "model.layers.16.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 4238481600,
      "nbytes": 184320
    },
    {
      "name": "model.layers.16.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 4238665920,
      "nbytes": 5760
    },
    {
      "name": "model.layers.16.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 4238671680,
      "nbytes": 1024
    },
    {
      "name": "model.layers.16.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 4238672704,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.16.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 4241621824,
      "nbytes": 5760
    },
    {
      "name": "model.layers.16.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 4241627584,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.16.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 4265220544,
      "nbytes": 8192
    },
    {
      "name": "model.layers.16.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 4265228736,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.16.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 4288821696,
      "nbytes": 128
    },
    {
      "name": "model.layers.16.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 4288821824,
      "nbytes": 1024
    },
    {
      "name": "model.layers.16.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 4288822848,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.17.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 4291771968,
      "nbytes": 5760
    },
    {
      "name": "model.layers.17.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 4291777728,
      "nbytes": 184320
    },
    {
      "name": "model.layers.17.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 4291962048,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.17.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 4424672448,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.17.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 4432966848,
      "nbytes": 368640
    },
    {
      "name": "model.layers.17.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 4433335488,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.17.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 4698756288,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.17.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 4715345088,
      "nbytes": 64
    },
    {
      "name": "model.layers.17.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 4715345152,
      "nbytes": 184320
    },
    {
      "name": "model.layers.17.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 4715529472,
      "nbytes": 5760
    },
    {
      "name": "model.layers.17.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 4715535232,
      "nbytes": 1024
    },
    {
      "name": "model.layers.17.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 4715536256,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.17.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 4718485376,
      "nbytes": 5760
    },
    {
      "name": "model.layers.17.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 4718491136,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.17.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 4742084096,
      "nbytes": 8192
    },
    {
      "name": "model.layers.17.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 4742092288,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.17.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 4765685248,
      "nbytes": 128
    },
    {
      "name": "model.layers.17.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 4765685376,
      "nbytes": 1024
    },
    {
      "name": "model.layers.17.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 4765686400,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.18.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 4768635520,
      "nbytes": 5760
    },
    {
      "name": "model.layers.18.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 4768641280,
      "nbytes": 1024
    },
    {
      "name": "model.layers.18.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 4768642304,
      "nbytes": 5760
    },
    {
      "name": "model.layers.18.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 4768648064,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.18.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 4792241024,
      "nbytes": 8192
    },
    {
      "name": "model.layers.18.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 4792249216,
      "nbytes": 1024
    },
    {
      "name": "model.layers.18.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 4792250240,
      "nbytes": 184320
    },
    {
      "name": "model.layers.18.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 4792434560,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.18.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 4925144960,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.18.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 4933439360,
      "nbytes": 368640
    },
    {
      "name": "model.layers.18.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 4933808000,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.18.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 5199228800,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.18.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 5215817600,
      "nbytes": 64
    },
    {
      "name": "model.layers.18.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 5215817664,
      "nbytes": 184320
    },
    {
      "name": "model.layers.18.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 5216001984,
      "nbytes": 5760
    },
    {
      "name": "model.layers.18.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 5216007744,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.18.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 5218956864,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.18.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 5242549824,
      "nbytes": 128
    },
    {
      "name": "model.layers.18.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 5242549952,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.19.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 5245499072,
      "nbytes": 5760
    },
    {
      "name": "model.layers.19.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 5245504832,
      "nbytes": 184320
    },
    {
      "name": "model.layers.19.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 5245689152,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.19.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 5378399552,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.19.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 5386693952,
      "nbytes": 368640
    },
    {
      "name": "model.layers.19.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 5387062592,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.19.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 5652483392,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.19.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 5669072192,
      "nbytes": 64
    },
    {
      "name": "model.layers.19.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 5669072256,
      "nbytes": 184320
    },
    {
      "name": "model.layers.19.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 5669256576,
      "nbytes": 5760
    },
    {
      "name": "model.layers.19.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 5669262336,
      "nbytes": 1024
    },
    {
      "name": "model.layers.19.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 5669263360,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.19.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 5672212480,
      "nbytes": 5760
    },
    {
      "name": "model.layers.19.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 5672218240,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.19.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 5695811200,
      "nbytes": 8192
    },
    {
      "name": "model.layers.19.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 5695819392,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.19.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 5719412352,
      "nbytes": 128
    },
    {
      "name": "model.layers.19.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 5719412480,
      "nbytes": 1024
    },
    {
      "name": "model.layers.19.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 5719413504,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.2.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 5722362624,
      "nbytes": 5760
    },
    {
      "name": "model.layers.2.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 5722368384,
      "nbytes": 184320
    },
    {
      "name": "model.layers.2.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 5722552704,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.2.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 5855263104,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.2.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 5863557504,
      "nbytes": 368640
    },
    {
      "name": "model.layers.2.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 5863926144,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.2.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 6129346944,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.2.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 6145935744,
      "nbytes": 64
    },
    {
      "name": "model.layers.2.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 6145935808,
      "nbytes": 184320
    },
    {
      "name": "model.layers.2.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 6146120128,
      "nbytes": 5760
    },
    {
      "name": "model.layers.2.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 6146125888,
      "nbytes": 1024
    },
    {
      "name": "model.layers.2.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 6146126912,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.2.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 6149076032,
      "nbytes": 5760
    },
    {
      "name": "model.layers.2.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 6149081792,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.2.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 6172674752,
      "nbytes": 8192
    },
    {
      "name": "model.layers.2.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 6172682944,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.2.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 6196275904,
      "nbytes": 128
    },
    {
      "name": "model.layers.2.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 6196276032,
      "nbytes": 1024
    },
    {
      "name": "model.layers.2.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 6196277056,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.20.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 6199226176,
      "nbytes": 5760
    },
    {
      "name": "model.layers.20.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 6199231936,
      "nbytes": 184320
    },
    {
      "name": "model.layers.20.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 6199416256,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.20.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 6332126656,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.20.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 6340421056,
      "nbytes": 368640
    },
    {
      "name": "model.layers.20.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 6340789696,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.20.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 6606210496,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.20.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 6622799296,
      "nbytes": 64
    },
    {
      "name": "model.layers.20.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 6622799360,
      "nbytes": 184320
    },
    {
      "name": "model.layers.20.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 6622983680,
      "nbytes": 5760
    },
    {
      "name": "model.layers.20.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 6622989440,
      "nbytes": 1024
    },
    {
      "name": "model.layers.20.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 6622990464,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.20.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 6625939584,
      "nbytes": 5760
    },
    {
      "name": "model.layers.20.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 6625945344,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.20.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 6649538304,
      "nbytes": 8192
    },
    {
      "name": "model.layers.20.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 6649546496,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.20.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 6673139456,
      "nbytes": 128
    },
    {
      "name": "model.layers.20.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 6673139584,
      "nbytes": 1024
    },
    {
      "name": "model.layers.20.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 6673140608,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.21.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 6676089728,
      "nbytes": 5760
    },
    {
      "name": "model.layers.21.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 6676095488,
      "nbytes": 184320
    },
    {
      "name": "model.layers.21.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 6676279808,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.21.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 6808990208,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.21.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 6817284608,
      "nbytes": 368640
    },
    {
      "name": "model.layers.21.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 6817653248,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.21.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 7083074048,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.21.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 7099662848,
      "nbytes": 64
    },
    {
      "name": "model.layers.21.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 7099662912,
      "nbytes": 184320
    },
    {
      "name": "model.layers.21.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 7099847232,
      "nbytes": 5760
    },
    {
      "name": "model.layers.21.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 7099852992,
      "nbytes": 1024
    },
    {
      "name": "model.layers.21.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 7099854016,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.21.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 7102803136,
      "nbytes": 5760
    },
    {
      "name": "model.layers.21.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 7102808896,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.21.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 7126401856,
      "nbytes": 8192
    },
    {
      "name": "model.layers.21.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 7126410048,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.21.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 7150003008,
      "nbytes": 128
    },
    {
      "name": "model.layers.21.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 7150003136,
      "nbytes": 1024
    },
    {
      "name": "model.layers.21.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 7150004160,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.22.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 7152953280,
      "nbytes": 5760
    },
    {
      "name": "model.layers.22.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 7152959040,
      "nbytes": 184320
    },
    {
      "name": "model.layers.22.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 7153143360,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.22.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 7285853760,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.22.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 7294148160,
      "nbytes": 368640
    },
    {
      "name": "model.layers.22.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 7294516800,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.22.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 7559937600,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.22.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 7576526400,
      "nbytes": 64
    },
    {
      "name": "model.layers.22.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 7576526464,
      "nbytes": 184320
    },
    {
      "name": "model.layers.22.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 7576710784,
      "nbytes": 5760
    },
    {
      "name": "model.layers.22.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 7576716544,
      "nbytes": 1024
    },
    {
      "name": "model.layers.22.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 7576717568,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.22.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 7579666688,
      "nbytes": 5760
    },
    {
      "name": "model.layers.22.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 7579672448,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.22.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 7603265408,
      "nbytes": 8192
    },
    {
      "name": "model.layers.22.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 7603273600,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.22.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 7626866560,
      "nbytes": 128
    },
    {
      "name": "model.layers.22.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 7626866688,
      "nbytes": 1024
    },
    {
      "name": "model.layers.22.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 7626867712,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.23.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 7629816832,
      "nbytes": 5760
    },
    {
      "name": "model.layers.23.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 7629822592,
      "nbytes": 184320
    },
    {
      "name": "model.layers.23.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 7630006912,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.23.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 7762717312,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.23.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 7771011712,
      "nbytes": 368640
    },
    {
      "name": "model.layers.23.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 7771380352,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.23.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 8036801152,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.23.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 8053389952,
      "nbytes": 64
    },
    {
      "name": "model.layers.23.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 8053390016,
      "nbytes": 184320
    },
    {
      "name": "model.layers.23.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 8053574336,
      "nbytes": 5760
    },
    {
      "name": "model.layers.23.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 8053580096,
      "nbytes": 1024
    },
    {
      "name": "model.layers.23.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 8053581120,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.23.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 8056530240,
      "nbytes": 5760
    },
    {
      "name": "model.layers.23.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 8056536000,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.23.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 8080128960,
      "nbytes": 8192
    },
    {
      "name": "model.layers.23.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 8080137152,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.23.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 8103730112,
      "nbytes": 128
    },
    {
      "name": "model.layers.23.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 8103730240,
      "nbytes": 1024
    },
    {
      "name": "model.layers.23.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 8103731264,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.3.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 8106680384,
      "nbytes": 5760
    },
    {
      "name": "model.layers.3.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 8106686144,
      "nbytes": 184320
    },
    {
      "name": "model.layers.3.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 8106870464,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.3.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 8239580864,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.3.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 8247875264,
      "nbytes": 368640
    },
    {
      "name": "model.layers.3.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 8248243904,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.3.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 8513664704,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.3.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 8530253504,
      "nbytes": 64
    },
    {
      "name": "model.layers.3.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 8530253568,
      "nbytes": 184320
    },
    {
      "name": "model.layers.3.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 8530437888,
      "nbytes": 5760
    },
    {
      "name": "model.layers.3.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 8530443648,
      "nbytes": 1024
    },
    {
      "name": "model.layers.3.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 8530444672,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.3.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 8533393792,
      "nbytes": 5760
    },
    {
      "name": "model.layers.3.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 8533399552,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.3.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 8556992512,
      "nbytes": 8192
    },
    {
      "name": "model.layers.3.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 8557000704,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.3.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 8580593664,
      "nbytes": 128
    },
    {
      "name": "model.layers.3.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 8580593792,
      "nbytes": 1024
    },
    {
      "name": "model.layers.3.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 8580594816,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.4.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 8583543936,
      "nbytes": 5760
    },
    {
      "name": "model.layers.4.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 8583549696,
      "nbytes": 184320
    },
    {
      "name": "model.layers.4.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 8583734016,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.4.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 8716444416,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.4.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 8724738816,
      "nbytes": 368640
    },
    {
      "name": "model.layers.4.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 8725107456,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.4.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 8990528256,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.4.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 9007117056,
      "nbytes": 64
    },
    {
      "name": "model.layers.4.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 9007117120,
      "nbytes": 184320
    },
    {
      "name": "model.layers.4.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 9007301440,
      "nbytes": 5760
    },
    {
      "name": "model.layers.4.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 9007307200,
      "nbytes": 1024
    },
    {
      "name": "model.layers.4.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 9007308224,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.4.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 9010257344,
      "nbytes": 5760
    },
    {
      "name": "model.layers.4.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 9010263104,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.4.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 9033856064,
      "nbytes": 8192
    },
    {
      "name": "model.layers.4.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 9033864256,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.4.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 9057457216,
      "nbytes": 128
    },
    {
      "name": "model.layers.4.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 9057457344,
      "nbytes": 1024
    },
    {
      "name": "model.layers.4.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 9057458368,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.5.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 9060407488,
      "nbytes": 5760
    },
    {
      "name": "model.layers.5.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 9060413248,
      "nbytes": 184320
    },
    {
      "name": "model.layers.5.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 9060597568,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.5.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 9193307968,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.5.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 9201602368,
      "nbytes": 368640
    },
    {
      "name": "model.layers.5.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 9201971008,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.5.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 9467391808,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.5.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 9483980608,
      "nbytes": 64
    },
    {
      "name": "model.layers.5.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 9483980672,
      "nbytes": 184320
    },
    {
      "name": "model.layers.5.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 9484164992,
      "nbytes": 5760
    },
    {
      "name": "model.layers.5.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 9484170752,
      "nbytes": 1024
    },
    {
      "name": "model.layers.5.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 9484171776,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.5.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 9487120896,
      "nbytes": 5760
    },
    {
      "name": "model.layers.5.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 9487126656,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.5.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 9510719616,
      "nbytes": 8192
    },
    {
      "name": "model.layers.5.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 9510727808,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.5.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 9534320768,
      "nbytes": 128
    },
    {
      "name": "model.layers.5.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 9534320896,
      "nbytes": 1024
    },
    {
      "name": "model.layers.5.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 9534321920,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.6.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 9537271040,
      "nbytes": 5760
    },
    {
      "name": "model.layers.6.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 9537276800,
      "nbytes": 368640
    },
    {
      "name": "model.layers.6.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 9537645440,
      "nbytes": 64
    },
    {
      "name": "model.layers.6.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 9537645504,
      "nbytes": 184320
    },
    {
      "name": "model.layers.6.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 9537829824,
      "nbytes": 1024
    },
    {
      "name": "model.layers.6.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 9537830848,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.6.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 9540779968,
      "nbytes": 5760
    },
    {
      "name": "model.layers.6.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 9540785728,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.6.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 9564378688,
      "nbytes": 8192
    },
    {
      "name": "model.layers.6.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 9564386880,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.6.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 9587979840,
      "nbytes": 128
    },
    {
      "name": "model.layers.6.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 9587979968,
      "nbytes": 1024
    },
    {
      "name": "model.layers.6.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 9587980992,
      "nbytes": 2949120
    },
    {
      "name": "lm_head.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        201088,
        2880
      ],
      "offset": 9590930112,
      "nbytes": 1158266880
    },
    {
      "name": "model.embed_tokens.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        201088,
        2880
      ],
      "offset": 10749196992,
      "nbytes": 1158266880
    },
    {
      "name": "model.layers.6.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 11907463872,
      "nbytes": 184320
    },
    {
      "name": "model.layers.6.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 11907648192,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.6.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 12040358592,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.6.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 12048652992,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.6.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 12314073792,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.6.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 12330662592,
      "nbytes": 5760
    },
    {
      "name": "model.layers.7.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 12330668352,
      "nbytes": 5760
    },
    {
      "name": "model.layers.7.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 12330674112,
      "nbytes": 184320
    },
    {
      "name": "model.layers.7.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 12330858432,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.7.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 12463568832,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.7.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 12471863232,
      "nbytes": 368640
    },
    {
      "name": "model.layers.7.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 12472231872,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.7.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 12737652672,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.7.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 12754241472,
      "nbytes": 64
    },
    {
      "name": "model.layers.7.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 12754241536,
      "nbytes": 184320
    },
    {
      "name": "model.layers.7.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 12754425856,
      "nbytes": 5760
    },
    {
      "name": "model.layers.7.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 12754431616,
      "nbytes": 1024
    },
    {
      "name": "model.layers.7.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 12754432640,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.7.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 12757381760,
      "nbytes": 5760
    },
    {
      "name": "model.layers.7.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 12757387520,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.7.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 12780980480,
      "nbytes": 8192
    },
    {
      "name": "model.layers.7.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 12780988672,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.7.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 12804581632,
      "nbytes": 128
    },
    {
      "name": "model.layers.7.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 12804581760,
      "nbytes": 1024
    },
    {
      "name": "model.layers.7.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 12804582784,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.8.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 12807531904,
      "nbytes": 5760
    },
    {
      "name": "model.layers.8.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 12807537664,
      "nbytes": 184320
    },
    {
      "name": "model.layers.8.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 12807721984,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.8.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 12940432384,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.8.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 12948726784,
      "nbytes": 368640
    },
    {
      "name": "model.layers.8.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 12949095424,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.8.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 13214516224,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.8.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 13231105024,
      "nbytes": 64
    },
    {
      "name": "model.layers.8.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 13231105088,
      "nbytes": 184320
    },
    {
      "name": "model.layers.8.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 13231289408,
      "nbytes": 5760
    },
    {
      "name": "model.layers.8.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 13231295168,
      "nbytes": 1024
    },
    {
      "name": "model.layers.8.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 13231296192,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.8.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 13234245312,
      "nbytes": 5760
    },
    {
      "name": "model.layers.8.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 13234251072,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.8.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 13257844032,
      "nbytes": 8192
    },
    {
      "name": "model.layers.8.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 13257852224,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.8.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 13281445184,
      "nbytes": 128
    },
    {
      "name": "model.layers.8.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 13281445312,
      "nbytes": 1024
    },
    {
      "name": "model.layers.8.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 13281446336,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.9.input_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 13284395456,
      "nbytes": 5760
    },
    {
      "name": "model.layers.9.mlp.experts.down_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 13284401216,
      "nbytes": 184320
    },
    {
      "name": "model.layers.9.mlp.experts.down_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "offset": 13284585536,
      "nbytes": 132710400
    },
    {
      "name": "model.layers.9.mlp.experts.down_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        2880,
        90
      ],
      "offset": 13417295936,
      "nbytes": 8294400
    },
    {
      "name": "model.layers.9.mlp.experts.gate_up_proj_bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        5760
      ],
      "offset": 13425590336,
      "nbytes": 368640
    },
    {
      "name": "model.layers.9.mlp.experts.gate_up_proj_blocks",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "offset": 13425958976,
      "nbytes": 265420800
    },
    {
      "name": "model.layers.9.mlp.experts.gate_up_proj_scales",
      "dtype": "torch.uint8",
      "shape": [
        32,
        5760,
        90
      ],
      "offset": 13691379776,
      "nbytes": 16588800
    },
    {
      "name": "model.layers.9.mlp.router.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        32
      ],
      "offset": 13707968576,
      "nbytes": 64
    },
    {
      "name": "model.layers.9.mlp.router.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        32,
        2880
      ],
      "offset": 13707968640,
      "nbytes": 184320
    },
    {
      "name": "model.layers.9.post_attention_layernorm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 13708152960,
      "nbytes": 5760
    },
    {
      "name": "model.layers.9.self_attn.k_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 13708158720,
      "nbytes": 1024
    },
    {
      "name": "model.layers.9.self_attn.k_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 13708159744,
      "nbytes": 2949120
    },
    {
      "name": "model.layers.9.self_attn.o_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 13711108864,
      "nbytes": 5760
    },
    {
      "name": "model.layers.9.self_attn.o_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880,
        4096
      ],
      "offset": 13711114624,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.9.self_attn.q_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        4096
      ],
      "offset": 13734707584,
      "nbytes": 8192
    },
    {
      "name": "model.layers.9.self_attn.q_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        4096,
        2880
      ],
      "offset": 13734715776,
      "nbytes": 23592960
    },
    {
      "name": "model.layers.9.self_attn.sinks",
      "dtype": "torch.bfloat16",
      "shape": [
        64
      ],
      "offset": 13758308736,
      "nbytes": 128
    },
    {
      "name": "model.layers.9.self_attn.v_proj.bias",
      "dtype": "torch.bfloat16",
      "shape": [
        512
      ],
      "offset": 13758308864,
      "nbytes": 1024
    },
    {
      "name": "model.layers.9.self_attn.v_proj.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        512,
        2880
      ],
      "offset": 13758309888,
      "nbytes": 2949120
    },
    {
      "name": "model.norm.weight",
      "dtype": "torch.bfloat16",
      "shape": [
        2880
      ],
      "offset": 13761259008,
      "nbytes": 5760
    }
  ]
}