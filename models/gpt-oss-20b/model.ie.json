{
  "version": 1,
  "dtype": "bf16",
  "weights_bin": "model.ie.bin",
  "format": "iebin_v1_raw_safetensors",
  "hf_dir": "/home/ricardomag/Desktop/Clocher/models/gpt-oss-20b/hf/original",
  "tensors": [
    {
      "name": "model.layers.0.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 0
    },
    {
      "name": "model.layers.0.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 5760
    },
    {
      "name": "model.layers.0.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 190080
    },
    {
      "name": "model.layers.0.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 132900480
    },
    {
      "name": "model.layers.0.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 141194880
    },
    {
      "name": "model.layers.0.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 141563520
    },
    {
      "name": "model.layers.0.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 406984320
    },
    {
      "name": "model.layers.0.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 423573120
    },
    {
      "name": "model.layers.0.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 423573184
    },
    {
      "name": "model.layers.0.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 423757504
    },
    {
      "name": "model.layers.0.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 423763264
    },
    {
      "name": "model.layers.0.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 423764288
    },
    {
      "name": "model.layers.0.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 426713408
    },
    {
      "name": "model.layers.0.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 426719168
    },
    {
      "name": "model.layers.0.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 450312128
    },
    {
      "name": "model.layers.0.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 450320320
    },
    {
      "name": "model.layers.0.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 473913280
    },
    {
      "name": "model.layers.0.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 473913408
    },
    {
      "name": "model.layers.0.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 473914432
    },
    {
      "name": "model.layers.1.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 476863552
    },
    {
      "name": "model.layers.1.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 476869312
    },
    {
      "name": "model.layers.1.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 477053632
    },
    {
      "name": "model.layers.1.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 609764032
    },
    {
      "name": "model.layers.1.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 618058432
    },
    {
      "name": "model.layers.1.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 618427072
    },
    {
      "name": "model.layers.1.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 883847872
    },
    {
      "name": "model.layers.1.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 900436672
    },
    {
      "name": "model.layers.1.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 900436736
    },
    {
      "name": "model.layers.1.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 900621056
    },
    {
      "name": "model.layers.1.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 900626816
    },
    {
      "name": "model.layers.1.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 900627840
    },
    {
      "name": "model.layers.1.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 903576960
    },
    {
      "name": "model.layers.1.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 903582720
    },
    {
      "name": "model.layers.1.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 927175680
    },
    {
      "name": "model.layers.1.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 927183872
    },
    {
      "name": "model.layers.1.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 950776832
    },
    {
      "name": "model.layers.1.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 950776960
    },
    {
      "name": "model.layers.1.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 950777984
    },
    {
      "name": "model.layers.10.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 953727104
    },
    {
      "name": "model.layers.10.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 953732864
    },
    {
      "name": "model.layers.10.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 953917184
    },
    {
      "name": "model.layers.10.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 1086627584
    },
    {
      "name": "model.layers.10.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 1094921984
    },
    {
      "name": "model.layers.10.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 1095290624
    },
    {
      "name": "model.layers.10.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 1360711424
    },
    {
      "name": "model.layers.10.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 1377300224
    },
    {
      "name": "model.layers.10.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 1377300288
    },
    {
      "name": "model.layers.10.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 1377484608
    },
    {
      "name": "model.layers.10.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 1377490368
    },
    {
      "name": "model.layers.10.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 1377491392
    },
    {
      "name": "model.layers.10.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 1380440512
    },
    {
      "name": "model.layers.10.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 1380446272
    },
    {
      "name": "model.layers.10.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 1404039232
    },
    {
      "name": "model.layers.10.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 1404047424
    },
    {
      "name": "model.layers.10.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 1427640384
    },
    {
      "name": "model.layers.10.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 1427640512
    },
    {
      "name": "model.layers.10.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 1427641536
    },
    {
      "name": "model.layers.11.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 1430590656
    },
    {
      "name": "model.layers.11.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 1430596416
    },
    {
      "name": "model.layers.11.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 1430780736
    },
    {
      "name": "model.layers.11.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 1563491136
    },
    {
      "name": "model.layers.11.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 1571785536
    },
    {
      "name": "model.layers.11.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 1572154176
    },
    {
      "name": "model.layers.11.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 1837574976
    },
    {
      "name": "model.layers.11.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 1854163776
    },
    {
      "name": "model.layers.11.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 1854163840
    },
    {
      "name": "model.layers.11.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 1854348160
    },
    {
      "name": "model.layers.11.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 1854353920
    },
    {
      "name": "model.layers.11.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 1854354944
    },
    {
      "name": "model.layers.11.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 1857304064
    },
    {
      "name": "model.layers.11.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 1857309824
    },
    {
      "name": "model.layers.11.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 1880902784
    },
    {
      "name": "model.layers.11.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 1880910976
    },
    {
      "name": "model.layers.11.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 1904503936
    },
    {
      "name": "model.layers.11.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 1904504064
    },
    {
      "name": "model.layers.11.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 1904505088
    },
    {
      "name": "model.layers.12.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 1907454208
    },
    {
      "name": "model.layers.12.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 1907459968
    },
    {
      "name": "model.layers.12.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 1907644288
    },
    {
      "name": "model.layers.12.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 2040354688
    },
    {
      "name": "model.layers.12.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 2048649088
    },
    {
      "name": "model.layers.12.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 2049017728
    },
    {
      "name": "model.layers.12.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 2314438528
    },
    {
      "name": "model.layers.12.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 2331027328
    },
    {
      "name": "model.layers.12.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 2331027392
    },
    {
      "name": "model.layers.12.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 2331211712
    },
    {
      "name": "model.layers.12.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 2331217472
    },
    {
      "name": "model.layers.12.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 2331218496
    },
    {
      "name": "model.layers.12.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 2334167616
    },
    {
      "name": "model.layers.12.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 2334173376
    },
    {
      "name": "model.layers.12.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 2357766336
    },
    {
      "name": "model.layers.12.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 2357774528
    },
    {
      "name": "model.layers.12.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 2381367488
    },
    {
      "name": "model.layers.12.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 2381367616
    },
    {
      "name": "model.layers.12.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 2381368640
    },
    {
      "name": "model.layers.13.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 2384317760
    },
    {
      "name": "model.layers.13.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 2384323520
    },
    {
      "name": "model.layers.13.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 2384507840
    },
    {
      "name": "model.layers.13.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 2517218240
    },
    {
      "name": "model.layers.13.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 2525512640
    },
    {
      "name": "model.layers.13.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 2525881280
    },
    {
      "name": "model.layers.13.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 2791302080
    },
    {
      "name": "model.layers.13.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 2807890880
    },
    {
      "name": "model.layers.13.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 2807890944
    },
    {
      "name": "model.layers.13.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 2808075264
    },
    {
      "name": "model.layers.13.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 2808081024
    },
    {
      "name": "model.layers.13.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 2808082048
    },
    {
      "name": "model.layers.13.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 2811031168
    },
    {
      "name": "model.layers.13.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 2811036928
    },
    {
      "name": "model.layers.13.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 2834629888
    },
    {
      "name": "model.layers.13.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 2834638080
    },
    {
      "name": "model.layers.13.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 2858231040
    },
    {
      "name": "model.layers.13.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 2858231168
    },
    {
      "name": "model.layers.13.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 2858232192
    },
    {
      "name": "model.layers.14.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 2861181312
    },
    {
      "name": "model.layers.14.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 2861187072
    },
    {
      "name": "model.layers.14.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 2861371392
    },
    {
      "name": "model.layers.14.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 2994081792
    },
    {
      "name": "model.layers.14.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 3002376192
    },
    {
      "name": "model.layers.14.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 3002744832
    },
    {
      "name": "model.layers.14.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 3268165632
    },
    {
      "name": "model.layers.14.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 3284754432
    },
    {
      "name": "model.layers.14.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 3284754496
    },
    {
      "name": "model.layers.14.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 3284938816
    },
    {
      "name": "model.layers.14.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 3284944576
    },
    {
      "name": "model.layers.14.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 3284945600
    },
    {
      "name": "model.layers.14.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 3287894720
    },
    {
      "name": "model.layers.14.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 3287900480
    },
    {
      "name": "model.layers.14.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 3311493440
    },
    {
      "name": "model.layers.14.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 3311501632
    },
    {
      "name": "model.layers.14.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 3335094592
    },
    {
      "name": "model.layers.14.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 3335094720
    },
    {
      "name": "model.layers.14.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 3335095744
    },
    {
      "name": "model.layers.15.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 3338044864
    },
    {
      "name": "model.layers.15.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 3338050624
    },
    {
      "name": "model.layers.15.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 3338234944
    },
    {
      "name": "model.layers.15.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 3470945344
    },
    {
      "name": "model.layers.15.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 3479239744
    },
    {
      "name": "model.layers.15.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 3479608384
    },
    {
      "name": "model.layers.15.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 3745029184
    },
    {
      "name": "model.layers.15.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 3761617984
    },
    {
      "name": "model.layers.15.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 3761618048
    },
    {
      "name": "model.layers.15.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 3761802368
    },
    {
      "name": "model.layers.15.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 3761808128
    },
    {
      "name": "model.layers.15.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 3761809152
    },
    {
      "name": "model.layers.15.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 3764758272
    },
    {
      "name": "model.layers.15.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 3764764032
    },
    {
      "name": "model.layers.15.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 3788356992
    },
    {
      "name": "model.layers.15.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 3788365184
    },
    {
      "name": "model.layers.15.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 3811958144
    },
    {
      "name": "model.layers.15.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 3811958272
    },
    {
      "name": "model.layers.15.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 3811959296
    },
    {
      "name": "model.layers.16.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 3814908416
    },
    {
      "name": "model.layers.16.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 3814914176
    },
    {
      "name": "model.layers.16.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 3815098496
    },
    {
      "name": "model.layers.16.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 3947808896
    },
    {
      "name": "model.layers.16.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 3956103296
    },
    {
      "name": "model.layers.16.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 3956471936
    },
    {
      "name": "model.layers.16.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 4221892736
    },
    {
      "name": "model.layers.16.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 4238481536
    },
    {
      "name": "model.layers.16.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 4238481600
    },
    {
      "name": "model.layers.16.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 4238665920
    },
    {
      "name": "model.layers.16.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 4238671680
    },
    {
      "name": "model.layers.16.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 4238672704
    },
    {
      "name": "model.layers.16.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 4241621824
    },
    {
      "name": "model.layers.16.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 4241627584
    },
    {
      "name": "model.layers.16.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 4265220544
    },
    {
      "name": "model.layers.16.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 4265228736
    },
    {
      "name": "model.layers.16.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 4288821696
    },
    {
      "name": "model.layers.16.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 4288821824
    },
    {
      "name": "model.layers.16.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 4288822848
    },
    {
      "name": "model.layers.17.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 4291771968
    },
    {
      "name": "model.layers.17.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 4291777728
    },
    {
      "name": "model.layers.17.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 4291962048
    },
    {
      "name": "model.layers.17.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 4424672448
    },
    {
      "name": "model.layers.17.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 4432966848
    },
    {
      "name": "model.layers.17.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 4433335488
    },
    {
      "name": "model.layers.17.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 4698756288
    },
    {
      "name": "model.layers.17.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 4715345088
    },
    {
      "name": "model.layers.17.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 4715345152
    },
    {
      "name": "model.layers.17.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 4715529472
    },
    {
      "name": "model.layers.17.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 4715535232
    },
    {
      "name": "model.layers.17.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 4715536256
    },
    {
      "name": "model.layers.17.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 4718485376
    },
    {
      "name": "model.layers.17.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 4718491136
    },
    {
      "name": "model.layers.17.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 4742084096
    },
    {
      "name": "model.layers.17.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 4742092288
    },
    {
      "name": "model.layers.17.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 4765685248
    },
    {
      "name": "model.layers.17.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 4765685376
    },
    {
      "name": "model.layers.17.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 4765686400
    },
    {
      "name": "model.layers.18.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 4768635520
    },
    {
      "name": "model.layers.18.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 4768641280
    },
    {
      "name": "model.layers.18.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 4768642304
    },
    {
      "name": "model.layers.18.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 4768648064
    },
    {
      "name": "model.layers.18.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 4792241024
    },
    {
      "name": "model.layers.18.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 4792249216
    },
    {
      "name": "model.layers.18.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 4792250240
    },
    {
      "name": "model.layers.18.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 4792434560
    },
    {
      "name": "model.layers.18.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 4925144960
    },
    {
      "name": "model.layers.18.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 4933439360
    },
    {
      "name": "model.layers.18.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 4933808000
    },
    {
      "name": "model.layers.18.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 5199228800
    },
    {
      "name": "model.layers.18.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 5215817600
    },
    {
      "name": "model.layers.18.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 5215817664
    },
    {
      "name": "model.layers.18.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 5216001984
    },
    {
      "name": "model.layers.18.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 5216007744
    },
    {
      "name": "model.layers.18.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 5218956864
    },
    {
      "name": "model.layers.18.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 5242549824
    },
    {
      "name": "model.layers.18.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 5242549952
    },
    {
      "name": "model.layers.19.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 5245499072
    },
    {
      "name": "model.layers.19.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 5245504832
    },
    {
      "name": "model.layers.19.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 5245689152
    },
    {
      "name": "model.layers.19.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 5378399552
    },
    {
      "name": "model.layers.19.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 5386693952
    },
    {
      "name": "model.layers.19.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 5387062592
    },
    {
      "name": "model.layers.19.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 5652483392
    },
    {
      "name": "model.layers.19.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 5669072192
    },
    {
      "name": "model.layers.19.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 5669072256
    },
    {
      "name": "model.layers.19.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 5669256576
    },
    {
      "name": "model.layers.19.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 5669262336
    },
    {
      "name": "model.layers.19.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 5669263360
    },
    {
      "name": "model.layers.19.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 5672212480
    },
    {
      "name": "model.layers.19.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 5672218240
    },
    {
      "name": "model.layers.19.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 5695811200
    },
    {
      "name": "model.layers.19.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 5695819392
    },
    {
      "name": "model.layers.19.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 5719412352
    },
    {
      "name": "model.layers.19.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 5719412480
    },
    {
      "name": "model.layers.19.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 5719413504
    },
    {
      "name": "model.layers.2.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 5722362624
    },
    {
      "name": "model.layers.2.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 5722368384
    },
    {
      "name": "model.layers.2.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 5722552704
    },
    {
      "name": "model.layers.2.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 5855263104
    },
    {
      "name": "model.layers.2.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 5863557504
    },
    {
      "name": "model.layers.2.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 5863926144
    },
    {
      "name": "model.layers.2.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 6129346944
    },
    {
      "name": "model.layers.2.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 6145935744
    },
    {
      "name": "model.layers.2.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 6145935808
    },
    {
      "name": "model.layers.2.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 6146120128
    },
    {
      "name": "model.layers.2.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 6146125888
    },
    {
      "name": "model.layers.2.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 6146126912
    },
    {
      "name": "model.layers.2.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 6149076032
    },
    {
      "name": "model.layers.2.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 6149081792
    },
    {
      "name": "model.layers.2.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 6172674752
    },
    {
      "name": "model.layers.2.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 6172682944
    },
    {
      "name": "model.layers.2.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 6196275904
    },
    {
      "name": "model.layers.2.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 6196276032
    },
    {
      "name": "model.layers.2.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 6196277056
    },
    {
      "name": "model.layers.20.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 6199226176
    },
    {
      "name": "model.layers.20.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 6199231936
    },
    {
      "name": "model.layers.20.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 6199416256
    },
    {
      "name": "model.layers.20.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 6332126656
    },
    {
      "name": "model.layers.20.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 6340421056
    },
    {
      "name": "model.layers.20.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 6340789696
    },
    {
      "name": "model.layers.20.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 6606210496
    },
    {
      "name": "model.layers.20.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 6622799296
    },
    {
      "name": "model.layers.20.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 6622799360
    },
    {
      "name": "model.layers.20.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 6622983680
    },
    {
      "name": "model.layers.20.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 6622989440
    },
    {
      "name": "model.layers.20.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 6622990464
    },
    {
      "name": "model.layers.20.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 6625939584
    },
    {
      "name": "model.layers.20.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 6625945344
    },
    {
      "name": "model.layers.20.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 6649538304
    },
    {
      "name": "model.layers.20.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 6649546496
    },
    {
      "name": "model.layers.20.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 6673139456
    },
    {
      "name": "model.layers.20.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 6673139584
    },
    {
      "name": "model.layers.20.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 6673140608
    },
    {
      "name": "model.layers.21.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 6676089728
    },
    {
      "name": "model.layers.21.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 6676095488
    },
    {
      "name": "model.layers.21.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 6676279808
    },
    {
      "name": "model.layers.21.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 6808990208
    },
    {
      "name": "model.layers.21.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 6817284608
    },
    {
      "name": "model.layers.21.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 6817653248
    },
    {
      "name": "model.layers.21.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 7083074048
    },
    {
      "name": "model.layers.21.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 7099662848
    },
    {
      "name": "model.layers.21.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 7099662912
    },
    {
      "name": "model.layers.21.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 7099847232
    },
    {
      "name": "model.layers.21.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 7099852992
    },
    {
      "name": "model.layers.21.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 7099854016
    },
    {
      "name": "model.layers.21.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 7102803136
    },
    {
      "name": "model.layers.21.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 7102808896
    },
    {
      "name": "model.layers.21.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 7126401856
    },
    {
      "name": "model.layers.21.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 7126410048
    },
    {
      "name": "model.layers.21.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 7150003008
    },
    {
      "name": "model.layers.21.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 7150003136
    },
    {
      "name": "model.layers.21.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 7150004160
    },
    {
      "name": "model.layers.22.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 7152953280
    },
    {
      "name": "model.layers.22.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 7152959040
    },
    {
      "name": "model.layers.22.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 7153143360
    },
    {
      "name": "model.layers.22.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 7285853760
    },
    {
      "name": "model.layers.22.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 7294148160
    },
    {
      "name": "model.layers.22.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 7294516800
    },
    {
      "name": "model.layers.22.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 7559937600
    },
    {
      "name": "model.layers.22.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 7576526400
    },
    {
      "name": "model.layers.22.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 7576526464
    },
    {
      "name": "model.layers.22.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 7576710784
    },
    {
      "name": "model.layers.22.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 7576716544
    },
    {
      "name": "model.layers.22.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 7576717568
    },
    {
      "name": "model.layers.22.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 7579666688
    },
    {
      "name": "model.layers.22.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 7579672448
    },
    {
      "name": "model.layers.22.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 7603265408
    },
    {
      "name": "model.layers.22.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 7603273600
    },
    {
      "name": "model.layers.22.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 7626866560
    },
    {
      "name": "model.layers.22.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 7626866688
    },
    {
      "name": "model.layers.22.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 7626867712
    },
    {
      "name": "model.layers.23.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 7629816832
    },
    {
      "name": "model.layers.23.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 7629822592
    },
    {
      "name": "model.layers.23.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 7630006912
    },
    {
      "name": "model.layers.23.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 7762717312
    },
    {
      "name": "model.layers.23.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 7771011712
    },
    {
      "name": "model.layers.23.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 7771380352
    },
    {
      "name": "model.layers.23.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 8036801152
    },
    {
      "name": "model.layers.23.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 8053389952
    },
    {
      "name": "model.layers.23.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 8053390016
    },
    {
      "name": "model.layers.23.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 8053574336
    },
    {
      "name": "model.layers.23.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 8053580096
    },
    {
      "name": "model.layers.23.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 8053581120
    },
    {
      "name": "model.layers.23.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 8056530240
    },
    {
      "name": "model.layers.23.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 8056536000
    },
    {
      "name": "model.layers.23.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 8080128960
    },
    {
      "name": "model.layers.23.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 8080137152
    },
    {
      "name": "model.layers.23.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 8103730112
    },
    {
      "name": "model.layers.23.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 8103730240
    },
    {
      "name": "model.layers.23.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 8103731264
    },
    {
      "name": "model.layers.3.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 8106680384
    },
    {
      "name": "model.layers.3.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 8106686144
    },
    {
      "name": "model.layers.3.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 8106870464
    },
    {
      "name": "model.layers.3.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 8239580864
    },
    {
      "name": "model.layers.3.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 8247875264
    },
    {
      "name": "model.layers.3.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 8248243904
    },
    {
      "name": "model.layers.3.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 8513664704
    },
    {
      "name": "model.layers.3.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 8530253504
    },
    {
      "name": "model.layers.3.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 8530253568
    },
    {
      "name": "model.layers.3.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 8530437888
    },
    {
      "name": "model.layers.3.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 8530443648
    },
    {
      "name": "model.layers.3.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 8530444672
    },
    {
      "name": "model.layers.3.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 8533393792
    },
    {
      "name": "model.layers.3.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 8533399552
    },
    {
      "name": "model.layers.3.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 8556992512
    },
    {
      "name": "model.layers.3.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 8557000704
    },
    {
      "name": "model.layers.3.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 8580593664
    },
    {
      "name": "model.layers.3.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 8580593792
    },
    {
      "name": "model.layers.3.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 8580594816
    },
    {
      "name": "model.layers.4.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 8583543936
    },
    {
      "name": "model.layers.4.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 8583549696
    },
    {
      "name": "model.layers.4.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 8583734016
    },
    {
      "name": "model.layers.4.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 8716444416
    },
    {
      "name": "model.layers.4.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 8724738816
    },
    {
      "name": "model.layers.4.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 8725107456
    },
    {
      "name": "model.layers.4.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 8990528256
    },
    {
      "name": "model.layers.4.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 9007117056
    },
    {
      "name": "model.layers.4.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 9007117120
    },
    {
      "name": "model.layers.4.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 9007301440
    },
    {
      "name": "model.layers.4.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 9007307200
    },
    {
      "name": "model.layers.4.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 9007308224
    },
    {
      "name": "model.layers.4.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 9010257344
    },
    {
      "name": "model.layers.4.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 9010263104
    },
    {
      "name": "model.layers.4.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 9033856064
    },
    {
      "name": "model.layers.4.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 9033864256
    },
    {
      "name": "model.layers.4.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 9057457216
    },
    {
      "name": "model.layers.4.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 9057457344
    },
    {
      "name": "model.layers.4.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 9057458368
    },
    {
      "name": "model.layers.5.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 9060407488
    },
    {
      "name": "model.layers.5.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 9060413248
    },
    {
      "name": "model.layers.5.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 9060597568
    },
    {
      "name": "model.layers.5.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 9193307968
    },
    {
      "name": "model.layers.5.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 9201602368
    },
    {
      "name": "model.layers.5.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 9201971008
    },
    {
      "name": "model.layers.5.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 9467391808
    },
    {
      "name": "model.layers.5.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 9483980608
    },
    {
      "name": "model.layers.5.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 9483980672
    },
    {
      "name": "model.layers.5.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 9484164992
    },
    {
      "name": "model.layers.5.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 9484170752
    },
    {
      "name": "model.layers.5.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 9484171776
    },
    {
      "name": "model.layers.5.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 9487120896
    },
    {
      "name": "model.layers.5.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 9487126656
    },
    {
      "name": "model.layers.5.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 9510719616
    },
    {
      "name": "model.layers.5.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 9510727808
    },
    {
      "name": "model.layers.5.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 9534320768
    },
    {
      "name": "model.layers.5.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 9534320896
    },
    {
      "name": "model.layers.5.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 9534321920
    },
    {
      "name": "model.layers.6.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 9537271040
    },
    {
      "name": "model.layers.6.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 9537276800
    },
    {
      "name": "model.layers.6.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 9537645440
    },
    {
      "name": "model.layers.6.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 9537645504
    },
    {
      "name": "model.layers.6.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 9537829824
    },
    {
      "name": "model.layers.6.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 9537830848
    },
    {
      "name": "model.layers.6.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 9540779968
    },
    {
      "name": "model.layers.6.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 9540785728
    },
    {
      "name": "model.layers.6.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 9564378688
    },
    {
      "name": "model.layers.6.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 9564386880
    },
    {
      "name": "model.layers.6.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 9587979840
    },
    {
      "name": "model.layers.6.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 9587979968
    },
    {
      "name": "model.layers.6.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 9587980992
    },
    {
      "name": "lm_head.weight",
      "dtype": "BF16",
      "shape": [
        201088,
        2880
      ],
      "nbytes": 1158266880,
      "offset": 9590930112
    },
    {
      "name": "model.embed_tokens.weight",
      "dtype": "BF16",
      "shape": [
        201088,
        2880
      ],
      "nbytes": 1158266880,
      "offset": 10749196992
    },
    {
      "name": "model.layers.6.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 11907463872
    },
    {
      "name": "model.layers.6.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 11907648192
    },
    {
      "name": "model.layers.6.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 12040358592
    },
    {
      "name": "model.layers.6.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 12048652992
    },
    {
      "name": "model.layers.6.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 12314073792
    },
    {
      "name": "model.layers.6.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 12330662592
    },
    {
      "name": "model.layers.7.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 12330668352
    },
    {
      "name": "model.layers.7.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 12330674112
    },
    {
      "name": "model.layers.7.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 12330858432
    },
    {
      "name": "model.layers.7.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 12463568832
    },
    {
      "name": "model.layers.7.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 12471863232
    },
    {
      "name": "model.layers.7.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 12472231872
    },
    {
      "name": "model.layers.7.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 12737652672
    },
    {
      "name": "model.layers.7.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 12754241472
    },
    {
      "name": "model.layers.7.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 12754241536
    },
    {
      "name": "model.layers.7.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 12754425856
    },
    {
      "name": "model.layers.7.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 12754431616
    },
    {
      "name": "model.layers.7.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 12754432640
    },
    {
      "name": "model.layers.7.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 12757381760
    },
    {
      "name": "model.layers.7.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 12757387520
    },
    {
      "name": "model.layers.7.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 12780980480
    },
    {
      "name": "model.layers.7.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 12780988672
    },
    {
      "name": "model.layers.7.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 12804581632
    },
    {
      "name": "model.layers.7.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 12804581760
    },
    {
      "name": "model.layers.7.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 12804582784
    },
    {
      "name": "model.layers.8.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 12807531904
    },
    {
      "name": "model.layers.8.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 12807537664
    },
    {
      "name": "model.layers.8.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 12807721984
    },
    {
      "name": "model.layers.8.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 12940432384
    },
    {
      "name": "model.layers.8.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 12948726784
    },
    {
      "name": "model.layers.8.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 12949095424
    },
    {
      "name": "model.layers.8.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 13214516224
    },
    {
      "name": "model.layers.8.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 13231105024
    },
    {
      "name": "model.layers.8.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 13231105088
    },
    {
      "name": "model.layers.8.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 13231289408
    },
    {
      "name": "model.layers.8.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 13231295168
    },
    {
      "name": "model.layers.8.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 13231296192
    },
    {
      "name": "model.layers.8.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 13234245312
    },
    {
      "name": "model.layers.8.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 13234251072
    },
    {
      "name": "model.layers.8.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 13257844032
    },
    {
      "name": "model.layers.8.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 13257852224
    },
    {
      "name": "model.layers.8.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 13281445184
    },
    {
      "name": "model.layers.8.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 13281445312
    },
    {
      "name": "model.layers.8.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 13281446336
    },
    {
      "name": "model.layers.9.input_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 13284395456
    },
    {
      "name": "model.layers.9.mlp.experts.down_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 13284401216
    },
    {
      "name": "model.layers.9.mlp.experts.down_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90,
        16
      ],
      "nbytes": 132710400,
      "offset": 13284585536
    },
    {
      "name": "model.layers.9.mlp.experts.down_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        2880,
        90
      ],
      "nbytes": 8294400,
      "offset": 13417295936
    },
    {
      "name": "model.layers.9.mlp.experts.gate_up_proj_bias",
      "dtype": "BF16",
      "shape": [
        32,
        5760
      ],
      "nbytes": 368640,
      "offset": 13425590336
    },
    {
      "name": "model.layers.9.mlp.experts.gate_up_proj_blocks",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90,
        16
      ],
      "nbytes": 265420800,
      "offset": 13425958976
    },
    {
      "name": "model.layers.9.mlp.experts.gate_up_proj_scales",
      "dtype": "U8",
      "shape": [
        32,
        5760,
        90
      ],
      "nbytes": 16588800,
      "offset": 13691379776
    },
    {
      "name": "model.layers.9.mlp.router.bias",
      "dtype": "BF16",
      "shape": [
        32
      ],
      "nbytes": 64,
      "offset": 13707968576
    },
    {
      "name": "model.layers.9.mlp.router.weight",
      "dtype": "BF16",
      "shape": [
        32,
        2880
      ],
      "nbytes": 184320,
      "offset": 13707968640
    },
    {
      "name": "model.layers.9.post_attention_layernorm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 13708152960
    },
    {
      "name": "model.layers.9.self_attn.k_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 13708158720
    },
    {
      "name": "model.layers.9.self_attn.k_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 13708159744
    },
    {
      "name": "model.layers.9.self_attn.o_proj.bias",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 13711108864
    },
    {
      "name": "model.layers.9.self_attn.o_proj.weight",
      "dtype": "BF16",
      "shape": [
        2880,
        4096
      ],
      "nbytes": 23592960,
      "offset": 13711114624
    },
    {
      "name": "model.layers.9.self_attn.q_proj.bias",
      "dtype": "BF16",
      "shape": [
        4096
      ],
      "nbytes": 8192,
      "offset": 13734707584
    },
    {
      "name": "model.layers.9.self_attn.q_proj.weight",
      "dtype": "BF16",
      "shape": [
        4096,
        2880
      ],
      "nbytes": 23592960,
      "offset": 13734715776
    },
    {
      "name": "model.layers.9.self_attn.sinks",
      "dtype": "BF16",
      "shape": [
        64
      ],
      "nbytes": 128,
      "offset": 13758308736
    },
    {
      "name": "model.layers.9.self_attn.v_proj.bias",
      "dtype": "BF16",
      "shape": [
        512
      ],
      "nbytes": 1024,
      "offset": 13758308864
    },
    {
      "name": "model.layers.9.self_attn.v_proj.weight",
      "dtype": "BF16",
      "shape": [
        512,
        2880
      ],
      "nbytes": 2949120,
      "offset": 13758309888
    },
    {
      "name": "model.norm.weight",
      "dtype": "BF16",
      "shape": [
        2880
      ],
      "nbytes": 5760,
      "offset": 13761259008
    }
  ]
}