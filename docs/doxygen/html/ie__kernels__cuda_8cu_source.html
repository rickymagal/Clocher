<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Inference Engine (Clocher): engine/src/kernels/ie_kernels_cuda.cu Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Inference Engine (Clocher)<span id="projectnumber">&#160;0.2</span>
   </div>
   <div id="projectbrief">C11 CPU/GPU inference baseline with strict metrics &amp; harness</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('ie__kernels__cuda_8cu_source.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">ie_kernels_cuda.cu</div></div>
</div><!--header-->
<div class="contents">
<a href="ie__kernels__cuda_8cu.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">// File: engine/src/kernels/ie_kernels_cuda.cu</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">// -----------------------------------------------------------------------------</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span> </div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="preprocessor">#include &lt;cuda_runtime.h&gt;</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="preprocessor">#include &lt;math_constants.h&gt;</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="preprocessor">#include &lt;stddef.h&gt;</span></div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="preprocessor">#include &lt;stdint.h&gt;</span></div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span> </div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">   28</a></span><span class="preprocessor">#define IE_CUDA_OK 0</span></div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span> </div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="comment">/* Expose the same stream type name as in the public header. */</span></div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#ad253e9c439228a67be0e55b0f4c81edf">   31</a></span><span class="preprocessor">#define IE_CUDA_STREAM_T_DEFINED</span></div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#aa036ed43d83d669bfc8c15c81a7efe73">   32</a></span><span class="keyword">typedef</span> cudaStream_t <a class="code hl_typedef" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a>;</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span> </div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span><span class="preprocessor">#include &quot;<a class="code" href="ie__kernels__cuda_8h.html">ie_kernels_cuda.h</a>&quot;</span></div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span><span class="preprocessor">#include &quot;<a class="code" href="ie__quant__act_8h.html">ie_quant_act.h</a>&quot;</span> <span class="comment">/* for ie_fp8_format, ie_act_kind_t */</span></div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span> </div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">   37</a></span><span class="keyword">static</span> __thread <span class="keywordtype">char</span> <a class="code hl_variable" href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a>[256] = {0};</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span></div>
<div class="foldopen" id="foldopen00043" data-start="{" data-end="}">
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">   43</a></span><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="keyword">const</span> <span class="keywordtype">char</span> *msg) {</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>  <span class="keywordflow">if</span> (!msg) {</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>    <a class="code hl_variable" href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a>[0] = <span class="charliteral">&#39;\0&#39;</span>;</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>  }</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>  <span class="keywordtype">size_t</span> i = 0;</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>  <span class="keywordflow">for</span> (; i + 1 &lt; <span class="keyword">sizeof</span>(<a class="code hl_variable" href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a>) &amp;&amp; msg[i]; ++i) <a class="code hl_variable" href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a>[i] = msg[i];</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>  <a class="code hl_variable" href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a>[i] = <span class="charliteral">&#39;\0&#39;</span>;</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>}</div>
</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span></div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno"><a class="line" href="group__IE__GPU.html#ga6656c0ddd9df382048e7cd162e0c1d64">   57</a></span><span class="keyword">const</span> <span class="keywordtype">char</span> *<a class="code hl_function" href="group__IE__GPU.html#ga6656c0ddd9df382048e7cd162e0c1d64">ie_cuda_last_error_string</a>(<span class="keywordtype">void</span>) { <span class="keywordflow">return</span> <a class="code hl_variable" href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a>; }</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span></div>
<div class="foldopen" id="foldopen00066" data-start="" data-end="">
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">   66</a></span><span class="preprocessor">#define CUDA_GUARD(call)                                                     \</span></div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span><span class="preprocessor">  do {                                                                       \</span></div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span><span class="preprocessor">    cudaError_t _st = (call);                                                \</span></div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span><span class="preprocessor">    if (_st != cudaSuccess) {                                                \</span></div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span><span class="preprocessor">      ie_cuda_set_err(cudaGetErrorString(_st));                              \</span></div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span><span class="preprocessor">      return -(int)_st;                                                      \</span></div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span><span class="preprocessor">    }                                                                        \</span></div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span><span class="preprocessor">  } while (0)</span></div>
</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span> </div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span><span class="comment">/* ========================================================================== */</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span><span class="comment">/*                               Device helpers                               */</span></div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span><span class="comment">/* ========================================================================== */</span></div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span></div>
<div class="foldopen" id="foldopen00085" data-start="{" data-end="}">
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#a603115e5bb835d21609518d0af053e8d">   85</a></span>__device__ <span class="keyword">inline</span> <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a603115e5bb835d21609518d0af053e8d">ie_apply_activation</a>(<span class="keywordtype">float</span> x, <a class="code hl_typedef" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a> act) {</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>  <span class="keywordflow">if</span> (act == <a class="code hl_enumvalue" href="group__IE__GPU.html#ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f">IE_ACT_RELU</a>) {</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>    <span class="keywordflow">return</span> x &gt; 0.f ? x : 0.f;</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>  } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (act == <a class="code hl_enumvalue" href="group__IE__GPU.html#ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08">IE_ACT_TANH</a>) {</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>    <span class="keywordflow">return</span> tanhf(x);</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>  }</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>  <span class="keywordflow">return</span> x; <span class="comment">/* IE_ACT_NONE */</span></div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>}</div>
</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span> </div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span><span class="comment">/* ---- FP8 decoders (device) ---- */</span></div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span></div>
<div class="foldopen" id="foldopen00101" data-start="{" data-end="}">
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#a8d15fdbcd086d7ef5932207fa5b5d91b">  101</a></span>__device__ <span class="keyword">inline</span> <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a8d15fdbcd086d7ef5932207fa5b5d91b">ie_decode_fp8_e4m3_u8</a>(uint8_t v) {</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>  <span class="keywordflow">if</span> (v == 0u) <span class="keywordflow">return</span> 0.0f;</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>  <span class="keyword">const</span> uint8_t sign = (v &gt;&gt; 7) &amp; 0x1;</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>  <span class="keyword">const</span> uint8_t exp = (v &gt;&gt; 3) &amp; 0xF;</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>  <span class="keyword">const</span> uint8_t man = (v &amp; 0x7);</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>  <span class="keywordflow">if</span> (exp == 0) <span class="keywordflow">return</span> sign ? -0.0f : 0.0f;</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> bias = 7;</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> e = (int)exp - bias;</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> frac = (float)man / 8.0f;</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> val = (1.0f + frac) * __int2float_rn(1 &lt;&lt; e);</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>  <span class="keywordflow">return</span> sign ? -val : val;</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>}</div>
</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span></div>
<div class="foldopen" id="foldopen00119" data-start="{" data-end="}">
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#a98464ed99207f2ed392f751bae2ea10e">  119</a></span>__device__ <span class="keyword">inline</span> <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a98464ed99207f2ed392f751bae2ea10e">ie_decode_fp8_e5m2_u8</a>(uint8_t v) {</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>  <span class="keyword">const</span> uint8_t sign = (v &gt;&gt; 7) &amp; 0x1;</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>  <span class="keyword">const</span> uint8_t exp = (v &gt;&gt; 2) &amp; 0x1F;</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>  <span class="keyword">const</span> uint8_t man = (v &amp; 0x3);</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>  <span class="keywordflow">if</span> (exp == 0) <span class="keywordflow">return</span> sign ? -0.0f : 0.0f;</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>  <span class="keywordflow">if</span> (exp == 0x1F) {</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>    <span class="keywordflow">if</span> (man == 0) <span class="keywordflow">return</span> sign ? -CUDART_INF_F : CUDART_INF_F;</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>    <span class="keywordflow">return</span> CUDART_NAN_F;</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>  }</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> bias = 15;</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> e = (int)exp - bias;</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> frac = (float)man / 4.0f;</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> val = (1.0f + frac) * __int2float_rn(1 &lt;&lt; e);</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>  <span class="keywordflow">return</span> sign ? -val : val;</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>}</div>
</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span> </div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span><span class="comment">/* ========================================================================== */</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span><span class="comment">/*                                  Kernels                                   */</span></div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span><span class="comment">/* ========================================================================== */</span></div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span></div>
<div class="foldopen" id="foldopen00154" data-start="{" data-end="}">
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">  154</a></span>__global__ <span class="keywordtype">void</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k_gemv_rowwise_f32</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ W,</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>                                   <span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ x,</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>                                   <span class="keywordtype">float</span> *__restrict__ y, <span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols,</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>                                   <span class="keywordtype">int</span> ldW, <span class="keywordtype">float</span> alpha, <span class="keywordtype">float</span> beta) {</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>  <span class="keywordtype">int</span> r = blockIdx.x;</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>  <span class="keywordflow">if</span> (r &gt;= rows) <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span> </div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>  <span class="keywordtype">float</span> acc = 0.f;</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = threadIdx.x; k &lt; cols; k += blockDim.x) {</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>    acc += W[(size_t)r * (<span class="keywordtype">size_t</span>)ldW + (size_t)k] * x[k];</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>  }</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span> </div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>  __shared__ <span class="keywordtype">float</span> buf[256];</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>  buf[threadIdx.x] = acc;</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>  __syncthreads();</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span> </div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> s = blockDim.x &gt;&gt; 1; s &gt; 0; s &gt;&gt;= 1) {</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>    <span class="keywordflow">if</span> (threadIdx.x &lt; s) buf[threadIdx.x] += buf[threadIdx.x + s];</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>    __syncthreads();</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>  }</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span> </div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>  <span class="keywordflow">if</span> (threadIdx.x == 0) {</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>    <span class="keywordtype">float</span> out = alpha * buf[0];</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>    <span class="keywordflow">if</span> (beta != 0.f) out += beta * y[r];</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>    y[r] = out;</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>  }</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>}</div>
</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span></div>
<div class="foldopen" id="foldopen00188" data-start="{" data-end="}">
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#ab9150fe6fc7da507974bfdd38b262ce2">  188</a></span>__global__ <span class="keywordtype">void</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#ab9150fe6fc7da507974bfdd38b262ce2">k_gemv_bias_act_f32</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ W,</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>                                    <span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ x,</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>                                    <span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ bias,</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>                                    <span class="keywordtype">float</span> *__restrict__ y, <span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols,</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>                                    <span class="keywordtype">int</span> ldW, <span class="keywordtype">float</span> alpha, <span class="keywordtype">float</span> beta,</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>                                    <a class="code hl_typedef" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a> act) {</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>  <span class="keywordtype">int</span> r = blockIdx.x;</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>  <span class="keywordflow">if</span> (r &gt;= rows) <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span> </div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>  <span class="keywordtype">float</span> acc = 0.f;</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = threadIdx.x; k &lt; cols; k += blockDim.x) {</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>    acc += W[(size_t)r * (<span class="keywordtype">size_t</span>)ldW + (size_t)k] * x[k];</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>  }</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span> </div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>  __shared__ <span class="keywordtype">float</span> buf[256];</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>  buf[threadIdx.x] = acc;</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>  __syncthreads();</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span> </div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> s = blockDim.x &gt;&gt; 1; s &gt; 0; s &gt;&gt;= 1) {</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>    <span class="keywordflow">if</span> (threadIdx.x &lt; s) buf[threadIdx.x] += buf[threadIdx.x + s];</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>    __syncthreads();</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>  }</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span> </div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>  <span class="keywordflow">if</span> (threadIdx.x == 0) {</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>    <span class="keywordtype">float</span> b = bias ? bias[r] : 0.f;</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>    <span class="keywordtype">float</span> out = alpha * buf[0] + b;</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>    <span class="keywordflow">if</span> (beta != 0.f) out += beta * y[r];</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>    y[r] = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a603115e5bb835d21609518d0af053e8d">ie_apply_activation</a>(out, act);</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>  }</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>}</div>
</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span></div>
<div class="foldopen" id="foldopen00235" data-start="{" data-end="}">
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#abb0d57e76ef0b1dea1ae1b8bb55e1c02">  235</a></span>__global__ <span class="keywordtype">void</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#abb0d57e76ef0b1dea1ae1b8bb55e1c02">k_gemv_rowwise_qi8_f32</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ W,</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>                                       <span class="keyword">const</span> int8_t *__restrict__ xq,</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>                                       <span class="keywordtype">float</span> *__restrict__ y, <span class="keywordtype">int</span> rows,</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>                                       <span class="keywordtype">int</span> cols, <span class="keywordtype">int</span> ldW, <span class="keywordtype">float</span> scale, <span class="keywordtype">int</span> zp,</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>                                       <span class="keywordtype">float</span> alpha, <span class="keywordtype">float</span> beta) {</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>  <span class="keywordtype">int</span> r = blockIdx.x;</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>  <span class="keywordflow">if</span> (r &gt;= rows) <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span> </div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>  <span class="keywordtype">float</span> acc = 0.f;</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = threadIdx.x; k &lt; cols; k += blockDim.x) {</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> xv = scale * ((int)xq[k] - zp);</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>    acc += W[(size_t)r * (<span class="keywordtype">size_t</span>)ldW + (size_t)k] * xv;</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>  }</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span> </div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>  __shared__ <span class="keywordtype">float</span> buf[256];</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>  buf[threadIdx.x] = acc;</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>  __syncthreads();</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span> </div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> s = blockDim.x &gt;&gt; 1; s &gt; 0; s &gt;&gt;= 1) {</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>    <span class="keywordflow">if</span> (threadIdx.x &lt; s) buf[threadIdx.x] += buf[threadIdx.x + s];</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>    __syncthreads();</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>  }</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span> </div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>  <span class="keywordflow">if</span> (threadIdx.x == 0) {</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>    <span class="keywordtype">float</span> out = alpha * buf[0];</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>    <span class="keywordflow">if</span> (beta != 0.f) out += beta * y[r];</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>    y[r] = out;</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>  }</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>}</div>
</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span></div>
<div class="foldopen" id="foldopen00278" data-start="{" data-end="}">
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#a74040aacee610aa771ee11bb0bc74022">  278</a></span>__global__ <span class="keywordtype">void</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a74040aacee610aa771ee11bb0bc74022">k_gemv_rowwise_qfp8_f32</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ W,</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>                                        <span class="keyword">const</span> uint8_t *__restrict__ x8,</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>                                        <span class="keywordtype">float</span> *__restrict__ y, <span class="keywordtype">int</span> rows,</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>                                        <span class="keywordtype">int</span> cols, <span class="keywordtype">int</span> ldW, <a class="code hl_enumeration" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52c">ie_fp8_format</a> fmt,</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>                                        <span class="keywordtype">float</span> alpha, <span class="keywordtype">float</span> beta) {</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>  <span class="keywordtype">int</span> r = blockIdx.x;</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>  <span class="keywordflow">if</span> (r &gt;= rows) <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span> </div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> e4m3 = (fmt == <a class="code hl_enumvalue" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52ca67cfe56fcb473bed9a2f92388f2fc347">IE_FP8_E4M3</a>);</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span> </div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>  <span class="keywordtype">float</span> acc = 0.f;</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = threadIdx.x; k &lt; cols; k += blockDim.x) {</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>    <span class="keyword">const</span> uint8_t b = x8[k];</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> xv =</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>        e4m3 ? <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a8d15fdbcd086d7ef5932207fa5b5d91b">ie_decode_fp8_e4m3_u8</a>(b) : <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a98464ed99207f2ed392f751bae2ea10e">ie_decode_fp8_e5m2_u8</a>(b);</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>    acc += W[(size_t)r * (<span class="keywordtype">size_t</span>)ldW + (size_t)k] * xv;</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>  }</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span> </div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>  __shared__ <span class="keywordtype">float</span> buf[256];</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>  buf[threadIdx.x] = acc;</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>  __syncthreads();</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span> </div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> s = blockDim.x &gt;&gt; 1; s &gt; 0; s &gt;&gt;= 1) {</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>    <span class="keywordflow">if</span> (threadIdx.x &lt; s) buf[threadIdx.x] += buf[threadIdx.x + s];</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>    __syncthreads();</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>  }</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span> </div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>  <span class="keywordflow">if</span> (threadIdx.x == 0) {</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>    <span class="keywordtype">float</span> out = alpha * buf[0];</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>    <span class="keywordflow">if</span> (beta != 0.f) out += beta * y[r];</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>    y[r] = out;</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>  }</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>}</div>
</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span></div>
<div class="foldopen" id="foldopen00318" data-start="{" data-end="}">
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#aea063f21d4bdf3ba4108f9677476aad4">  318</a></span>__global__ <span class="keywordtype">void</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#aea063f21d4bdf3ba4108f9677476aad4">k_vec_tanh_f32</a>(<span class="keywordtype">float</span> *__restrict__ y,</div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>                               <span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ x, <span class="keywordtype">int</span> n) {</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = blockIdx.x * blockDim.x + threadIdx.x; i &lt; n;</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>       i += blockDim.x * gridDim.x) {</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>    y[i] = tanhf(x[i]);</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>  }</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>}</div>
</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span></div>
<div class="foldopen" id="foldopen00340" data-start="{" data-end="}">
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#ac440d51163bc9f16e835d00aedcb4b79">  340</a></span>__global__ <span class="keywordtype">void</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#ac440d51163bc9f16e835d00aedcb4b79">k_pack_w_blockedk_f32</a>(<span class="keywordtype">float</span> *__restrict__ Wp,</div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>                                      <span class="keyword">const</span> <span class="keywordtype">float</span> *__restrict__ W, <span class="keywordtype">int</span> rows,</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>                                      <span class="keywordtype">int</span> cols, <span class="keywordtype">int</span> ldW, <span class="keywordtype">int</span> block_k) {</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>  <span class="keywordtype">int</span> r0 = blockIdx.y * blockDim.y + threadIdx.y;</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>  <span class="keywordtype">int</span> k0 = blockIdx.x * blockDim.x + threadIdx.x;</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span> </div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> r = r0; r &lt; rows; r += blockDim.y * gridDim.y) {</div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = k0; k &lt; cols; k += blockDim.x * gridDim.x) {</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>      <span class="keywordtype">int</span> kb = k / block_k;</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>      <span class="keywordtype">int</span> ko = k % block_k;</div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>      <span class="keywordtype">size_t</span> dst = ((size_t)kb * (size_t)rows + (size_t)r) * (<span class="keywordtype">size_t</span>)block_k +</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>                   (size_t)ko;</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>      Wp[dst] = W[(size_t)r * (<span class="keywordtype">size_t</span>)ldW + (size_t)k];</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>    }</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>  }</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>}</div>
</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span> </div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span><span class="comment">/* ========================================================================== */</span></div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span><span class="comment">/*                                  Launchers                                 */</span></div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span><span class="comment">/* ========================================================================== */</span></div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span></div>
<div class="foldopen" id="foldopen00366" data-start="{" data-end="}">
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno"><a class="line" href="group__IE__GPU.html#ga92e383308a681db6bb757c3add5906f0">  366</a></span><span class="keywordtype">int</span> <a class="code hl_function" href="group__IE__GPU.html#ga92e383308a681db6bb757c3add5906f0">ie_cuda_launch_gemv_rowwise_f32</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> *W, <span class="keyword">const</span> <span class="keywordtype">float</span> *x, <span class="keywordtype">float</span> *y,</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>                                    <span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols, <span class="keywordtype">int</span> ldW, <span class="keywordtype">float</span> alpha,</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>                                    <span class="keywordtype">float</span> beta, <a class="code hl_typedef" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream) {</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>  <span class="keywordflow">if</span> (!W || !x || !y || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols) {</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>    <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span>  }</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>  dim3 block(256, 1, 1);</div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>  dim3 grid(rows, 1, 1);</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k_gemv_rowwise_f32&lt;&lt;&lt;grid, block, 0, stream&gt;</a>&gt;&gt;(W, x, y, rows, cols, ldW,</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>                                                  alpha, beta);</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span>  <a class="code hl_define" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>  <span class="keywordflow">return</span> <a class="code hl_define" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>}</div>
</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span></div>
<div class="foldopen" id="foldopen00387" data-start="{" data-end="}">
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno"><a class="line" href="group__IE__GPU.html#gaa2441c827e95b20c0413b0372ffc262b">  387</a></span><span class="keywordtype">int</span> <a class="code hl_function" href="group__IE__GPU.html#gaa2441c827e95b20c0413b0372ffc262b">ie_cuda_launch_gemv_bias_act_f32</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> *W, <span class="keyword">const</span> <span class="keywordtype">float</span> *x,</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>                                     <span class="keyword">const</span> <span class="keywordtype">float</span> *bias, <span class="keywordtype">float</span> *y, <span class="keywordtype">int</span> rows,</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>                                     <span class="keywordtype">int</span> cols, <span class="keywordtype">int</span> ldW, <span class="keywordtype">float</span> alpha, <span class="keywordtype">float</span> beta,</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>                                     <a class="code hl_typedef" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a> act,</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>                                     <a class="code hl_typedef" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream) {</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>  <span class="keywordflow">if</span> (!W || !x || !y || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols) {</div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>    <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>  }</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>  dim3 block(256, 1, 1);</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>  dim3 grid(rows, 1, 1);</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#ab9150fe6fc7da507974bfdd38b262ce2">k_gemv_bias_act_f32&lt;&lt;&lt;grid, block, 0, stream&gt;</a>&gt;&gt;(W, x, bias, y, rows, cols,</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>                                                  ldW, alpha, beta, act);</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>  <a class="code hl_define" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>  <span class="keywordflow">return</span> <a class="code hl_define" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>}</div>
</div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span></div>
<div class="foldopen" id="foldopen00410" data-start="{" data-end="}">
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#a525e3ca0d9d0030847aef26b70fa0cb9">  410</a></span><span class="keywordtype">int</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a525e3ca0d9d0030847aef26b70fa0cb9">ie_cuda_launch_gemv_rowwise_qi8_f32</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> *W, <span class="keyword">const</span> int8_t *xq,</div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>                                        <span class="keywordtype">float</span> *y, <span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols, <span class="keywordtype">int</span> ldW,</div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>                                        <span class="keywordtype">float</span> scale, <span class="keywordtype">int</span> zp, <span class="keywordtype">float</span> alpha,</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>                                        <span class="keywordtype">float</span> beta, <a class="code hl_typedef" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream) {</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>  <span class="keywordflow">if</span> (!W || !xq || !y || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols) {</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>    <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>  }</div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>  dim3 block(256, 1, 1);</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>  dim3 grid(rows, 1, 1);</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#abb0d57e76ef0b1dea1ae1b8bb55e1c02">k_gemv_rowwise_qi8_f32&lt;&lt;&lt;grid, block, 0, stream&gt;</a>&gt;&gt;(W, xq, y, rows, cols,</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span>                                                     ldW, scale, zp, alpha,</div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>                                                     beta);</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>  <a class="code hl_define" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>  <span class="keywordflow">return</span> <a class="code hl_define" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>}</div>
</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span></div>
<div class="foldopen" id="foldopen00433" data-start="{" data-end="}">
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno"><a class="line" href="ie__kernels__cuda_8cu.html#a78cbe5a89ec13c5a9edca717f79caab8">  433</a></span><span class="keywordtype">int</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a78cbe5a89ec13c5a9edca717f79caab8">ie_cuda_launch_gemv_rowwise_qfp8_f32</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> *W, <span class="keyword">const</span> uint8_t *x8,</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>                                         <span class="keywordtype">float</span> *y, <span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> cols, <span class="keywordtype">int</span> ldW,</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>                                         <a class="code hl_enumeration" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52c">ie_fp8_format</a> fmt, <span class="keywordtype">float</span> alpha,</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>                                         <span class="keywordtype">float</span> beta, <a class="code hl_typedef" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream) {</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>  <span class="keywordflow">if</span> (!W || !x8 || !y || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols) {</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>    <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span>    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>  }</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>  dim3 block(256, 1, 1);</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>  dim3 grid(rows, 1, 1);</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a74040aacee610aa771ee11bb0bc74022">k_gemv_rowwise_qfp8_f32&lt;&lt;&lt;grid, block, 0, stream&gt;</a>&gt;&gt;(W, x8, y, rows, cols,</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>                                                      ldW, fmt, alpha, beta);</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>  <a class="code hl_define" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>  <span class="keywordflow">return</span> <a class="code hl_define" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>}</div>
</div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span></div>
<div class="foldopen" id="foldopen00458" data-start="{" data-end="}">
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno"><a class="line" href="group__IE__GPU.html#ga4e8445935545f1b5bbb671826543ffab">  458</a></span><span class="keywordtype">int</span> <a class="code hl_function" href="group__IE__GPU.html#ga4e8445935545f1b5bbb671826543ffab">ie_cuda_launch_vec_tanh_f32</a>(<span class="keywordtype">float</span> *y, <span class="keyword">const</span> <span class="keywordtype">float</span> *x, <span class="keywordtype">int</span> n,</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>                                <a class="code hl_typedef" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream) {</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>  <span class="keywordflow">if</span> (!x || !y || n &lt;= 0) {</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>    <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>  }</div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> block = 256;</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>  <span class="keywordtype">int</span> grid = (n + block - 1) / block;</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>  <span class="keywordflow">if</span> (grid &gt; 65535) grid = 65535;</div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#aea063f21d4bdf3ba4108f9677476aad4">k_vec_tanh_f32&lt;&lt;&lt;grid, block, 0, stream&gt;</a>&gt;&gt;(y, x, n);</div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span>  <a class="code hl_define" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>  <span class="keywordflow">return</span> <a class="code hl_define" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>}</div>
</div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span></div>
<div class="foldopen" id="foldopen00478" data-start="{" data-end="}">
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno"><a class="line" href="group__IE__GPU.html#ga72b6dfd858bd993a18d9c5dfb3112389">  478</a></span><span class="keywordtype">int</span> <a class="code hl_function" href="group__IE__GPU.html#ga72b6dfd858bd993a18d9c5dfb3112389">ie_cuda_launch_pack_w_blockedk_f32</a>(<span class="keywordtype">float</span> *Wp, <span class="keyword">const</span> <span class="keywordtype">float</span> *W, <span class="keywordtype">int</span> rows,</div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>                                       <span class="keywordtype">int</span> cols, <span class="keywordtype">int</span> ldW, <span class="keywordtype">int</span> block_k,</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>                                       <a class="code hl_typedef" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream) {</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>  <span class="keywordflow">if</span> (!Wp || !W || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols || block_k &lt;= 0) {</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>    <a class="code hl_function" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>  }</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>  dim3 block(32, 8, 1); <span class="comment">/* 256 threads per block */</span></div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>  dim3 grid((cols + block.x - 1) / block.x, (rows + block.y - 1) / block.y, 1);</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#ac440d51163bc9f16e835d00aedcb4b79">k_pack_w_blockedk_f32&lt;&lt;&lt;grid, block, 0, stream&gt;</a>&gt;&gt;(Wp, W, rows, cols, ldW,</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>                                                    block_k);</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>  <a class="code hl_define" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>  <span class="keywordflow">return</span> <a class="code hl_define" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>}</div>
</div>
<div class="ttc" id="agroup__IE__GPU_html_ga08ba1d3777f64c23e99124d2e460e701"><div class="ttname"><a href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a></div><div class="ttdeci">enum ie_act_kind_e ie_act_kind_t</div><div class="ttdoc">Activation types supported by fused kernels.</div></div>
<div class="ttc" id="agroup__IE__GPU_html_ga4e8445935545f1b5bbb671826543ffab"><div class="ttname"><a href="group__IE__GPU.html#ga4e8445935545f1b5bbb671826543ffab">ie_cuda_launch_vec_tanh_f32</a></div><div class="ttdeci">int ie_cuda_launch_vec_tanh_f32(float *y, const float *x, int n, ie_cuda_stream_t stream)</div><div class="ttdoc">Launch elementwise tanh on device.</div><div class="ttdef"><b>Definition</b> <a href="#l00458">ie_kernels_cuda.cu:458</a></div></div>
<div class="ttc" id="agroup__IE__GPU_html_ga6656c0ddd9df382048e7cd162e0c1d64"><div class="ttname"><a href="group__IE__GPU.html#ga6656c0ddd9df382048e7cd162e0c1d64">ie_cuda_last_error_string</a></div><div class="ttdeci">const char * ie_cuda_last_error_string(void)</div><div class="ttdoc">Retrieve the last CUDA error string set by a launcher in this TU.</div><div class="ttdef"><b>Definition</b> <a href="#l00057">ie_kernels_cuda.cu:57</a></div></div>
<div class="ttc" id="agroup__IE__GPU_html_ga72b6dfd858bd993a18d9c5dfb3112389"><div class="ttname"><a href="group__IE__GPU.html#ga72b6dfd858bd993a18d9c5dfb3112389">ie_cuda_launch_pack_w_blockedk_f32</a></div><div class="ttdeci">int ie_cuda_launch_pack_w_blockedk_f32(float *Wp, const float *W, int rows, int cols, int ldW, int block_k, ie_cuda_stream_t stream)</div><div class="ttdoc">Launch packing of row-major W into Blocked-K layout on device.</div><div class="ttdef"><b>Definition</b> <a href="#l00478">ie_kernels_cuda.cu:478</a></div></div>
<div class="ttc" id="agroup__IE__GPU_html_ga92e383308a681db6bb757c3add5906f0"><div class="ttname"><a href="group__IE__GPU.html#ga92e383308a681db6bb757c3add5906f0">ie_cuda_launch_gemv_rowwise_f32</a></div><div class="ttdeci">int ie_cuda_launch_gemv_rowwise_f32(const float *W, const float *x, float *y, int rows, int cols, int ldW, float alpha, float beta, ie_cuda_stream_t stream)</div><div class="ttdoc">Launch row-wise GEMV (float path).</div><div class="ttdef"><b>Definition</b> <a href="#l00366">ie_kernels_cuda.cu:366</a></div></div>
<div class="ttc" id="agroup__IE__GPU_html_gaa2441c827e95b20c0413b0372ffc262b"><div class="ttname"><a href="group__IE__GPU.html#gaa2441c827e95b20c0413b0372ffc262b">ie_cuda_launch_gemv_bias_act_f32</a></div><div class="ttdeci">int ie_cuda_launch_gemv_bias_act_f32(const float *W, const float *x, const float *bias, float *y, int rows, int cols, int ldW, float alpha, float beta, ie_act_kind_t act, ie_cuda_stream_t stream)</div><div class="ttdoc">Launch fused GEMV + bias + activation (float).</div><div class="ttdef"><b>Definition</b> <a href="#l00387">ie_kernels_cuda.cu:387</a></div></div>
<div class="ttc" id="agroup__IE__GPU_html_gaefb3d7d282a514152960b6c3d812355b"><div class="ttname"><a href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a></div><div class="ttdeci">void * ie_cuda_stream_t</div><div class="ttdef"><b>Definition</b> <a href="ie__kernels__cuda_8h_source.html#l00049">ie_kernels_cuda.h:49</a></div></div>
<div class="ttc" id="agroup__IE__GPU_html_ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f"><div class="ttname"><a href="group__IE__GPU.html#ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f">IE_ACT_RELU</a></div><div class="ttdeci">@ IE_ACT_RELU</div><div class="ttdoc">ReLU: max(0, x).</div><div class="ttdef"><b>Definition</b> <a href="ie__kernels__cuda_8h_source.html#l00057">ie_kernels_cuda.h:57</a></div></div>
<div class="ttc" id="agroup__IE__GPU_html_ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08"><div class="ttname"><a href="group__IE__GPU.html#ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08">IE_ACT_TANH</a></div><div class="ttdeci">@ IE_ACT_TANH</div><div class="ttdoc">Hyperbolic tangent.</div><div class="ttdef"><b>Definition</b> <a href="ie__kernels__cuda_8h_source.html#l00058">ie_kernels_cuda.h:58</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a525e3ca0d9d0030847aef26b70fa0cb9"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a525e3ca0d9d0030847aef26b70fa0cb9">ie_cuda_launch_gemv_rowwise_qi8_f32</a></div><div class="ttdeci">int ie_cuda_launch_gemv_rowwise_qi8_f32(const float *W, const int8_t *xq, float *y, int rows, int cols, int ldW, float scale, int zp, float alpha, float beta, ie_cuda_stream_t stream)</div><div class="ttdoc">Launch GEMV with INT8 activations (per-tensor), fused dequantization.</div><div class="ttdef"><b>Definition</b> <a href="#l00410">ie_kernels_cuda.cu:410</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a5ab38bcd2467e982c68d46e66acfa9ef"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a></div><div class="ttdeci">static __thread char g_ie_cuda_err[256]</div><div class="ttdef"><b>Definition</b> <a href="#l00037">ie_kernels_cuda.cu:37</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a603115e5bb835d21609518d0af053e8d"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a603115e5bb835d21609518d0af053e8d">ie_apply_activation</a></div><div class="ttdeci">__device__ float ie_apply_activation(float x, ie_act_kind_t act)</div><div class="ttdoc">Apply a simple activation kind to a scalar.</div><div class="ttdef"><b>Definition</b> <a href="#l00085">ie_kernels_cuda.cu:85</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a74040aacee610aa771ee11bb0bc74022"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a74040aacee610aa771ee11bb0bc74022">k_gemv_rowwise_qfp8_f32</a></div><div class="ttdeci">__global__ void k_gemv_rowwise_qfp8_f32(const float *__restrict__ W, const uint8_t *__restrict__ x8, float *__restrict__ y, int rows, int cols, int ldW, ie_fp8_format fmt, float alpha, float beta)</div><div class="ttdoc">Row-wise GEMV with FP8 activations (E4M3/E5M2), fused byte decode.</div><div class="ttdef"><b>Definition</b> <a href="#l00278">ie_kernels_cuda.cu:278</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a78cbe5a89ec13c5a9edca717f79caab8"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a78cbe5a89ec13c5a9edca717f79caab8">ie_cuda_launch_gemv_rowwise_qfp8_f32</a></div><div class="ttdeci">int ie_cuda_launch_gemv_rowwise_qfp8_f32(const float *W, const uint8_t *x8, float *y, int rows, int cols, int ldW, ie_fp8_format fmt, float alpha, float beta, ie_cuda_stream_t stream)</div><div class="ttdoc">Launch GEMV with FP8 activations (E4M3/E5M2), fused byte decode.</div><div class="ttdef"><b>Definition</b> <a href="#l00433">ie_kernels_cuda.cu:433</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a841d35ecb02f9850f311a5724d21deac"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a></div><div class="ttdeci">static void ie_cuda_set_err(const char *msg)</div><div class="ttdoc">Set or clear the per-thread CUDA error string buffer.</div><div class="ttdef"><b>Definition</b> <a href="#l00043">ie_kernels_cuda.cu:43</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a8d15fdbcd086d7ef5932207fa5b5d91b"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a8d15fdbcd086d7ef5932207fa5b5d91b">ie_decode_fp8_e4m3_u8</a></div><div class="ttdeci">__device__ float ie_decode_fp8_e4m3_u8(uint8_t v)</div><div class="ttdoc">Decode one E4M3 FP8 byte on device (subnormals flushed to zero).</div><div class="ttdef"><b>Definition</b> <a href="#l00101">ie_kernels_cuda.cu:101</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a98464ed99207f2ed392f751bae2ea10e"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a98464ed99207f2ed392f751bae2ea10e">ie_decode_fp8_e5m2_u8</a></div><div class="ttdeci">__device__ float ie_decode_fp8_e5m2_u8(uint8_t v)</div><div class="ttdoc">Decode one E5M2 FP8 byte on device (IEEE-like special cases).</div><div class="ttdef"><b>Definition</b> <a href="#l00119">ie_kernels_cuda.cu:119</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_ab9150fe6fc7da507974bfdd38b262ce2"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#ab9150fe6fc7da507974bfdd38b262ce2">k_gemv_bias_act_f32</a></div><div class="ttdeci">__global__ void k_gemv_bias_act_f32(const float *__restrict__ W, const float *__restrict__ x, const float *__restrict__ bias, float *__restrict__ y, int rows, int cols, int ldW, float alpha, float beta, ie_act_kind_t act)</div><div class="ttdoc">Fused GEMV + bias + activation kernel (float activations).</div><div class="ttdef"><b>Definition</b> <a href="#l00188">ie_kernels_cuda.cu:188</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_abb0d57e76ef0b1dea1ae1b8bb55e1c02"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#abb0d57e76ef0b1dea1ae1b8bb55e1c02">k_gemv_rowwise_qi8_f32</a></div><div class="ttdeci">__global__ void k_gemv_rowwise_qi8_f32(const float *__restrict__ W, const int8_t *__restrict__ xq, float *__restrict__ y, int rows, int cols, int ldW, float scale, int zp, float alpha, float beta)</div><div class="ttdoc">Row-wise GEMV with INT8 activations (per-tensor), fused dequantization.</div><div class="ttdef"><b>Definition</b> <a href="#l00235">ie_kernels_cuda.cu:235</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_ac440d51163bc9f16e835d00aedcb4b79"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#ac440d51163bc9f16e835d00aedcb4b79">k_pack_w_blockedk_f32</a></div><div class="ttdeci">__global__ void k_pack_w_blockedk_f32(float *__restrict__ Wp, const float *__restrict__ W, int rows, int cols, int ldW, int block_k)</div><div class="ttdoc">Pack row-major W into Blocked-K layout on device (see header docs).</div><div class="ttdef"><b>Definition</b> <a href="#l00340">ie_kernels_cuda.cu:340</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_aea063f21d4bdf3ba4108f9677476aad4"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#aea063f21d4bdf3ba4108f9677476aad4">k_vec_tanh_f32</a></div><div class="ttdeci">__global__ void k_vec_tanh_f32(float *__restrict__ y, const float *__restrict__ x, int n)</div><div class="ttdoc">Elementwise hyperbolic tangent on a vector.</div><div class="ttdef"><b>Definition</b> <a href="#l00318">ie_kernels_cuda.cu:318</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_af00402674d56c833c92c62df1cef1e84"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k_gemv_rowwise_f32</a></div><div class="ttdeci">__global__ void k_gemv_rowwise_f32(const float *__restrict__ W, const float *__restrict__ x, float *__restrict__ y, int rows, int cols, int ldW, float alpha, float beta)</div><div class="ttdoc">Row-wise GEMV kernel: y = alpha * W * x + beta * y.</div><div class="ttdef"><b>Definition</b> <a href="#l00154">ie_kernels_cuda.cu:154</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_af4c083462b1e956e6461aa246d2af9a6"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a></div><div class="ttdeci">#define CUDA_GUARD(call)</div><div class="ttdoc">CUDA error guard macro that stores the error string and returns.</div><div class="ttdef"><b>Definition</b> <a href="#l00066">ie_kernels_cuda.cu:66</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_afb3284f12e7d5038612ece3185920449"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a></div><div class="ttdeci">#define IE_CUDA_OK</div><div class="ttdef"><b>Definition</b> <a href="#l00028">ie_kernels_cuda.cu:28</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8h_html"><div class="ttname"><a href="ie__kernels__cuda_8h.html">ie_kernels_cuda.h</a></div><div class="ttdoc">CUDA GPU kernels and C-ABI launchers for hot-path vector/matrix ops.</div></div>
<div class="ttc" id="aie__quant__act_8h_html"><div class="ttname"><a href="ie__quant__act_8h.html">ie_quant_act.h</a></div><div class="ttdoc">Activation quantization utilities (INT8 and FP8) for runtime paths.</div></div>
<div class="ttc" id="aie__quant__act_8h_html_a67a1bdaa8281d1c69b6b76ecba79c52c"><div class="ttname"><a href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52c">ie_fp8_format</a></div><div class="ttdeci">ie_fp8_format</div><div class="ttdoc">FP8 format selector.</div><div class="ttdef"><b>Definition</b> <a href="ie__quant__act_8h_source.html#l00040">ie_quant_act.h:40</a></div></div>
<div class="ttc" id="aie__quant__act_8h_html_a67a1bdaa8281d1c69b6b76ecba79c52ca67cfe56fcb473bed9a2f92388f2fc347"><div class="ttname"><a href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52ca67cfe56fcb473bed9a2f92388f2fc347">IE_FP8_E4M3</a></div><div class="ttdeci">@ IE_FP8_E4M3</div><div class="ttdoc">1 sign, 4 exponent (bias 7), 3 mantissa, finite-only saturation.</div><div class="ttdef"><b>Definition</b> <a href="ie__quant__act_8h_source.html#l00041">ie_quant_act.h:41</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_996f45160da62e1a3d7f6046fad68f51.html">engine</a></li><li class="navelem"><a class="el" href="dir_3d9126aa00c041bc0b8f859d1965a0f4.html">src</a></li><li class="navelem"><a class="el" href="dir_2151caada9eddb57703a29b50b7782f8.html">kernels</a></li><li class="navelem"><a class="el" href="ie__kernels__cuda_8cu.html">ie_kernels_cuda.cu</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
