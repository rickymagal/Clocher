<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Inference Engine (Clocher): CUDA kernels &amp; launchers</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Inference Engine (Clocher)
   &#160;<span id="projectnumber">0.2</span>
   </div>
   <div id="projectbrief">C11 CPU/GPU inference baseline with strict metrics &amp; harness</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('group__IE__GPU.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#files">Files</a> &#124;
<a href="#define-members">Macros</a> &#124;
<a href="#typedef-members">Typedefs</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">CUDA kernels &amp; launchers</div>  </div>
</div><!--header-->
<div class="contents">

<p>Public API to invoke CUDA kernels for GEMV, activations and packing.  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="files"></a>
Files</h2></td></tr>
<tr class="memitem:ie__kernels__cuda_8h"><td class="memItemLeft" align="right" valign="top">file &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__kernels__cuda_8h.html">ie_kernels_cuda.h</a></td></tr>
<tr class="memdesc:ie__kernels__cuda_8h"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA GPU kernels and C-ABI launchers for hot-path vector/matrix ops. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="define-members"></a>
Macros</h2></td></tr>
<tr class="memitem:gad253e9c439228a67be0e55b0f4c81edf"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#gad253e9c439228a67be0e55b0f4c81edf">IE_CUDA_STREAM_T_DEFINED</a></td></tr>
<tr class="memdesc:gad253e9c439228a67be0e55b0f4c81edf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Opaque CUDA stream handle used by this C API.  <a href="group__IE__GPU.html#gad253e9c439228a67be0e55b0f4c81edf">More...</a><br /></td></tr>
<tr class="separator:gad253e9c439228a67be0e55b0f4c81edf"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr class="memitem:gaefb3d7d282a514152960b6c3d812355b"><td class="memItemLeft" align="right" valign="top">typedef void *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a></td></tr>
<tr class="separator:gaefb3d7d282a514152960b6c3d812355b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga08ba1d3777f64c23e99124d2e460e701"><td class="memItemLeft" align="right" valign="top">typedef enum <a class="el" href="group__IE__GPU.html#gab2c254b332e574ed55c2537075337f85">ie_act_kind_e</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a></td></tr>
<tr class="memdesc:ga08ba1d3777f64c23e99124d2e460e701"><td class="mdescLeft">&#160;</td><td class="mdescRight">Activation types supported by fused kernels.  <a href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">More...</a><br /></td></tr>
<tr class="separator:ga08ba1d3777f64c23e99124d2e460e701"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:gab2c254b332e574ed55c2537075337f85"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#gab2c254b332e574ed55c2537075337f85">ie_act_kind_e</a> { <br />
&#160;&#160;<a class="el" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a72bddb07e52c2dcecd390cda078cd33f">IE_ACT_NONE</a> = 0
, <a class="el" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f">IE_ACT_RELU</a> = 1
, <a class="el" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08">IE_ACT_TANH</a> = 2
, <a class="el" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a72bddb07e52c2dcecd390cda078cd33f">IE_ACT_NONE</a> = 0
, <br />
&#160;&#160;<a class="el" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f">IE_ACT_RELU</a> = 1
, <a class="el" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08">IE_ACT_TANH</a> = 2
<br />
 }</td></tr>
<tr class="memdesc:gab2c254b332e574ed55c2537075337f85"><td class="mdescLeft">&#160;</td><td class="mdescRight">Activation types supported by fused kernels.  <a href="group__IE__GPU.html#gab2c254b332e574ed55c2537075337f85">More...</a><br /></td></tr>
<tr class="separator:gab2c254b332e574ed55c2537075337f85"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:gacf16a468f3ceed4f35dbd6990ff4b302"><td class="memItemLeft" align="right" valign="top">const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#gacf16a468f3ceed4f35dbd6990ff4b302">ie_cuda_last_error_string</a> (void)</td></tr>
<tr class="memdesc:gacf16a468f3ceed4f35dbd6990ff4b302"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return a thread-local message describing the last CUDA error.  <a href="group__IE__GPU.html#gacf16a468f3ceed4f35dbd6990ff4b302">More...</a><br /></td></tr>
<tr class="separator:gacf16a468f3ceed4f35dbd6990ff4b302"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga92e383308a681db6bb757c3add5906f0"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#ga92e383308a681db6bb757c3add5906f0">ie_cuda_launch_gemv_rowwise_f32</a> (const float *W, const float *x, float *y, int rows, int cols, int ldW, float alpha, float beta, <a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream)</td></tr>
<tr class="memdesc:ga92e383308a681db6bb757c3add5906f0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute <code>y = alpha * W * x + beta * y</code> (row-wise GEMV).  <a href="group__IE__GPU.html#ga92e383308a681db6bb757c3add5906f0">More...</a><br /></td></tr>
<tr class="separator:ga92e383308a681db6bb757c3add5906f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa2441c827e95b20c0413b0372ffc262b"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#gaa2441c827e95b20c0413b0372ffc262b">ie_cuda_launch_gemv_bias_act_f32</a> (const float *W, const float *x, const float *bias, float *y, int rows, int cols, int ldW, float alpha, float beta, <a class="el" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a> act, <a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream)</td></tr>
<tr class="memdesc:gaa2441c827e95b20c0413b0372ffc262b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute <code>y = act(alpha * W*x + bias + beta*y)</code> in one pass.  <a href="group__IE__GPU.html#gaa2441c827e95b20c0413b0372ffc262b">More...</a><br /></td></tr>
<tr class="separator:gaa2441c827e95b20c0413b0372ffc262b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga525e3ca0d9d0030847aef26b70fa0cb9"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#ga525e3ca0d9d0030847aef26b70fa0cb9">ie_cuda_launch_gemv_rowwise_qi8_f32</a> (const float *W, const int8_t *xq, float *y, int rows, int cols, int ldW, float scale, int zp, float alpha, float beta, <a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream)</td></tr>
<tr class="memdesc:ga525e3ca0d9d0030847aef26b70fa0cb9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Row-wise GEMV with INT8 activations (per-tensor), fused dequantization.  <a href="group__IE__GPU.html#ga525e3ca0d9d0030847aef26b70fa0cb9">More...</a><br /></td></tr>
<tr class="separator:ga525e3ca0d9d0030847aef26b70fa0cb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga78cbe5a89ec13c5a9edca717f79caab8"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#ga78cbe5a89ec13c5a9edca717f79caab8">ie_cuda_launch_gemv_rowwise_qfp8_f32</a> (const float *W, const uint8_t *x8, float *y, int rows, int cols, int ldW, <a class="el" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52c">ie_fp8_format</a> fmt, float alpha, float beta, <a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream)</td></tr>
<tr class="memdesc:ga78cbe5a89ec13c5a9edca717f79caab8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Row-wise GEMV with FP8 activations (E4M3/E5M2), fused byte decode.  <a href="group__IE__GPU.html#ga78cbe5a89ec13c5a9edca717f79caab8">More...</a><br /></td></tr>
<tr class="separator:ga78cbe5a89ec13c5a9edca717f79caab8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4e8445935545f1b5bbb671826543ffab"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#ga4e8445935545f1b5bbb671826543ffab">ie_cuda_launch_vec_tanh_f32</a> (float *y, const float *x, int n, <a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream)</td></tr>
<tr class="memdesc:ga4e8445935545f1b5bbb671826543ffab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute <code>y[i] = tanh(x[i])</code> for <code>i in [0, n)</code>.  <a href="group__IE__GPU.html#ga4e8445935545f1b5bbb671826543ffab">More...</a><br /></td></tr>
<tr class="separator:ga4e8445935545f1b5bbb671826543ffab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga72b6dfd858bd993a18d9c5dfb3112389"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__IE__GPU.html#ga72b6dfd858bd993a18d9c5dfb3112389">ie_cuda_launch_pack_w_blockedk_f32</a> (float *Wp, const float *W, int rows, int cols, int ldW, int block_k, <a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a> stream)</td></tr>
<tr class="memdesc:ga72b6dfd858bd993a18d9c5dfb3112389"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pack a row-major matrix into Blocked-K layout for better memory access.  <a href="group__IE__GPU.html#ga72b6dfd858bd993a18d9c5dfb3112389">More...</a><br /></td></tr>
<tr class="separator:ga72b6dfd858bd993a18d9c5dfb3112389"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>Public API to invoke CUDA kernels for GEMV, activations and packing. </p>
<h2 class="groupheader">Macro Definition Documentation</h2>
<a id="gad253e9c439228a67be0e55b0f4c81edf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad253e9c439228a67be0e55b0f4c81edf">&#9670;&nbsp;</a></span>IE_CUDA_STREAM_T_DEFINED</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define IE_CUDA_STREAM_T_DEFINED</td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Opaque CUDA stream handle used by this C API. </p>
<p>In non-CUDA translation units this is a <code>void*</code>. In the CUDA TU it is replaced by <code>cudaStream_t</code>. You may pass <code>NULL</code> to use the default stream. </p>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8h_source.html#l00050">50</a> of file <a class="el" href="ie__kernels__cuda_8h_source.html">ie_kernels_cuda.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Typedef Documentation</h2>
<a id="ga08ba1d3777f64c23e99124d2e460e701"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga08ba1d3777f64c23e99124d2e460e701">&#9670;&nbsp;</a></span>ie_act_kind_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef enum <a class="el" href="group__IE__GPU.html#gab2c254b332e574ed55c2537075337f85">ie_act_kind_e</a> <a class="el" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Activation types supported by fused kernels. </p>

</div>
</div>
<a id="gaefb3d7d282a514152960b6c3d812355b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaefb3d7d282a514152960b6c3d812355b">&#9670;&nbsp;</a></span>ie_cuda_stream_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef void* <a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8h_source.html#l00051">51</a> of file <a class="el" href="ie__kernels__cuda_8h_source.html">ie_kernels_cuda.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="gab2c254b332e574ed55c2537075337f85"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab2c254b332e574ed55c2537075337f85">&#9670;&nbsp;</a></span>ie_act_kind_e</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group__IE__GPU.html#gab2c254b332e574ed55c2537075337f85">ie_act_kind_e</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Activation types supported by fused kernels. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="ggab2c254b332e574ed55c2537075337f85a72bddb07e52c2dcecd390cda078cd33f"></a>IE_ACT_NONE&#160;</td><td class="fielddoc"><p>Identity. </p>
<p><br  />
 </p>
</td></tr>
<tr><td class="fieldname"><a id="ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f"></a>IE_ACT_RELU&#160;</td><td class="fielddoc"><p>ReLU: max(0, x). </p>
<p><br  />
 </p>
</td></tr>
<tr><td class="fieldname"><a id="ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08"></a>IE_ACT_TANH&#160;</td><td class="fielddoc"><p>Hyperbolic tangent. </p>
<p><br  />
 </p>
</td></tr>
<tr><td class="fieldname"><a id="ggab2c254b332e574ed55c2537075337f85a72bddb07e52c2dcecd390cda078cd33f"></a>IE_ACT_NONE&#160;</td><td class="fielddoc"><p>Identity. </p>
<p><br  />
 </p>
</td></tr>
<tr><td class="fieldname"><a id="ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f"></a>IE_ACT_RELU&#160;</td><td class="fielddoc"><p>ReLU. </p>
<p><br  />
 </p>
</td></tr>
<tr><td class="fieldname"><a id="ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08"></a>IE_ACT_TANH&#160;</td><td class="fielddoc"><p>tanh(). </p>
<p><br  />
 </p>
</td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8h_source.html#l00057">57</a> of file <a class="el" href="ie__kernels__cuda_8h_source.html">ie_kernels_cuda.h</a>.</p>
<div class="fragment"><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;                           {</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;  <a class="code" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a72bddb07e52c2dcecd390cda078cd33f">IE_ACT_NONE</a> = 0,   </div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;  <a class="code" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f">IE_ACT_RELU</a> = 1,   </div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;  <a class="code" href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08">IE_ACT_TANH</a> = 2    </div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;} <a class="code" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a>;</div>
<div class="ttc" id="agroup__IE__GPU__ZE_html_ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f"><div class="ttname"><a href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a4efb020b6e30222eac585f53f1d3e47f">IE_ACT_RELU</a></div><div class="ttdeci">@ IE_ACT_RELU</div><div class="ttdoc">ReLU: max(0, x).</div><div class="ttdef"><b>Definition:</b> <a href="ie__kernels__cuda_8h_source.html#l00059">ie_kernels_cuda.h:59</a></div></div>
<div class="ttc" id="agroup__IE__GPU__ZE_html_ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08"><div class="ttname"><a href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a5c3ab96a97ea7aa059b44e7508c28a08">IE_ACT_TANH</a></div><div class="ttdeci">@ IE_ACT_TANH</div><div class="ttdoc">Hyperbolic tangent.</div><div class="ttdef"><b>Definition:</b> <a href="ie__kernels__cuda_8h_source.html#l00061">ie_kernels_cuda.h:60</a></div></div>
<div class="ttc" id="agroup__IE__GPU__ZE_html_ggab2c254b332e574ed55c2537075337f85a72bddb07e52c2dcecd390cda078cd33f"><div class="ttname"><a href="group__IE__GPU__ZE.html#ggab2c254b332e574ed55c2537075337f85a72bddb07e52c2dcecd390cda078cd33f">IE_ACT_NONE</a></div><div class="ttdeci">@ IE_ACT_NONE</div><div class="ttdoc">Identity.</div><div class="ttdef"><b>Definition:</b> <a href="ie__kernels__cuda_8h_source.html#l00058">ie_kernels_cuda.h:58</a></div></div>
<div class="ttc" id="agroup__IE__GPU_html_ga08ba1d3777f64c23e99124d2e460e701"><div class="ttname"><a href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a></div><div class="ttdeci">enum ie_act_kind_e ie_act_kind_t</div><div class="ttdoc">Activation types supported by fused kernels.</div></div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="gacf16a468f3ceed4f35dbd6990ff4b302"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gacf16a468f3ceed4f35dbd6990ff4b302">&#9670;&nbsp;</a></span>ie_cuda_last_error_string()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const char* ie_cuda_last_error_string </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Return a thread-local message describing the last CUDA error. </p>
<p>The pointer remains valid until the next launcher call on the same thread. An empty string means "no error".</p>
<dl class="section return"><dt>Returns</dt><dd>NUL-terminated error message (never <code>NULL</code>).</dd></dl>
<p>Return a thread-local message describing the last CUDA error.</p>
<dl class="section return"><dt>Returns</dt><dd>Pointer to a thread-local, NUL-terminated message (may be ""). </dd></dl>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8cu_source.html#l00067">67</a> of file <a class="el" href="ie__kernels__cuda_8cu_source.html">ie_kernels_cuda.cu</a>.</p>
<div class="fragment"><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;                                            {</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a>;</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;}</div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a5ab38bcd2467e982c68d46e66acfa9ef"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a5ab38bcd2467e982c68d46e66acfa9ef">g_ie_cuda_err</a></div><div class="ttdeci">static __thread char g_ie_cuda_err[256]</div><div class="ttdef"><b>Definition:</b> <a href="ie__kernels__cuda_8cu_source.html#l00045">ie_kernels_cuda.cu:45</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="ie__kernels__cuda_8cu_source.html#l00045">g_ie_cuda_err</a>.</p>

</div>
</div>
<a id="gaa2441c827e95b20c0413b0372ffc262b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa2441c827e95b20c0413b0372ffc262b">&#9670;&nbsp;</a></span>ie_cuda_launch_gemv_bias_act_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ie_cuda_launch_gemv_bias_act_f32 </td>
          <td>(</td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldW</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701">ie_act_kind_t</a>&#160;</td>
          <td class="paramname"><em>act</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a>&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Compute <code>y = act(alpha * W*x + bias + beta*y)</code> in one pass. </p>
<ul>
<li>Applies optional per-row <code>bias</code> (may be NULL â†’ treated as zeros).</li>
<li>Applies activation specified by <a class="el" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701" title="Activation types supported by fused kernels.">ie_act_kind_t</a>.</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Device pointer to row-major matrix <code>(rows x ldW)</code>. </td></tr>
    <tr><td class="paramname">x</td><td>Device pointer to input vector (length <code>cols</code>). </td></tr>
    <tr><td class="paramname">bias</td><td>Device pointer to per-row bias (length <code>rows</code>) or <code>NULL</code>. </td></tr>
    <tr><td class="paramname">y</td><td>Device pointer to output vector (length <code>rows</code>). </td></tr>
    <tr><td class="paramname">rows</td><td>Number of rows in <code>W</code>/<code>y</code>/<code>bias</code> (&gt;= 1). </td></tr>
    <tr><td class="paramname">cols</td><td>Number of columns in <code>W</code> and elements in <code>x</code> (&gt;= 1). </td></tr>
    <tr><td class="paramname">ldW</td><td>Leading dimension of <code>W</code> in elements (&gt;= <code>cols</code>). </td></tr>
    <tr><td class="paramname">alpha</td><td>Scalar multiplier for <code>W*x</code>. </td></tr>
    <tr><td class="paramname">beta</td><td>Scalar multiplier for existing <code>y</code> (use <code>0.f</code> to overwrite). </td></tr>
    <tr><td class="paramname">act</td><td>Activation kind (see <a class="el" href="group__IE__GPU.html#ga08ba1d3777f64c23e99124d2e460e701" title="Activation types supported by fused kernels.">ie_act_kind_t</a>). </td></tr>
    <tr><td class="paramname">stream</td><td>CUDA stream handle (may be <code>NULL</code>). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code>0</code> on success, negative on error.</dd></dl>
<dl class="section pre"><dt>Precondition</dt><dd>Pointers are non-NULL device pointers (except <code>bias</code>, which may be NULL). </dd>
<dd>
<code>rows &gt; 0</code>, <code>cols &gt; 0</code>, <code>ldW &gt;= cols</code>. </dd></dl>
<dl class="section post"><dt>Postcondition</dt><dd><code>y</code> contains the result with activation applied.</dd></dl>
<p>Compute <code>y = act(alpha * W*x + bias + beta*y)</code> in one pass. </p>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8cu_source.html#l00391">391</a> of file <a class="el" href="ie__kernels__cuda_8cu_source.html">ie_kernels_cuda.cu</a>.</p>
<div class="fragment"><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;                                                              {</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;  <span class="keywordflow">if</span> (!W || !x || !y || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols) {</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;    <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;  }</div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160; </div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;  dim3 block(256, 1, 1);</div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;  dim3 grid(rows, 1, 1);</div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;  k_gemv_bias_act_f32&lt;&lt;&lt;grid, block, 0, stream&gt;&gt;&gt;(W, x, bias, y,</div>
<div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;                                                  rows, cols, ldW,</div>
<div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;                                                  alpha, beta, act);</div>
<div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;}</div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_a841d35ecb02f9850f311a5724d21deac"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a></div><div class="ttdeci">static void ie_cuda_set_err(const char *msg)</div><div class="ttdoc">Set or clear the per-thread CUDA error string buffer.</div><div class="ttdef"><b>Definition:</b> <a href="ie__kernels__cuda_8cu_source.html#l00051">ie_kernels_cuda.cu:51</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_af4c083462b1e956e6461aa246d2af9a6"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a></div><div class="ttdeci">#define CUDA_GUARD(call)</div><div class="ttdoc">CUDA error guard macro that stores the error string and returns.</div><div class="ttdef"><b>Definition:</b> <a href="ie__kernels__cuda_8cu_source.html#l00078">ie_kernels_cuda.cu:78</a></div></div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_afb3284f12e7d5038612ece3185920449"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a></div><div class="ttdeci">#define IE_CUDA_OK</div><div class="ttdef"><b>Definition:</b> <a href="ie__kernels__cuda_8cu_source.html#l00028">ie_kernels_cuda.cu:28</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="ie__kernels__cuda_8cu_source.html#l00078">CUDA_GUARD</a>, <a class="el" href="ie__kernels__cuda_8cu_source.html#l00028">IE_CUDA_OK</a>, and <a class="el" href="ie__kernels__cuda_8cu_source.html#l00051">ie_cuda_set_err()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="group__IE__GPU_gaa2441c827e95b20c0413b0372ffc262b_cgraph.svg" width="350" height="52"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="ga92e383308a681db6bb757c3add5906f0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga92e383308a681db6bb757c3add5906f0">&#9670;&nbsp;</a></span>ie_cuda_launch_gemv_rowwise_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ie_cuda_launch_gemv_rowwise_f32 </td>
          <td>(</td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldW</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a>&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Compute <code>y = alpha * W * x + beta * y</code> (row-wise GEMV). </p>
<ul>
<li><code>W</code> is dense row-major with <code>rows</code> rows and <code>ldW</code> columns stride.</li>
<li>Each row is reduced in parallel; one block per output row.</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Device pointer to row-major matrix <code>(rows x ldW)</code>. </td></tr>
    <tr><td class="paramname">x</td><td>Device pointer to input vector (length <code>cols</code>). </td></tr>
    <tr><td class="paramname">y</td><td>Device pointer to output vector (length <code>rows</code>). </td></tr>
    <tr><td class="paramname">rows</td><td>Number of rows in <code>W</code> and elements in <code>y</code> (&gt;= 1). </td></tr>
    <tr><td class="paramname">cols</td><td>Number of columns in <code>W</code> and elements in <code>x</code> (&gt;= 1). </td></tr>
    <tr><td class="paramname">ldW</td><td>Leading dimension of <code>W</code> in elements (&gt;= <code>cols</code>). </td></tr>
    <tr><td class="paramname">alpha</td><td>Scalar multiplier for <code>W*x</code>. </td></tr>
    <tr><td class="paramname">beta</td><td>Scalar multiplier for existing <code>y</code> (use <code>0.f</code> to overwrite). </td></tr>
    <tr><td class="paramname">stream</td><td>CUDA stream handle (may be <code>NULL</code>). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code>0</code> on success, negative on error (see <a class="el" href="group__IE__GPU.html#gacf16a468f3ceed4f35dbd6990ff4b302" title="Return a thread-local message describing the last CUDA error.">ie_cuda_last_error_string()</a>).</dd></dl>
<dl class="section pre"><dt>Precondition</dt><dd>Pointers are non-NULL and reference device memory. </dd>
<dd>
<code>rows &gt; 0</code>, <code>cols &gt; 0</code>, <code>ldW &gt;= cols</code>. </dd></dl>
<dl class="section post"><dt>Postcondition</dt><dd><code>y</code> contains the result.</dd></dl>
<p>Compute <code>y = alpha * W * x + beta * y</code> (row-wise GEMV). </p>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8cu_source.html#l00365">365</a> of file <a class="el" href="ie__kernels__cuda_8cu_source.html">ie_kernels_cuda.cu</a>.</p>
<div class="fragment"><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;                                                             {</div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;  <span class="keywordflow">if</span> (!W || !x || !y || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols) {</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;    <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;  }</div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160; </div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;  dim3 block(256, 1, 1);</div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;  dim3 grid(rows, 1, 1);</div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;  k_gemv_rowwise_f32&lt;&lt;&lt;grid, block, 0, stream&gt;&gt;&gt;(W, x, y, rows, cols, ldW,</div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;                                                 alpha, beta);</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="ie__kernels__cuda_8cu_source.html#l00078">CUDA_GUARD</a>, <a class="el" href="ie__kernels__cuda_8cu_source.html#l00028">IE_CUDA_OK</a>, and <a class="el" href="ie__kernels__cuda_8cu_source.html#l00051">ie_cuda_set_err()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="group__IE__GPU_ga92e383308a681db6bb757c3add5906f0_cgraph.svg" width="350" height="52"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="ga78cbe5a89ec13c5a9edca717f79caab8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga78cbe5a89ec13c5a9edca717f79caab8">&#9670;&nbsp;</a></span>ie_cuda_launch_gemv_rowwise_qfp8_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ie_cuda_launch_gemv_rowwise_qfp8_f32 </td>
          <td>(</td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t *&#160;</td>
          <td class="paramname"><em>x8</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldW</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52c">ie_fp8_format</a>&#160;</td>
          <td class="paramname"><em>fmt</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a>&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Row-wise GEMV with FP8 activations (E4M3/E5M2), fused byte decode. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Float weights on device (row-major), size rows x ldW. </td></tr>
    <tr><td class="paramname">x8</td><td>FP8 activations on device (bytes), length cols. </td></tr>
    <tr><td class="paramname">y</td><td>Output on device, length rows. </td></tr>
    <tr><td class="paramname">rows</td><td>Rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Cols. </td></tr>
    <tr><td class="paramname">ldW</td><td>Leading dimension (&gt;= cols). </td></tr>
    <tr><td class="paramname">fmt</td><td>FP8 format (<a class="el" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52ca67cfe56fcb473bed9a2f92388f2fc347" title="1 sign, 4 exponent (bias 7), 3 mantissa; finite-only saturation policy.">IE_FP8_E4M3</a> or <a class="el" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52caa1844f8dd595aba744eb3243b127a3e0" title="1 sign, 5 exponent (bias 15), 2 mantissa; Inf/NaN representable.">IE_FP8_E5M2</a>). </td></tr>
    <tr><td class="paramname">alpha</td><td>Scale for W*x. </td></tr>
    <tr><td class="paramname">beta</td><td>Scale for existing y. </td></tr>
    <tr><td class="paramname">stream</td><td>CUDA stream (may be NULL). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code>0</code> on success, negative on error.</dd></dl>
<p>Row-wise GEMV with FP8 activations (E4M3/E5M2), fused byte decode. </p>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8cu_source.html#l00450">450</a> of file <a class="el" href="ie__kernels__cuda_8cu_source.html">ie_kernels_cuda.cu</a>.</p>
<div class="fragment"><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;                                                                  {</div>
<div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;  <span class="keywordflow">if</span> (!W || !x8 || !y || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols) {</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;    <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;  }</div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160; </div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;  dim3 block(256, 1, 1);</div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;  dim3 grid(rows, 1, 1);</div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;  k_gemv_rowwise_qfp8_f32&lt;&lt;&lt;grid, block, 0, stream&gt;&gt;&gt;(W, x8, y,</div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;                                                      rows, cols, ldW,</div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;                                                      fmt, alpha, beta);</div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="ie__kernels__cuda_8cu_source.html#l00078">CUDA_GUARD</a>, <a class="el" href="ie__kernels__cuda_8cu_source.html#l00028">IE_CUDA_OK</a>, and <a class="el" href="ie__kernels__cuda_8cu_source.html#l00051">ie_cuda_set_err()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="group__IE__GPU_ga78cbe5a89ec13c5a9edca717f79caab8_cgraph.svg" width="350" height="52"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="ga525e3ca0d9d0030847aef26b70fa0cb9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga525e3ca0d9d0030847aef26b70fa0cb9">&#9670;&nbsp;</a></span>ie_cuda_launch_gemv_rowwise_qi8_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ie_cuda_launch_gemv_rowwise_qi8_f32 </td>
          <td>(</td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>xq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldW</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>zp</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a>&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Row-wise GEMV with INT8 activations (per-tensor), fused dequantization. </p>
<p>Dequantization model: <code>real = scale * (q - zero_point)</code>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Float weights on device (row-major), size rows x ldW. </td></tr>
    <tr><td class="paramname">xq</td><td>INT8 activations on device, length cols. </td></tr>
    <tr><td class="paramname">y</td><td>Output on device, length rows. </td></tr>
    <tr><td class="paramname">rows</td><td>Rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Cols. </td></tr>
    <tr><td class="paramname">ldW</td><td>Leading dimension (&gt;= cols). </td></tr>
    <tr><td class="paramname">scale</td><td>Per-tensor scale. </td></tr>
    <tr><td class="paramname">zp</td><td>Per-tensor zero-point. </td></tr>
    <tr><td class="paramname">alpha</td><td>Scale for W*x. </td></tr>
    <tr><td class="paramname">beta</td><td>Scale for existing y. </td></tr>
    <tr><td class="paramname">stream</td><td>CUDA stream (may be NULL). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code>0</code> on success, negative on error.</dd></dl>
<p>Row-wise GEMV with INT8 activations (per-tensor), fused dequantization. </p>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8cu_source.html#l00420">420</a> of file <a class="el" href="ie__kernels__cuda_8cu_source.html">ie_kernels_cuda.cu</a>.</p>
<div class="fragment"><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;                                                                 {</div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;  <span class="keywordflow">if</span> (!W || !xq || !y || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols) {</div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;    <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;  }</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160; </div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;  dim3 block(256, 1, 1);</div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;  dim3 grid(rows, 1, 1);</div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;  k_gemv_rowwise_qi8_f32&lt;&lt;&lt;grid, block, 0, stream&gt;&gt;&gt;(W, xq, y,</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;                                                     rows, cols, ldW,</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;                                                     scale, zp,</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;                                                     alpha, beta);</div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="ie__kernels__cuda_8cu_source.html#l00078">CUDA_GUARD</a>, <a class="el" href="ie__kernels__cuda_8cu_source.html#l00028">IE_CUDA_OK</a>, and <a class="el" href="ie__kernels__cuda_8cu_source.html#l00051">ie_cuda_set_err()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="group__IE__GPU_ga525e3ca0d9d0030847aef26b70fa0cb9_cgraph.svg" width="350" height="52"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="ga72b6dfd858bd993a18d9c5dfb3112389"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga72b6dfd858bd993a18d9c5dfb3112389">&#9670;&nbsp;</a></span>ie_cuda_launch_pack_w_blockedk_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ie_cuda_launch_pack_w_blockedk_f32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>Wp</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldW</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>block_k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a>&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Pack a row-major matrix into Blocked-K layout for better memory access. </p>
<p>The K dimension (columns) is partitioned into tiles of size <code>block_k</code>. Data are stored as contiguous tiles: </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> kb = k / block_k;  <span class="comment">// tile index along K</span></div>
<div class="line"><span class="keywordtype">int</span> ko = k % block_k;  <span class="comment">// in-tile offset</span></div>
<div class="line"><span class="keywordtype">size_t</span> dst = ((size_t)kb * rows + r) * (size_t)block_k + (<span class="keywordtype">size_t</span>)ko;</div>
<div class="line">Wp[dst] = W[(size_t)r * ldW + (<span class="keywordtype">size_t</span>)k];</div>
</div><!-- fragment --><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">Wp</td><td>Device pointer to destination buffer (size = rows*cols). </td></tr>
    <tr><td class="paramname">W</td><td>Device pointer to source row-major matrix. </td></tr>
    <tr><td class="paramname">rows</td><td>Number of rows (&gt;= 1). </td></tr>
    <tr><td class="paramname">cols</td><td>Number of columns (&gt;= 1). </td></tr>
    <tr><td class="paramname">ldW</td><td>Leading dimension of <code>W</code> in elements (&gt;= <code>cols</code>). </td></tr>
    <tr><td class="paramname">block_k</td><td>Tile size along K (e.g., 32/64/128; must be &gt; 0). </td></tr>
    <tr><td class="paramname">stream</td><td>CUDA stream handle (may be <code>NULL</code>). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code>0</code> on success, negative on error.</dd></dl>
<dl class="section pre"><dt>Precondition</dt><dd><code>Wp</code> and <code>W</code> are device pointers with sufficient capacity. </dd></dl>
<dl class="section post"><dt>Postcondition</dt><dd><code>Wp</code> contains the packed matrix in Blocked-K layout.</dd></dl>
<p>Pack a row-major matrix into Blocked-K layout for better memory access. </p>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8cu_source.html#l00500">500</a> of file <a class="el" href="ie__kernels__cuda_8cu_source.html">ie_kernels_cuda.cu</a>.</p>
<div class="fragment"><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;                                                                {</div>
<div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;  <span class="keywordflow">if</span> (!Wp || !W || rows &lt;= 0 || cols &lt;= 0 || ldW &lt; cols || block_k &lt;= 0) {</div>
<div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;    <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;  }</div>
<div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160; </div>
<div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;  dim3 block(32, 8, 1); <span class="comment">/* 256 threads per block */</span></div>
<div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;  dim3 grid((cols + block.x - 1) / block.x,</div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;            (rows + block.y - 1) / block.y,</div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;            1);</div>
<div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160; </div>
<div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;  k_pack_w_blockedk_f32&lt;&lt;&lt;grid, block, 0, stream&gt;&gt;&gt;(Wp, W,</div>
<div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;                                                    rows, cols,</div>
<div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;                                                    ldW, block_k);</div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="ie__kernels__cuda_8cu_source.html#l00078">CUDA_GUARD</a>, <a class="el" href="ie__kernels__cuda_8cu_source.html#l00028">IE_CUDA_OK</a>, and <a class="el" href="ie__kernels__cuda_8cu_source.html#l00051">ie_cuda_set_err()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="group__IE__GPU_ga72b6dfd858bd993a18d9c5dfb3112389_cgraph.svg" width="343" height="52"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="ga4e8445935545f1b5bbb671826543ffab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4e8445935545f1b5bbb671826543ffab">&#9670;&nbsp;</a></span>ie_cuda_launch_vec_tanh_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ie_cuda_launch_vec_tanh_f32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__IE__GPU.html#gaefb3d7d282a514152960b6c3d812355b">ie_cuda_stream_t</a>&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="ie__kernels__cuda_8h.html">engine/include/ie_kernels_cuda.h</a>&gt;</code></p>

<p>Compute <code>y[i] = tanh(x[i])</code> for <code>i in [0, n)</code>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">y</td><td>Device pointer to output vector (length <code>n</code>). </td></tr>
    <tr><td class="paramname">x</td><td>Device pointer to input vector (length <code>n</code>). </td></tr>
    <tr><td class="paramname">n</td><td>Number of elements (&gt;= 1). </td></tr>
    <tr><td class="paramname">stream</td><td>CUDA stream handle (may be <code>NULL</code>). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code>0</code> on success, negative on error.</dd></dl>
<dl class="section pre"><dt>Precondition</dt><dd><code>x</code> and <code>y</code> are valid device pointers with at least <code>n</code> elements. </dd></dl>
<dl class="section post"><dt>Postcondition</dt><dd><code>y</code> contains elementwise <code>tanh(x)</code>.</dd></dl>
<p>Compute <code>y[i] = tanh(x[i])</code> for <code>i in [0, n)</code>. </p>

<p class="definition">Definition at line <a class="el" href="ie__kernels__cuda_8cu_source.html#l00478">478</a> of file <a class="el" href="ie__kernels__cuda_8cu_source.html">ie_kernels_cuda.cu</a>.</p>
<div class="fragment"><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;                                                         {</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(NULL);</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;  <span class="keywordflow">if</span> (!x || !y || n &lt;= 0) {</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;    <a class="code" href="ie__kernels__cuda_8cu.html#a841d35ecb02f9850f311a5724d21deac">ie_cuda_set_err</a>(<span class="stringliteral">&quot;invalid arguments&quot;</span>);</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;    <span class="keywordflow">return</span> -1;</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;  }</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160; </div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;  <span class="keyword">const</span> <span class="keywordtype">int</span> block = 256;</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;  <span class="keywordtype">int</span> grid = (n + block - 1) / block;</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;  <span class="keywordflow">if</span> (grid &gt; 65535) grid = 65535;</div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160; </div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;  k_vec_tanh_f32&lt;&lt;&lt;grid, block, 0, stream&gt;&gt;&gt;(y, x, n);</div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;  <a class="code" href="ie__kernels__cuda_8cu.html#af4c083462b1e956e6461aa246d2af9a6">CUDA_GUARD</a>(cudaGetLastError());</div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="ie__kernels__cuda_8cu.html#afb3284f12e7d5038612ece3185920449">IE_CUDA_OK</a>;</div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="ie__kernels__cuda_8cu_source.html#l00078">CUDA_GUARD</a>, <a class="el" href="ie__kernels__cuda_8cu_source.html#l00028">IE_CUDA_OK</a>, and <a class="el" href="ie__kernels__cuda_8cu_source.html#l00051">ie_cuda_set_err()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="group__IE__GPU_ga4e8445935545f1b5bbb671826543ffab_cgraph.svg" width="335" height="52"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
