<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Inference Engine (Clocher): engine/include/ie_kernels.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Inference Engine (Clocher)<span id="projectnumber">&#160;0.2</span>
   </div>
   <div id="projectbrief">C11 CPU/GPU inference baseline with strict metrics &amp; harness</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('ie__kernels_8h.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">ie_kernels.h File Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><code>#include &lt;stddef.h&gt;</code><br />
<code>#include &lt;stdint.h&gt;</code><br />
<code>#include &quot;<a class="el" href="ie__quant__act_8h_source.html">ie_quant_act.h</a>&quot;</code><br />
</div><div class="textblock"><div class="dynheader">
Include dependency graph for ie_kernels.h:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 0 --></div>
</div>
</div><div class="textblock"><div class="dynheader">
This graph shows which files directly or indirectly include this file:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 1 --></div>
</div>
</div>
<p><a href="ie__kernels_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a1b919f71b86ec1791fe53bc68d5c240d" id="r_a1b919f71b86ec1791fe53bc68d5c240d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__kernels_8h.html#a1b919f71b86ec1791fe53bc68d5c240d">ie_kernels_install</a> (<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">use_avx2</a>)</td></tr>
<tr class="memdesc:a1b919f71b86ec1791fe53bc68d5c240d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Install the best available CPU kernels for this process.  <br /></td></tr>
<tr class="separator:a1b919f71b86ec1791fe53bc68d5c240d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e112b3396ed21919f404631c1d4d7fb" id="r_a4e112b3396ed21919f404631c1d4d7fb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__kernels_8h.html#a4e112b3396ed21919f404631c1d4d7fb">ie_gemv_f32</a> (<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> rows, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> cols, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> blk_k)</td></tr>
<tr class="memdesc:a4e112b3396ed21919f404631c1d4d7fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">GEMV (fp32): y[r] = dot(W[r,:], x) + (bias ? bias[r] : 0).  <br /></td></tr>
<tr class="separator:a4e112b3396ed21919f404631c1d4d7fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd518beacb02189b5b640948ed348f25" id="r_abd518beacb02189b5b640948ed348f25"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__kernels_8h.html#abd518beacb02189b5b640948ed348f25">ie_gemv_qi8_f32</a> (<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int8_t</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x_q</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> rows, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> cols, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> blk_k, <a class="el" href="structie__act__i8__params.html">ie_act_i8_params</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">params</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int</a> symmetric)</td></tr>
<tr class="memdesc:abd518beacb02189b5b640948ed348f25"><td class="mdescLeft">&#160;</td><td class="mdescRight">GEMV with per-tensor INT8 activations (fused dequantization).  <br /></td></tr>
<tr class="separator:abd518beacb02189b5b640948ed348f25"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf2b6125d5d567523a5d113f09dd73ee" id="r_abf2b6125d5d567523a5d113f09dd73ee"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__kernels_8h.html#abf2b6125d5d567523a5d113f09dd73ee">ie_gemv_qi8pg_f32</a> (<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int8_t</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x_q</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> rows, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> cols, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> blk_k, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> group_size, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">scales</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int8_t</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">zeros</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int</a> symmetric)</td></tr>
<tr class="memdesc:abf2b6125d5d567523a5d113f09dd73ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">GEMV with per-group INT8 activations (blockwise parameters).  <br /></td></tr>
<tr class="separator:abf2b6125d5d567523a5d113f09dd73ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7548a57990692513f283a22543688e1b" id="r_a7548a57990692513f283a22543688e1b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__kernels_8h.html#a7548a57990692513f283a22543688e1b">ie_gemv_qfp8_f32</a> (<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">uint8_t</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x_fp8</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> rows, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> cols, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> blk_k, <a class="el" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52c">ie_fp8_format</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">fmt</a>)</td></tr>
<tr class="memdesc:a7548a57990692513f283a22543688e1b"><td class="mdescLeft">&#160;</td><td class="mdescRight">GEMV with FP8 activations (software decode, fused).  <br /></td></tr>
<tr class="separator:a7548a57990692513f283a22543688e1b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31b6c03fd5b95bdecb37f06821d3ce93" id="r_a31b6c03fd5b95bdecb37f06821d3ce93"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__kernels_8h.html#a31b6c03fd5b95bdecb37f06821d3ce93">ie_vec_tanh_f32</a> (<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *v, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a> n, <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">fast_tanh</a>)</td></tr>
<tr class="memdesc:a31b6c03fd5b95bdecb37f06821d3ce93"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vector tanh on fp32 data (in-place).  <br /></td></tr>
<tr class="separator:a31b6c03fd5b95bdecb37f06821d3ce93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b9a073aea2b6ff7450b2d0ee32765ae" id="r_a2b9a073aea2b6ff7450b2d0ee32765ae"><td class="memItemLeft" align="right" valign="top"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__kernels_8h.html#a2b9a073aea2b6ff7450b2d0ee32765ae">ie_fast_tanhf</a> (<a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x</a>)</td></tr>
<tr class="memdesc:a2b9a073aea2b6ff7450b2d0ee32765ae"><td class="mdescLeft">&#160;</td><td class="mdescRight">Fast scalar tanh approximation.  <br /></td></tr>
<tr class="separator:a2b9a073aea2b6ff7450b2d0ee32765ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a2b9a073aea2b6ff7450b2d0ee32765ae" name="a2b9a073aea2b6ff7450b2d0ee32765ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b9a073aea2b6ff7450b2d0ee32765ae">&#9670;&#160;</a></span>ie_fast_tanhf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> ie_fast_tanhf </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a>&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Fast scalar tanh approximation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>Input value. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Approximated tanh(x).</dd></dl>
<p>Fast scalar tanh approximation.</p>
<p>For large |x| we short-circuit to +/-1.0f. For moderate |x| we use a small rational function that gives a smooth S-curve: </p><pre class="fragment">tanh(x) â‰ˆ x * (27 + x^2) / (27 + 9 x^2)
</pre><p> Finally, the result is clamped to [-1, 1] to guarantee range correctness.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>Input value. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Approximated tanh(x) in [-1.0f, 1.0f]. </dd></dl>

<p class="definition">Definition at line <a class="el" href="fast__tanh_8c_source.html#l00028">28</a> of file <a class="el" href="fast__tanh_8c_source.html">fast_tanh.c</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   28</span>                             {</div>
<div class="line"><span class="lineno">   29</span>  <span class="comment">/* Early clamp for large magnitude to avoid overflow and extra work. */</span></div>
<div class="line"><span class="lineno">   30</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x</a> &gt; 5.0f)  <span class="keywordflow">return</span> 1.0f;</div>
<div class="line"><span class="lineno">   31</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x</a> &lt; -5.0f) <span class="keywordflow">return</span> -1.0f;</div>
<div class="line"><span class="lineno">   32</span> </div>
<div class="line"><span class="lineno">   33</span>  <span class="comment">/* Rational approximation (cheap and monotonic on [-3,3]) */</span></div>
<div class="line"><span class="lineno">   34</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x2</a>  = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x</a> * <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x</a>;</div>
<div class="line"><span class="lineno">   35</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">num</a> = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x</a> * (27.0f + <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x2</a>);</div>
<div class="line"><span class="lineno">   36</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">den</a> = 27.0f + 9.0f * <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x2</a>;</div>
<div class="line"><span class="lineno">   37</span>  <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">num</a> / <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">den</a>;</div>
<div class="line"><span class="lineno">   38</span> </div>
<div class="line"><span class="lineno">   39</span>  <span class="comment">/* Safety clamp for strict range compliance. */</span></div>
<div class="line"><span class="lineno">   40</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> &gt; 1.0f)  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> = 1.0f;</div>
<div class="line"><span class="lineno">   41</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> &lt; -1.0f) <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> = -1.0f;</div>
<div class="line"><span class="lineno">   42</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>;</div>
<div class="line"><span class="lineno">   43</span>}</div>
<div class="ttc" id="aie__kernels__cuda_8cu_html_af00402674d56c833c92c62df1cef1e84"><div class="ttname"><a href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k_gemv_rowwise_f32</a></div><div class="ttdeci">__global__ void k_gemv_rowwise_f32(const float *__restrict__ W, const float *__restrict__ x, float *__restrict__ y, int rows, int cols, int ldW, float alpha, float beta)</div><div class="ttdoc">Row-wise GEMV kernel: y = alpha * W * x + beta * y.</div><div class="ttdef"><b>Definition</b> <a href="ie__kernels__cuda_8cu_source.html#l00157">ie_kernels_cuda.cu:157</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a4e112b3396ed21919f404631c1d4d7fb" name="a4e112b3396ed21919f404631c1d4d7fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4e112b3396ed21919f404631c1d4d7fb">&#9670;&#160;</a></span>ie_gemv_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a> ie_gemv_f32 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>blk_k</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>GEMV (fp32): y[r] = dot(W[r,:], x) + (bias ? bias[r] : 0). </p>
<p>Computes a matrix-vector product using the best installed implementation.</p>
<p>Layout:</p><ul>
<li>Default is row-major: W is rows*cols floats, each row contiguous.</li>
<li>Some kernels also accept a "blocked-K contiguous" interpretation per row; pass blk_k to describe the block size. Passing 0 disables blocking.</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Pointer to weights (row-major or compatible packed layout). </td></tr>
    <tr><td class="paramname">x</td><td>Input vector (length cols). </td></tr>
    <tr><td class="paramname">y</td><td>Output vector (length rows). </td></tr>
    <tr><td class="paramname">rows</td><td>Number of rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Number of columns. </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias vector (length rows) or NULL. </td></tr>
    <tr><td class="paramname">blk_k</td><td>Column block size for blocked-K layout; 0 for plain row-major.</td></tr>
  </table>
  </dd>
</dl>
<p>GEMV (fp32): y[r] = dot(W[r,:], x) + (bias ? bias[r] : 0).</p>
<p>If kernels were not installed yet, calls <a class="el" href="ie__kernels_8h.html#a1b919f71b86ec1791fe53bc68d5c240d" title="Install the best available CPU kernels for this process.">ie_kernels_install</a> with AVX2 enabled.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Weights. </td></tr>
    <tr><td class="paramname">x</td><td>Input vector. </td></tr>
    <tr><td class="paramname">y</td><td>Output vector. </td></tr>
    <tr><td class="paramname">rows</td><td>Rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Cols. </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias. </td></tr>
    <tr><td class="paramname">blk_k</td><td>Column block size; 0 disables blocking. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="gemv__generic_8c_source.html#l00323">323</a> of file <a class="el" href="gemv__generic_8c_source.html">gemv_generic.c</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  324</span>                                                               {</div>
<div class="line"><span class="lineno">  325</span>  <span class="keywordflow">if</span> (!<a class="code hl_variable" href="gemv__generic_8c.html#aa80eb69d355054f1f8213721e72bec9a">s_gemv_f32</a>) <a class="code hl_function" href="gemv__generic_8c.html#a1b919f71b86ec1791fe53bc68d5c240d">ie_kernels_install</a>(<span class="comment">/*use_avx2=*/</span>1);</div>
<div class="line"><span class="lineno">  326</span>  <a class="code hl_variable" href="gemv__generic_8c.html#aa80eb69d355054f1f8213721e72bec9a">s_gemv_f32</a>(<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>, rows, cols, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>, blk_k);</div>
<div class="line"><span class="lineno">  327</span>}</div>
<div class="ttc" id="agemv__generic_8c_html_a1b919f71b86ec1791fe53bc68d5c240d"><div class="ttname"><a href="gemv__generic_8c.html#a1b919f71b86ec1791fe53bc68d5c240d">ie_kernels_install</a></div><div class="ttdeci">void ie_kernels_install(int use_avx2)</div><div class="ttdoc">Install the best available fp32 GEMV kernel.</div><div class="ttdef"><b>Definition</b> <a href="gemv__generic_8c_source.html#l00289">gemv_generic.c:289</a></div></div>
<div class="ttc" id="agemv__generic_8c_html_aa80eb69d355054f1f8213721e72bec9a"><div class="ttname"><a href="gemv__generic_8c.html#aa80eb69d355054f1f8213721e72bec9a">s_gemv_f32</a></div><div class="ttdeci">static void(* s_gemv_f32)(const float *, const float *, float *, size_t, size_t, const float *, size_t)</div><div class="ttdoc">Installed fp32 GEMV implementation.</div><div class="ttdef"><b>Definition</b> <a href="gemv__generic_8c_source.html#l00073">gemv_generic.c:73</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemv__generic_8c_source.html#l00289">ie_kernels_install()</a>, and <a class="el" href="gemv__generic_8c_source.html#l00073">s_gemv_f32</a>.</p>

<p class="reference">Referenced by <a class="el" href="ie__device__common_8c_source.html#l00086">cpu_gemv_f32()</a>, <a class="el" href="test__kernels_8c_source.html#l00109">test_gemv_rowmajor_no_bias()</a>, and <a class="el" href="test__kernels_8c_source.html#l00129">test_gemv_rowmajor_with_bias()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 2 --></div>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 3 --></div>
</div>

</div>
</div>
<a id="a7548a57990692513f283a22543688e1b" name="a7548a57990692513f283a22543688e1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7548a57990692513f283a22543688e1b">&#9670;&#160;</a></span>ie_gemv_qfp8_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a> ie_gemv_qfp8_f32 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">uint8_t</a> *&#160;</td>
          <td class="paramname"><em>x_fp8</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>blk_k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52c">ie_fp8_format</a>&#160;</td>
          <td class="paramname"><em>fmt</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>GEMV with FP8 activations (software decode, fused). </p>
<p>Decodes FP8 bytes (E4M3 or E5M2) on the fly while accumulating the dot product.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Weights (float). </td></tr>
    <tr><td class="paramname">x_fp8</td><td>FP8 activations (bytes, length cols). </td></tr>
    <tr><td class="paramname">y</td><td>Output (float, length rows). </td></tr>
    <tr><td class="paramname">rows</td><td>Rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Cols. </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias or NULL. </td></tr>
    <tr><td class="paramname">blk_k</td><td>Column block size; 0 disables blocking. </td></tr>
    <tr><td class="paramname">fmt</td><td>FP8 format selector.</td></tr>
  </table>
  </dd>
</dl>
<p>GEMV with FP8 activations (software decode, fused).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Weights. </td></tr>
    <tr><td class="paramname">x_fp8</td><td>FP8 activations (bytes). </td></tr>
    <tr><td class="paramname">y</td><td>Output. </td></tr>
    <tr><td class="paramname">rows</td><td>Rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Cols. </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias. </td></tr>
    <tr><td class="paramname">blk_k</td><td>Column block size; 0 disables blocking. </td></tr>
    <tr><td class="paramname">fmt</td><td>FP8 format. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="gemv__generic_8c_source.html#l00394">394</a> of file <a class="el" href="gemv__generic_8c_source.html">gemv_generic.c</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  396</span>                                                       {</div>
<div class="line"><span class="lineno">  397</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">BK</a> = (blk_k &gt; 0 ? blk_k : cols);</div>
<div class="line"><span class="lineno">  398</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">use_e4m3</a> = (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">fmt</a> == <a class="code hl_enumvalue" href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52ca67cfe56fcb473bed9a2f92388f2fc347">IE_FP8_E4M3</a>);</div>
<div class="line"><span class="lineno">  399</span> </div>
<div class="line"><span class="lineno">  400</span>  <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> r = 0; r &lt; rows; ++r) {</div>
<div class="line"><span class="lineno">  401</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> *<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">wrow</a> = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a> + r * cols;</div>
<div class="line"><span class="lineno">  402</span>    <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">acc</a> = 0.0f;</div>
<div class="line"><span class="lineno">  403</span> </div>
<div class="line"><span class="lineno">  404</span>    <span class="keywordtype">size_t</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">kofs</a> = 0;</div>
<div class="line"><span class="lineno">  405</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k0</a> = 0; <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k0</a> &lt; cols; <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k0</a> += <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">BK</a>) {</div>
<div class="line"><span class="lineno">  406</span>      <span class="keyword">const</span> <span class="keywordtype">size_t</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">klen</a> = (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k0</a> + <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">BK</a> &lt;= cols) ? <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">BK</a> : (cols - <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k0</a>);</div>
<div class="line"><span class="lineno">  407</span>      <span class="keyword">const</span> <span class="keywordtype">float</span> *<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">wblk</a> = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">wrow</a> + <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">kofs</a>;</div>
<div class="line"><span class="lineno">  408</span>      <span class="keyword">const</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">uint8_t</a> *<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">xblk</a> = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x_fp8</a> + <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k0</a>;</div>
<div class="line"><span class="lineno">  409</span> </div>
<div class="line"><span class="lineno">  410</span>      <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k</a> = 0; <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k</a> &lt; <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">klen</a>; ++<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k</a>) {</div>
<div class="line"><span class="lineno">  411</span>        <span class="keyword">const</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">uint8_t</a> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">b</a> = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">xblk</a>[<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k</a>];</div>
<div class="line"><span class="lineno">  412</span>        <span class="keyword">const</span> <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">xv</a> = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">use_e4m3</a> ? <a class="code hl_function" href="gemv__generic_8c.html#ab15089960891cb16691529c685e7a96b">ie_decode_fp8_e4m3</a>(<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">b</a>) : <a class="code hl_function" href="gemv__generic_8c.html#a2caa51b99ab073c3a53146ca26153558">ie_decode_fp8_e5m2</a>(<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">b</a>);</div>
<div class="line"><span class="lineno">  413</span>        <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">acc</a> += <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">wblk</a>[<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">k</a>] * <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">xv</a>;</div>
<div class="line"><span class="lineno">  414</span>      }</div>
<div class="line"><span class="lineno">  415</span>      <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">kofs</a> += <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">klen</a>;</div>
<div class="line"><span class="lineno">  416</span>    }</div>
<div class="line"><span class="lineno">  417</span> </div>
<div class="line"><span class="lineno">  418</span>    <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>) <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">acc</a> += <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>[r];</div>
<div class="line"><span class="lineno">  419</span>    <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>[r] = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">acc</a>;</div>
<div class="line"><span class="lineno">  420</span>  }</div>
<div class="line"><span class="lineno">  421</span>}</div>
<div class="ttc" id="agemv__generic_8c_html_a2caa51b99ab073c3a53146ca26153558"><div class="ttname"><a href="gemv__generic_8c.html#a2caa51b99ab073c3a53146ca26153558">ie_decode_fp8_e5m2</a></div><div class="ttdeci">static float ie_decode_fp8_e5m2(uint8_t v)</div><div class="ttdoc">Decode FP8 E5M2 byte to float.</div><div class="ttdef"><b>Definition</b> <a href="gemv__generic_8c_source.html#l00256">gemv_generic.c:256</a></div></div>
<div class="ttc" id="agemv__generic_8c_html_ab15089960891cb16691529c685e7a96b"><div class="ttname"><a href="gemv__generic_8c.html#ab15089960891cb16691529c685e7a96b">ie_decode_fp8_e4m3</a></div><div class="ttdeci">static float ie_decode_fp8_e4m3(uint8_t v)</div><div class="ttdoc">Decode FP8 E4M3 byte to float.</div><div class="ttdef"><b>Definition</b> <a href="gemv__generic_8c_source.html#l00230">gemv_generic.c:230</a></div></div>
<div class="ttc" id="aie__quant__act_8h_html_a67a1bdaa8281d1c69b6b76ecba79c52ca67cfe56fcb473bed9a2f92388f2fc347"><div class="ttname"><a href="ie__quant__act_8h.html#a67a1bdaa8281d1c69b6b76ecba79c52ca67cfe56fcb473bed9a2f92388f2fc347">IE_FP8_E4M3</a></div><div class="ttdeci">@ IE_FP8_E4M3</div><div class="ttdoc">1 sign, 4 exponent (bias 7), 3 mantissa; finite-only saturation policy.</div><div class="ttdef"><b>Definition</b> <a href="ie__quant__act_8h_source.html#l00028">ie_quant_act.h:28</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemv__generic_8c_source.html#l00230">ie_decode_fp8_e4m3()</a>, <a class="el" href="gemv__generic_8c_source.html#l00256">ie_decode_fp8_e5m2()</a>, and <a class="el" href="ie__quant__act_8h_source.html#l00028">IE_FP8_E4M3</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 4 --></div>
</div>

</div>
</div>
<a id="abd518beacb02189b5b640948ed348f25" name="abd518beacb02189b5b640948ed348f25"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd518beacb02189b5b640948ed348f25">&#9670;&#160;</a></span>ie_gemv_qi8_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a> ie_gemv_qi8_f32 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int8_t</a> *&#160;</td>
          <td class="paramname"><em>x_q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>blk_k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structie__act__i8__params.html">ie_act_i8_params</a>&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int</a>&#160;</td>
          <td class="paramname"><em>symmetric</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>GEMV with per-tensor INT8 activations (fused dequantization). </p>
<p>Interprets activations with the affine model: real = scale * (q - zero_point) Implementations may fuse dequantization into the dot product or dequantize into a temporary float buffer depending on ISA.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Weights (float). </td></tr>
    <tr><td class="paramname">x_q</td><td>INT8 activations (length cols). </td></tr>
    <tr><td class="paramname">y</td><td>Output (float, length rows). </td></tr>
    <tr><td class="paramname">rows</td><td>Number of rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Number of columns. </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias (length rows) or NULL. </td></tr>
    <tr><td class="paramname">blk_k</td><td>Column block size; 0 disables blocking. </td></tr>
    <tr><td class="paramname">params</td><td>Per-tensor quantization parameters. </td></tr>
    <tr><td class="paramname">symmetric</td><td>Informational flag (unused by some paths).</td></tr>
  </table>
  </dd>
</dl>
<p>GEMV with per-tensor INT8 activations (fused dequantization).</p>
<p>Uses AVX2/FMA implementation when available; otherwise uses the C fused path.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Weights. </td></tr>
    <tr><td class="paramname">x_q</td><td>INT8 activations. </td></tr>
    <tr><td class="paramname">y</td><td>Output. </td></tr>
    <tr><td class="paramname">rows</td><td>Rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Cols. </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias. </td></tr>
    <tr><td class="paramname">blk_k</td><td>Column block size; 0 disables blocking. </td></tr>
    <tr><td class="paramname">params</td><td>INT8 params. </td></tr>
    <tr><td class="paramname">symmetric</td><td>Informational flag. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="gemv__generic_8c_source.html#l00345">345</a> of file <a class="el" href="gemv__generic_8c_source.html">gemv_generic.c</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  347</span>                                                             {</div>
<div class="line"><span class="lineno">  348</span><span class="preprocessor">#if defined(__GNUC__) || defined(__clang__)</span></div>
<div class="line"><span class="lineno">  349</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">__builtin_cpu_supports</a>(<span class="stringliteral">&quot;avx2&quot;</span>) &amp;&amp; <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">__builtin_cpu_supports</a>(<span class="stringliteral">&quot;fma&quot;</span>)) {</div>
<div class="line"><span class="lineno">  350</span>    <a class="code hl_function" href="gemv__generic_8c.html#aa8a6c887be55a3af970b49855f86682d">ie_gemv_qi8_f32_avx2_impl</a>(<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x_q</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>, rows, cols, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>, blk_k, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">params</a>,</div>
<div class="line"><span class="lineno">  351</span>                              symmetric);</div>
<div class="line"><span class="lineno">  352</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  353</span>  }</div>
<div class="line"><span class="lineno">  354</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  355</span>  <a class="code hl_function" href="gemv__generic_8c.html#aae97939d123420c09e5c3d4d7575b934">gemv_qi8_f32_fused_c_impl</a>(<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x_q</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>, rows, cols, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>, blk_k, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">params</a>,</div>
<div class="line"><span class="lineno">  356</span>                            symmetric);</div>
<div class="line"><span class="lineno">  357</span>}</div>
<div class="ttc" id="agemv__generic_8c_html_aa8a6c887be55a3af970b49855f86682d"><div class="ttname"><a href="gemv__generic_8c.html#aa8a6c887be55a3af970b49855f86682d">ie_gemv_qi8_f32_avx2_impl</a></div><div class="ttdeci">void ie_gemv_qi8_f32_avx2_impl(const float *W, const int8_t *x_q, float *y, size_t rows, size_t cols, const float *bias, size_t blk_k, ie_act_i8_params params, int symmetric)</div><div class="ttdoc">AVX2/FMA GEMV with per-tensor INT8 activations, provided by gemv_avx2.c.</div><div class="ttdef"><b>Definition</b> <a href="gemv__avx2_8c_source.html#l00186">gemv_avx2.c:186</a></div></div>
<div class="ttc" id="agemv__generic_8c_html_aae97939d123420c09e5c3d4d7575b934"><div class="ttname"><a href="gemv__generic_8c.html#aae97939d123420c09e5c3d4d7575b934">gemv_qi8_f32_fused_c_impl</a></div><div class="ttdeci">static void gemv_qi8_f32_fused_c_impl(const float *W, const int8_t *x_q, float *y, size_t rows, size_t cols, const float *bias, size_t blk_k, ie_act_i8_params params, int symmetric)</div><div class="ttdoc">GEMV with per-tensor INT8 activations (fused dequantization), C path.</div><div class="ttdef"><b>Definition</b> <a href="gemv__generic_8c_source.html#l00137">gemv_generic.c:137</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemv__generic_8c_source.html#l00137">gemv_qi8_f32_fused_c_impl()</a>, and <a class="el" href="gemv__avx2_8c_source.html#l00186">ie_gemv_qi8_f32_avx2_impl()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 5 --></div>
</div>

</div>
</div>
<a id="abf2b6125d5d567523a5d113f09dd73ee" name="abf2b6125d5d567523a5d113f09dd73ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf2b6125d5d567523a5d113f09dd73ee">&#9670;&#160;</a></span>ie_gemv_qi8pg_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a> ie_gemv_qi8pg_f32 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int8_t</a> *&#160;</td>
          <td class="paramname"><em>x_q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>blk_k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>group_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>scales</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">const</a> <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int8_t</a> *&#160;</td>
          <td class="paramname"><em>zeros</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int</a>&#160;</td>
          <td class="paramname"><em>symmetric</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>GEMV with per-group INT8 activations (blockwise parameters). </p>
<p>Each group of group_size elements uses its own (scale, zero_point): g = index / group_size real = scales[g] * (q - zeros[g])</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Weights (float). </td></tr>
    <tr><td class="paramname">x_q</td><td>INT8 activations (length cols). </td></tr>
    <tr><td class="paramname">y</td><td>Output (float, length rows). </td></tr>
    <tr><td class="paramname">rows</td><td>Rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Cols. </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias or NULL. </td></tr>
    <tr><td class="paramname">blk_k</td><td>Column block size; 0 disables blocking. </td></tr>
    <tr><td class="paramname">group_size</td><td>Activation group size (&gt;= 1). </td></tr>
    <tr><td class="paramname">scales</td><td>Scales array (ceil(cols/group_size)). </td></tr>
    <tr><td class="paramname">zeros</td><td>Zero-points array (ceil(cols/group_size)). </td></tr>
    <tr><td class="paramname">symmetric</td><td>Informational flag.</td></tr>
  </table>
  </dd>
</dl>
<p>GEMV with per-group INT8 activations (blockwise parameters).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>Weights. </td></tr>
    <tr><td class="paramname">x_q</td><td>INT8 activations. </td></tr>
    <tr><td class="paramname">y</td><td>Output. </td></tr>
    <tr><td class="paramname">rows</td><td>Rows. </td></tr>
    <tr><td class="paramname">cols</td><td>Cols. </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias. </td></tr>
    <tr><td class="paramname">blk_k</td><td>Column block size; 0 disables blocking. </td></tr>
    <tr><td class="paramname">group_size</td><td>Group size. </td></tr>
    <tr><td class="paramname">scales</td><td>Group scales. </td></tr>
    <tr><td class="paramname">zeros</td><td>Group zero points. </td></tr>
    <tr><td class="paramname">symmetric</td><td>Informational flag. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="gemv__generic_8c_source.html#l00374">374</a> of file <a class="el" href="gemv__generic_8c_source.html">gemv_generic.c</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  377</span>                                                           {</div>
<div class="line"><span class="lineno">  378</span>  <a class="code hl_function" href="gemv__generic_8c.html#a439a61ba39c741d7730f5615e540ca9c">gemv_qi8pg_f32_fused_c_impl</a>(<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">W</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">x_q</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>, rows, cols, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">bias</a>, blk_k, group_size,</div>
<div class="line"><span class="lineno">  379</span>                              <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">scales</a>, <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">zeros</a>, symmetric);</div>
<div class="line"><span class="lineno">  380</span>}</div>
<div class="ttc" id="agemv__generic_8c_html_a439a61ba39c741d7730f5615e540ca9c"><div class="ttname"><a href="gemv__generic_8c.html#a439a61ba39c741d7730f5615e540ca9c">gemv_qi8pg_f32_fused_c_impl</a></div><div class="ttdeci">static void gemv_qi8pg_f32_fused_c_impl(const float *W, const int8_t *x_q, float *y, size_t rows, size_t cols, const float *bias, size_t blk_k, size_t group_size, const float *scales, const int8_t *zeros, int symmetric)</div><div class="ttdoc">GEMV with per-group INT8 activations (fused dequantization), C path.</div><div class="ttdef"><b>Definition</b> <a href="gemv__generic_8c_source.html#l00188">gemv_generic.c:188</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemv__generic_8c_source.html#l00188">gemv_qi8pg_f32_fused_c_impl()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 6 --></div>
</div>

</div>
</div>
<a id="a1b919f71b86ec1791fe53bc68d5c240d" name="a1b919f71b86ec1791fe53bc68d5c240d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1b919f71b86ec1791fe53bc68d5c240d">&#9670;&#160;</a></span>ie_kernels_install()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a> ie_kernels_install </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int</a>&#160;</td>
          <td class="paramname"><em>use_avx2</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Install the best available CPU kernels for this process. </p>
<p>Selects optimized implementations based on runtime CPU feature detection and updates an internal dispatch table. Safe to call multiple times; last call wins.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">use_avx2</td><td>Non-zero to allow selecting AVX2/FMA-optimized paths.</td></tr>
  </table>
  </dd>
</dl>
<p>Install the best available CPU kernels for this process.</p>
<p>On x86 (GCC/Clang), installs the AVX2/FMA implementation when allowed and supported by the CPU. Otherwise, installs the generic C fallback.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">use_avx2</td><td>Non-zero to allow selecting AVX2/FMA implementation. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="gemv__generic_8c_source.html#l00289">289</a> of file <a class="el" href="gemv__generic_8c_source.html">gemv_generic.c</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  289</span>                                      {</div>
<div class="line"><span class="lineno">  290</span>  <span class="keywordtype">int</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">use_avx2_runtime</a> = 0;</div>
<div class="line"><span class="lineno">  291</span> </div>
<div class="line"><span class="lineno">  292</span><span class="preprocessor">#if defined(__x86_64__) || defined(_M_X64) || defined(__i386__)</span></div>
<div class="line"><span class="lineno">  293</span><span class="preprocessor">#if defined(__GNUC__) || defined(__clang__)</span></div>
<div class="line"><span class="lineno">  294</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">use_avx2</a>) {</div>
<div class="line"><span class="lineno">  295</span>    <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">__builtin_cpu_supports</a>(<span class="stringliteral">&quot;avx2&quot;</span>) &amp;&amp; <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">__builtin_cpu_supports</a>(<span class="stringliteral">&quot;fma&quot;</span>)) {</div>
<div class="line"><span class="lineno">  296</span>      <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">use_avx2_runtime</a> = 1;</div>
<div class="line"><span class="lineno">  297</span>    }</div>
<div class="line"><span class="lineno">  298</span>  }</div>
<div class="line"><span class="lineno">  299</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  300</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  301</span> </div>
<div class="line"><span class="lineno">  302</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">use_avx2_runtime</a>) {</div>
<div class="line"><span class="lineno">  303</span>    <a class="code hl_variable" href="gemv__generic_8c.html#aa80eb69d355054f1f8213721e72bec9a">s_gemv_f32</a> = <a class="code hl_function" href="gemv__generic_8c.html#a63b484c2984caeed7dfc9b5002444f57">ie_gemv_f32_avx2_impl</a>;</div>
<div class="line"><span class="lineno">  304</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno">  305</span>    <a class="code hl_variable" href="gemv__generic_8c.html#aa80eb69d355054f1f8213721e72bec9a">s_gemv_f32</a> = <a class="code hl_function" href="gemv__generic_8c.html#a51096a373f5e5010d39cbf44e34b730d">gemv_generic_impl</a>;</div>
<div class="line"><span class="lineno">  306</span>  }</div>
<div class="line"><span class="lineno">  307</span>}</div>
<div class="ttc" id="agemv__generic_8c_html_a51096a373f5e5010d39cbf44e34b730d"><div class="ttname"><a href="gemv__generic_8c.html#a51096a373f5e5010d39cbf44e34b730d">gemv_generic_impl</a></div><div class="ttdeci">static void gemv_generic_impl(const float *W, const float *x, float *y, size_t rows, size_t cols, const float *bias, size_t blk_k)</div><div class="ttdoc">Generic C GEMV: y = W * x (+bias), optional blocked-K traversal.</div><div class="ttdef"><b>Definition</b> <a href="gemv__generic_8c_source.html#l00095">gemv_generic.c:95</a></div></div>
<div class="ttc" id="agemv__generic_8c_html_a63b484c2984caeed7dfc9b5002444f57"><div class="ttname"><a href="gemv__generic_8c.html#a63b484c2984caeed7dfc9b5002444f57">ie_gemv_f32_avx2_impl</a></div><div class="ttdeci">void ie_gemv_f32_avx2_impl(const float *W, const float *x, float *y, size_t rows, size_t cols, const float *bias, size_t blk_k)</div><div class="ttdoc">AVX2/FMA GEMV (fp32), provided by gemv_avx2.c.</div><div class="ttdef"><b>Definition</b> <a href="gemv__avx2_8c_source.html#l00090">gemv_avx2.c:90</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemv__generic_8c_source.html#l00095">gemv_generic_impl()</a>, <a class="el" href="gemv__avx2_8c_source.html#l00090">ie_gemv_f32_avx2_impl()</a>, and <a class="el" href="gemv__generic_8c_source.html#l00073">s_gemv_f32</a>.</p>

<p class="reference">Referenced by <a class="el" href="gemv__generic_8c_source.html#l00323">ie_gemv_f32()</a>, and <a class="el" href="test__kernels_8c_source.html#l00149">main()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 7 --></div>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 8 --></div>
</div>

</div>
</div>
<a id="a31b6c03fd5b95bdecb37f06821d3ce93" name="a31b6c03fd5b95bdecb37f06821d3ce93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a31b6c03fd5b95bdecb37f06821d3ce93">&#9670;&#160;</a></span>ie_vec_tanh_f32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">void</a> ie_vec_tanh_f32 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">float</a> *&#160;</td>
          <td class="paramname"><em>v</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">size_t</a>&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">int</a>&#160;</td>
          <td class="paramname"><em>fast_tanh</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Vector tanh on fp32 data (in-place). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">v</td><td>Input/output vector. </td></tr>
    <tr><td class="paramname">n</td><td>Number of elements. </td></tr>
    <tr><td class="paramname">fast_tanh</td><td>Non-zero to use a fast approximation; zero to use <a class="el" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84" title="Row-wise GEMV kernel: y = alpha * W * x + beta * y.">tanhf()</a>.</td></tr>
  </table>
  </dd>
</dl>
<p>Vector tanh on fp32 data (in-place).</p>
<p>If <code>fast_tanh</code> != 0, uses <a class="el" href="ie__kernels_8h.html#a2b9a073aea2b6ff7450b2d0ee32765ae" title="Fast scalar tanh approximation.">ie_fast_tanhf</a>; otherwise uses libm <code>tanhf</code>. Output values are clamped to [-1, 1] in both modes to satisfy strict bounds.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">v</td><td>Pointer to the vector (length <code>n</code>). Modified in-place. </td></tr>
    <tr><td class="paramname">n</td><td>Number of elements in <code>v</code>. </td></tr>
    <tr><td class="paramname">fast_tanh</td><td>Non-zero to use the fast approximation; 0 to use libm. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="fast__tanh_8c_source.html#l00055">55</a> of file <a class="el" href="fast__tanh_8c_source.html">fast_tanh.c</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   55</span>                                                        {</div>
<div class="line"><span class="lineno">   56</span>  <span class="keywordflow">if</span> (!v || n == 0) <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">   57</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">fast_tanh</a>) {</div>
<div class="line"><span class="lineno">   58</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a> = 0; <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a> &lt; n; ++<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a>) {</div>
<div class="line"><span class="lineno">   59</span>      v[<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a>] = <a class="code hl_function" href="fast__tanh_8c.html#a2b9a073aea2b6ff7450b2d0ee32765ae">ie_fast_tanhf</a>(v[<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a>]);</div>
<div class="line"><span class="lineno">   60</span>    }</div>
<div class="line"><span class="lineno">   61</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno">   62</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a> = 0; <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a> &lt; n; ++<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a>) {</div>
<div class="line"><span class="lineno">   63</span>      <span class="keywordtype">float</span> <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">tanhf</a>(v[<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a>]);</div>
<div class="line"><span class="lineno">   64</span>      <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> &gt; 1.0f)  <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> = 1.0f;</div>
<div class="line"><span class="lineno">   65</span>      <span class="keywordflow">if</span> (<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> &lt; -1.0f) <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a> = -1.0f;</div>
<div class="line"><span class="lineno">   66</span>      v[<a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">i</a>] = <a class="code hl_function" href="ie__kernels__cuda_8cu.html#af00402674d56c833c92c62df1cef1e84">y</a>;</div>
<div class="line"><span class="lineno">   67</span>    }</div>
<div class="line"><span class="lineno">   68</span>  }</div>
<div class="line"><span class="lineno">   69</span>}</div>
<div class="ttc" id="afast__tanh_8c_html_a2b9a073aea2b6ff7450b2d0ee32765ae"><div class="ttname"><a href="fast__tanh_8c.html#a2b9a073aea2b6ff7450b2d0ee32765ae">ie_fast_tanhf</a></div><div class="ttdeci">float ie_fast_tanhf(float x)</div><div class="ttdoc">Fast approximation of hyperbolic tangent with hard clamping.</div><div class="ttdef"><b>Definition</b> <a href="fast__tanh_8c_source.html#l00028">fast_tanh.c:28</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="fast__tanh_8c_source.html#l00028">ie_fast_tanhf()</a>.</p>

<p class="reference">Referenced by <a class="el" href="test__math_8c_source.html#l00012">main()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 9 --></div>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 10 --></div>
</div>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_996f45160da62e1a3d7f6046fad68f51.html">engine</a></li><li class="navelem"><a class="el" href="dir_bafa501d493553e442f19f5f8dd7b29c.html">include</a></li><li class="navelem"><a class="el" href="ie__kernels_8h.html">ie_kernels.h</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
