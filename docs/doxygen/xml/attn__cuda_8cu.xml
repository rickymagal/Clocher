<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.8" xml:lang="en-US">
  <compounddef id="attn__cuda_8cu" kind="file" language="C++">
    <compoundname>attn_cuda.cu</compoundname>
    <includes local="no">cuda_runtime.h</includes>
    <includes local="no">math.h</includes>
    <includes local="no">stddef.h</includes>
    <includes local="no">stdint.h</includes>
    <incdepgraph>
      <node id="1">
        <label>engine/src/kernels/attn_cuda.cu</label>
        <link refid="attn__cuda_8cu"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="5" relation="include">
        </childnode>
      </node>
      <node id="2">
        <label>cuda_runtime.h</label>
      </node>
      <node id="3">
        <label>math.h</label>
      </node>
      <node id="4">
        <label>stddef.h</label>
      </node>
      <node id="5">
        <label>stdint.h</label>
      </node>
    </incdepgraph>
    <sectiondef kind="func">
      <memberdef kind="function" id="attn__cuda_8cu_1aa54b571e93693798ba4e7e1d7c71553e" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__device__ __forceinline__ size_t</type>
        <definition>static __device__ __forceinline__ size_t kv_index</definition>
        <argsstring>(size_t t, size_t h, size_t d, size_t H, size_t D)</argsstring>
        <name>kv_index</name>
        <param>
          <type>size_t</type>
          <declname>t</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>h</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>d</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>H</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>D</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/attn_cuda.cu" line="25" column="42" bodyfile="engine/src/kernels/attn_cuda.cu" bodystart="25" bodyend="27"/>
        <referencedby refid="attn__cuda_8cu_1a5f970763739ce761cfa55f94506e91b0" compoundref="attn__cuda_8cu" startline="86" endline="132">ie_attn_causal_f32_kernel</referencedby>
      </memberdef>
      <memberdef kind="function" id="attn__cuda_8cu_1acda759a4b725a3d6d2d57c215d7a84e6" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__device__ __forceinline__ float</type>
        <definition>static __device__ __forceinline__ float warp_reduce_max</definition>
        <argsstring>(float v)</argsstring>
        <name>warp_reduce_max</name>
        <param>
          <type>float</type>
          <declname>v</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/attn_cuda.cu" line="29" column="41" bodyfile="engine/src/kernels/attn_cuda.cu" bodystart="29" bodyend="35"/>
        <referencedby refid="attn__cuda_8cu_1aa89eec1d23b5d9762de86583310cb4ea" compoundref="attn__cuda_8cu" startline="44" endline="59">block_reduce_max</referencedby>
      </memberdef>
      <memberdef kind="function" id="attn__cuda_8cu_1ade2f7a48733cc2c3c509249724e2010d" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__device__ __forceinline__ float</type>
        <definition>static __device__ __forceinline__ float warp_reduce_sum</definition>
        <argsstring>(float v)</argsstring>
        <name>warp_reduce_sum</name>
        <param>
          <type>float</type>
          <declname>v</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/attn_cuda.cu" line="37" column="41" bodyfile="engine/src/kernels/attn_cuda.cu" bodystart="37" bodyend="42"/>
        <referencedby refid="attn__cuda_8cu_1ad9a2bec6c9690ab4c03b5239b4c0b5e5" compoundref="attn__cuda_8cu" startline="61" endline="76">block_reduce_sum</referencedby>
      </memberdef>
      <memberdef kind="function" id="attn__cuda_8cu_1aa89eec1d23b5d9762de86583310cb4ea" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__device__ __forceinline__ float</type>
        <definition>static __device__ __forceinline__ float block_reduce_max</definition>
        <argsstring>(float v)</argsstring>
        <name>block_reduce_max</name>
        <param>
          <type>float</type>
          <declname>v</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/attn_cuda.cu" line="44" column="41" bodyfile="engine/src/kernels/attn_cuda.cu" bodystart="44" bodyend="59"/>
        <references refid="attn__cuda_8cu_1acda759a4b725a3d6d2d57c215d7a84e6" compoundref="attn__cuda_8cu" startline="29" endline="35">warp_reduce_max</references>
        <referencedby refid="attn__cuda_8cu_1a5f970763739ce761cfa55f94506e91b0" compoundref="attn__cuda_8cu" startline="86" endline="132">ie_attn_causal_f32_kernel</referencedby>
      </memberdef>
      <memberdef kind="function" id="attn__cuda_8cu_1ad9a2bec6c9690ab4c03b5239b4c0b5e5" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__device__ __forceinline__ float</type>
        <definition>static __device__ __forceinline__ float block_reduce_sum</definition>
        <argsstring>(float v)</argsstring>
        <name>block_reduce_sum</name>
        <param>
          <type>float</type>
          <declname>v</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/attn_cuda.cu" line="61" column="41" bodyfile="engine/src/kernels/attn_cuda.cu" bodystart="61" bodyend="76"/>
        <references refid="attn__cuda_8cu_1ade2f7a48733cc2c3c509249724e2010d" compoundref="attn__cuda_8cu" startline="37" endline="42">warp_reduce_sum</references>
        <referencedby refid="attn__cuda_8cu_1a5f970763739ce761cfa55f94506e91b0" compoundref="attn__cuda_8cu" startline="86" endline="132">ie_attn_causal_f32_kernel</referencedby>
      </memberdef>
      <memberdef kind="function" id="attn__cuda_8cu_1a5f970763739ce761cfa55f94506e91b0" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__global__ void</type>
        <definition>__global__ void ie_attn_causal_f32_kernel</definition>
        <argsstring>(const float *Q, const float *K, const float *V, size_t seq_len, size_t heads, size_t head_dim, float inv_sqrt_d, float *out)</argsstring>
        <name>ie_attn_causal_f32_kernel</name>
        <param>
          <type>const float *</type>
          <declname>Q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>K</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>V</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>seq_len</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>heads</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>float</type>
          <declname>inv_sqrt_d</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>out</declname>
        </param>
        <briefdescription>
<para>One block per head. </para>
        </briefdescription>
        <detaileddescription>
<para>Threads cooperate over tokens t in [0, seq_len). Three passes: 1) max score 2) sum exp(score-max) 3) accumulate weighted V </para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/attn_cuda.cu" line="86" column="17" bodyfile="engine/src/kernels/attn_cuda.cu" bodystart="86" bodyend="132"/>
        <references refid="attn__cuda_8cu_1aa89eec1d23b5d9762de86583310cb4ea" compoundref="attn__cuda_8cu" startline="44" endline="59">block_reduce_max</references>
        <references refid="attn__cuda_8cu_1ad9a2bec6c9690ab4c03b5239b4c0b5e5" compoundref="attn__cuda_8cu" startline="61" endline="76">block_reduce_sum</references>
        <references refid="attn__cuda_8cu_1aa54b571e93693798ba4e7e1d7c71553e" compoundref="attn__cuda_8cu" startline="25" endline="27">kv_index</references>
      </memberdef>
      <memberdef kind="function" id="attn__cuda_8cu_1af8431ab0e10f324ffdb2d3240b12144a" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>int</type>
        <definition>int ie_attn_cuda_causal_f32</definition>
        <argsstring>(const float *Q, const float *K, const float *V, size_t seq_len, size_t heads, size_t head_dim, float inv_sqrt_d, float *out)</argsstring>
        <name>ie_attn_cuda_causal_f32</name>
        <param>
          <type>const float *</type>
          <declname>Q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>K</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>V</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>seq_len</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>heads</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>float</type>
          <declname>inv_sqrt_d</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>out</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/attn_cuda.cu" line="134" column="16" bodyfile="engine/src/kernels/attn_cuda.cu" bodystart="134" bodyend="154"/>
      </memberdef>
    </sectiondef>
    <briefdescription>
<para>Reference CUDA attention kernel (FP32) for causal self-attention. </para>
    </briefdescription>
    <detaileddescription>
<para>Computes, per head: scores[t] = dot(Q[h,:], K[t,h,:]) * inv_sqrt_d out[h,:] = sum_t softmax(scores)[t] * V[t,h,:]</para>
<para>Layout for Q/out: [heads, head_dim] Layout for K/V cache: [seq_len, heads, head_dim] flattened with head_dim fastest: index(t,h,d) = ((t * heads + h) * head_dim + d)</para>
<para>This is a correctness-first implementation for a single-step decode attention. </para>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="comment">/*<sp/>============================================================================</highlight></codeline>
<codeline lineno="2"><highlight class="comment"><sp/>*<sp/>File:<sp/>engine/src/kernels/attn_cuda.cu</highlight></codeline>
<codeline lineno="3"><highlight class="comment"><sp/>*<sp/>============================================================================</highlight></codeline>
<codeline lineno="4"><highlight class="comment"><sp/>*/</highlight></codeline>
<codeline lineno="20"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;cuda_runtime.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="21"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;math.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stddef.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="23"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stdint.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="24"><highlight class="normal"></highlight></codeline>
<codeline lineno="25" refid="attn__cuda_8cu_1aa54b571e93693798ba4e7e1d7c71553e" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>__device__<sp/>__forceinline__<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/><ref refid="attn__cuda_8cu_1aa54b571e93693798ba4e7e1d7c71553e" kindref="member">kv_index</ref>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>t,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>h,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>H,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>D)<sp/>{</highlight></codeline>
<codeline lineno="26"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>((t<sp/>*<sp/>H)<sp/>+<sp/>h)<sp/>*<sp/>D<sp/>+<sp/>d;</highlight></codeline>
<codeline lineno="27"><highlight class="normal">}</highlight></codeline>
<codeline lineno="28"><highlight class="normal"></highlight></codeline>
<codeline lineno="29" refid="attn__cuda_8cu_1acda759a4b725a3d6d2d57c215d7a84e6" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>__device__<sp/>__forceinline__<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/><ref refid="attn__cuda_8cu_1acda759a4b725a3d6d2d57c215d7a84e6" kindref="member">warp_reduce_max</ref>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>v)<sp/>{</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>offset<sp/>=<sp/>16;<sp/>offset<sp/>&gt;<sp/>0;<sp/>offset<sp/>&gt;&gt;=<sp/>1)<sp/>{</highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>o<sp/>=<sp/>__shfl_down_sync(0xFFFFFFFFu,<sp/>v,<sp/>offset);</highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/><sp/><sp/>v<sp/>=<sp/>fmaxf(v,<sp/>o);</highlight></codeline>
<codeline lineno="33"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="34"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>v;</highlight></codeline>
<codeline lineno="35"><highlight class="normal">}</highlight></codeline>
<codeline lineno="36"><highlight class="normal"></highlight></codeline>
<codeline lineno="37" refid="attn__cuda_8cu_1ade2f7a48733cc2c3c509249724e2010d" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>__device__<sp/>__forceinline__<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/><ref refid="attn__cuda_8cu_1ade2f7a48733cc2c3c509249724e2010d" kindref="member">warp_reduce_sum</ref>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>v)<sp/>{</highlight></codeline>
<codeline lineno="38"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>offset<sp/>=<sp/>16;<sp/>offset<sp/>&gt;<sp/>0;<sp/>offset<sp/>&gt;&gt;=<sp/>1)<sp/>{</highlight></codeline>
<codeline lineno="39"><highlight class="normal"><sp/><sp/><sp/><sp/>v<sp/>+=<sp/>__shfl_down_sync(0xFFFFFFFFu,<sp/>v,<sp/>offset);</highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="41"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>v;</highlight></codeline>
<codeline lineno="42"><highlight class="normal">}</highlight></codeline>
<codeline lineno="43"><highlight class="normal"></highlight></codeline>
<codeline lineno="44" refid="attn__cuda_8cu_1aa89eec1d23b5d9762de86583310cb4ea" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>__device__<sp/>__forceinline__<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/><ref refid="attn__cuda_8cu_1aa89eec1d23b5d9762de86583310cb4ea" kindref="member">block_reduce_max</ref>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>v)<sp/>{</highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/>__shared__<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>smem[32];</highlight></codeline>
<codeline lineno="46"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>lane<sp/>=<sp/>threadIdx.x<sp/>&amp;<sp/>31;</highlight></codeline>
<codeline lineno="47"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>wid<sp/><sp/>=<sp/>threadIdx.x<sp/>&gt;&gt;<sp/>5;</highlight></codeline>
<codeline lineno="48"><highlight class="normal"></highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/>v<sp/>=<sp/><ref refid="attn__cuda_8cu_1acda759a4b725a3d6d2d57c215d7a84e6" kindref="member">warp_reduce_max</ref>(v);</highlight></codeline>
<codeline lineno="50"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(lane<sp/>==<sp/>0)<sp/>smem[wid]<sp/>=<sp/>v;</highlight></codeline>
<codeline lineno="51"><highlight class="normal"><sp/><sp/>__syncthreads();</highlight></codeline>
<codeline lineno="52"><highlight class="normal"></highlight></codeline>
<codeline lineno="53"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>out<sp/>=<sp/>-INFINITY;</highlight></codeline>
<codeline lineno="54"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(wid<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/><sp/><sp/>out<sp/>=<sp/>(threadIdx.x<sp/>&lt;<sp/>(blockDim.x<sp/>+<sp/>31)<sp/>/<sp/>32)<sp/>?<sp/>smem[lane]<sp/>:<sp/>-INFINITY;</highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/><sp/><sp/>out<sp/>=<sp/><ref refid="attn__cuda_8cu_1acda759a4b725a3d6d2d57c215d7a84e6" kindref="member">warp_reduce_max</ref>(out);</highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="58"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>__shfl_sync(0xFFFFFFFFu,<sp/>out,<sp/>0);</highlight></codeline>
<codeline lineno="59"><highlight class="normal">}</highlight></codeline>
<codeline lineno="60"><highlight class="normal"></highlight></codeline>
<codeline lineno="61" refid="attn__cuda_8cu_1ad9a2bec6c9690ab4c03b5239b4c0b5e5" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>__device__<sp/>__forceinline__<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/><ref refid="attn__cuda_8cu_1ad9a2bec6c9690ab4c03b5239b4c0b5e5" kindref="member">block_reduce_sum</ref>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>v)<sp/>{</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/>__shared__<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>smem[32];</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>lane<sp/>=<sp/>threadIdx.x<sp/>&amp;<sp/>31;</highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>wid<sp/><sp/>=<sp/>threadIdx.x<sp/>&gt;&gt;<sp/>5;</highlight></codeline>
<codeline lineno="65"><highlight class="normal"></highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/>v<sp/>=<sp/><ref refid="attn__cuda_8cu_1ade2f7a48733cc2c3c509249724e2010d" kindref="member">warp_reduce_sum</ref>(v);</highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(lane<sp/>==<sp/>0)<sp/>smem[wid]<sp/>=<sp/>v;</highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/>__syncthreads();</highlight></codeline>
<codeline lineno="69"><highlight class="normal"></highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>out<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(wid<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/>out<sp/>=<sp/>(threadIdx.x<sp/>&lt;<sp/>(blockDim.x<sp/>+<sp/>31)<sp/>/<sp/>32)<sp/>?<sp/>smem[lane]<sp/>:<sp/>0.0f;</highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/><sp/><sp/>out<sp/>=<sp/><ref refid="attn__cuda_8cu_1ade2f7a48733cc2c3c509249724e2010d" kindref="member">warp_reduce_sum</ref>(out);</highlight></codeline>
<codeline lineno="74"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>__shfl_sync(0xFFFFFFFFu,<sp/>out,<sp/>0);</highlight></codeline>
<codeline lineno="76"><highlight class="normal">}</highlight></codeline>
<codeline lineno="77"><highlight class="normal"></highlight></codeline>
<codeline lineno="86" refid="attn__cuda_8cu_1a5f970763739ce761cfa55f94506e91b0" refkind="member"><highlight class="normal">__global__<sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attn__cuda_8cu_1a5f970763739ce761cfa55f94506e91b0" kindref="member">ie_attn_causal_f32_kernel</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*Q,</highlight></codeline>
<codeline lineno="87"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*K,</highlight></codeline>
<codeline lineno="88"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*V,</highlight></codeline>
<codeline lineno="89"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>seq_len,</highlight></codeline>
<codeline lineno="90"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>heads,</highlight></codeline>
<codeline lineno="91"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="92"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>inv_sqrt_d,</highlight></codeline>
<codeline lineno="93"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out)<sp/>{</highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>(size_t)blockIdx.x;</highlight></codeline>
<codeline lineno="95"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(h<sp/>&gt;=<sp/>heads)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="96"><highlight class="normal"></highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*Qh<sp/>=<sp/>Q<sp/>+<sp/>h<sp/>*<sp/>head_dim;</highlight></codeline>
<codeline lineno="98"><highlight class="normal"></highlight></codeline>
<codeline lineno="99"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>local_max<sp/>=<sp/>-INFINITY;</highlight></codeline>
<codeline lineno="100"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>t<sp/>=<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threadIdx.x;<sp/>t<sp/>&lt;<sp/>seq_len;<sp/>t<sp/>+=<sp/>(size_t)blockDim.x)<sp/>{</highlight></codeline>
<codeline lineno="101"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*Kh<sp/>=<sp/>K<sp/>+<sp/><ref refid="attn__cuda_8cu_1aa54b571e93693798ba4e7e1d7c71553e" kindref="member">kv_index</ref>(t,<sp/>h,<sp/>0,<sp/>heads,<sp/>head_dim);</highlight></codeline>
<codeline lineno="102"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>acc<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="103"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>acc<sp/>+=<sp/>Qh[d]<sp/>*<sp/>Kh[d];</highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/>acc<sp/>*=<sp/>inv_sqrt_d;</highlight></codeline>
<codeline lineno="105"><highlight class="normal"><sp/><sp/><sp/><sp/>local_max<sp/>=<sp/>fmaxf(local_max,<sp/>acc);</highlight></codeline>
<codeline lineno="106"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>mx<sp/>=<sp/><ref refid="attn__cuda_8cu_1aa89eec1d23b5d9762de86583310cb4ea" kindref="member">block_reduce_max</ref>(local_max);</highlight></codeline>
<codeline lineno="108"><highlight class="normal"></highlight></codeline>
<codeline lineno="109"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>local_sum<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="110"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>t<sp/>=<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threadIdx.x;<sp/>t<sp/>&lt;<sp/>seq_len;<sp/>t<sp/>+=<sp/>(size_t)blockDim.x)<sp/>{</highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*Kh<sp/>=<sp/>K<sp/>+<sp/><ref refid="attn__cuda_8cu_1aa54b571e93693798ba4e7e1d7c71553e" kindref="member">kv_index</ref>(t,<sp/>h,<sp/>0,<sp/>heads,<sp/>head_dim);</highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>acc<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="113"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>acc<sp/>+=<sp/>Qh[d]<sp/>*<sp/>Kh[d];</highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/><sp/><sp/>acc<sp/>*=<sp/>inv_sqrt_d;</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/>local_sum<sp/>+=<sp/>expf(acc<sp/>-<sp/>mx);</highlight></codeline>
<codeline lineno="116"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="117"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>denom<sp/>=<sp/><ref refid="attn__cuda_8cu_1ad9a2bec6c9690ab4c03b5239b4c0b5e5" kindref="member">block_reduce_sum</ref>(local_sum);</highlight></codeline>
<codeline lineno="118"><highlight class="normal"></highlight></codeline>
<codeline lineno="119"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threadIdx.x;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>d<sp/>+=<sp/>(size_t)blockDim.x)<sp/>{</highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>acc_out<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>t<sp/>=<sp/>0;<sp/>t<sp/>&lt;<sp/>seq_len;<sp/>++t)<sp/>{</highlight></codeline>
<codeline lineno="122"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*Kh<sp/>=<sp/>K<sp/>+<sp/><ref refid="attn__cuda_8cu_1aa54b571e93693798ba4e7e1d7c71553e" kindref="member">kv_index</ref>(t,<sp/>h,<sp/>0,<sp/>heads,<sp/>head_dim);</highlight></codeline>
<codeline lineno="123"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>s<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="124"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;<sp/>head_dim;<sp/>++j)<sp/>s<sp/>+=<sp/>Qh[j]<sp/>*<sp/>Kh[j];</highlight></codeline>
<codeline lineno="125"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>*=<sp/>inv_sqrt_d;</highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/>(denom<sp/>&gt;<sp/>0.0f)<sp/>?<sp/>(expf(s<sp/>-<sp/>mx)<sp/>/<sp/>denom)<sp/>:<sp/>(1.0f<sp/>/<sp/>(float)seq_len);</highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*Vh<sp/>=<sp/>V<sp/>+<sp/><ref refid="attn__cuda_8cu_1aa54b571e93693798ba4e7e1d7c71553e" kindref="member">kv_index</ref>(t,<sp/>h,<sp/>0,<sp/>heads,<sp/>head_dim);</highlight></codeline>
<codeline lineno="128"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>acc_out<sp/>+=<sp/>w<sp/>*<sp/>Vh[d];</highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/>out[h<sp/>*<sp/>head_dim<sp/>+<sp/>d]<sp/>=<sp/>acc_out;</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="132"><highlight class="normal">}</highlight></codeline>
<codeline lineno="133"><highlight class="normal"></highlight></codeline>
<codeline lineno="134" refid="attn__cuda_8cu_1af8431ab0e10f324ffdb2d3240b12144a" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">extern</highlight><highlight class="normal"><sp/></highlight><highlight class="stringliteral">&quot;C&quot;</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/><ref refid="attn__cuda_8cu_1af8431ab0e10f324ffdb2d3240b12144a" kindref="member">ie_attn_cuda_causal_f32</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*Q,</highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*K,</highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*V,</highlight></codeline>
<codeline lineno="137"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>seq_len,</highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>heads,</highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="140"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>inv_sqrt_d,</highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out)<sp/>{</highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!Q<sp/>||<sp/>!K<sp/>||<sp/>!V<sp/>||<sp/>!out)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-1;</highlight></codeline>
<codeline lineno="143"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(seq_len<sp/>==<sp/>0<sp/>||<sp/>heads<sp/>==<sp/>0<sp/>||<sp/>head_dim<sp/>==<sp/>0)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-1;</highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(inv_sqrt_d<sp/>==<sp/>0.0f)<sp/>inv_sqrt_d<sp/>=<sp/>1.0f;</highlight></codeline>
<codeline lineno="145"><highlight class="normal"></highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>threads<sp/>=<sp/>256;</highlight></codeline>
<codeline lineno="147"><highlight class="normal"><sp/><sp/>dim3<sp/>grid((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)heads,<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="148"><highlight class="normal"><sp/><sp/>dim3<sp/>block((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)threads,<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="149"><highlight class="normal"></highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/>ie_attn_causal_f32_kernel&lt;&lt;&lt;grid,<sp/>block,<sp/>0,<sp/>0&gt;&gt;&gt;(Q,<sp/>K,<sp/>V,<sp/>seq_len,<sp/>heads,<sp/>head_dim,<sp/>inv_sqrt_d,<sp/>out);</highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/>cudaError_t<sp/>e<sp/>=<sp/>cudaGetLastError();</highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(e<sp/>!=<sp/>cudaSuccess)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-2;</highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>0;</highlight></codeline>
<codeline lineno="154"><highlight class="normal">}</highlight></codeline>
    </programlisting>
    <location file="engine/src/kernels/attn_cuda.cu"/>
  </compounddef>
</doxygen>
