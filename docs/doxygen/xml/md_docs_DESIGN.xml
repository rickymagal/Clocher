<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.1" xml:lang="en-US">
  <compounddef id="md_docs_DESIGN" kind="page">
    <compoundname>md_docs_DESIGN</compoundname>
    <title>Design (CPU baseline + INT4 path)</title>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para>This document describes the hot path, API boundaries, and precision modes. <linebreak/>
 <bold>Last updated:</bold> 2025-10-24 21:00:48 UTC</para>
<sect1 id="md_docs_DESIGN_1autotoc_md27">
<title>Process and boundaries</title>
<para><itemizedlist>
<listitem><para>Single binary <computeroutput>inference-engine</computeroutput>: create → generate → collect metrics → destroy.</para>
</listitem><listitem><para>CLI prints exactly one JSON line per run so the Python harness can ingest results.</para>
</listitem><listitem><para>No third‑party runtime dependencies; only <computeroutput>pthread</computeroutput> and <computeroutput>libm</computeroutput> (and CUDA for the GPU build).</para>
</listitem></itemizedlist>
</para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md29">
<title>API surface (high level)</title>
<para><itemizedlist>
<listitem><para><computeroutput>ie_engine_create(cfg)</computeroutput> → initializes state (weights, buffers, thread‑pool).</para>
</listitem><listitem><para><computeroutput>ie_engine_generate(prompt, max_new, params)</computeroutput> → produces tokens and updates metrics rings.</para>
</listitem><listitem><para><computeroutput>ie_engine_metrics(out)</computeroutput> → returns latency p50/p95, true TPS, <bold>RSS peak</bold>, KV hits/misses.</para>
</listitem><listitem><para><computeroutput><ref refid="ie__api_8h_1a8a724f7097b3e19da8d7dd97fba4415e" kindref="member">ie_engine_destroy()</ref></computeroutput> → frees all resources.</para>
</listitem></itemizedlist>
</para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md32">
<title>Hot path layout</title>
<para><itemizedlist>
<listitem><para>GEMV microkernel:<itemizedlist>
<listitem><para>Generic scalar reference implementation.</para>
</listitem><listitem><para>AVX2/FMA path with light prefetch and blocked‑K packing.</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Activation:<itemizedlist>
<listitem><para><computeroutput>tanh</computeroutput> fast path with clamp (accuracy‑bounded), vector helper.</para>
</listitem><listitem><para>Optional fused bias + activation to reduce memory traffic.</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md33">
<title>Precision modes</title>
<sect2 id="md_docs_DESIGN_1autotoc_md34">
<title>Floating point</title>
<para><itemizedlist>
<listitem><para>FP32 baseline, optional BF16/FP16 round‑trip (accumulate FP32).</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md35">
<title>INT8 PTQ (reference)</title>
<para><itemizedlist>
<listitem><para>Per‑tensor/per‑row scales (min‑max); (de)quant helpers; task gate in scripts.</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md36">
<title>&lt;strong&gt;NEW — INT4 PTQ (weight‑only)&lt;/strong&gt;</title>
<para><itemizedlist>
<listitem><para><bold>Format</bold>: weights are <bold>nibble‑packed</bold> (2 values per byte). Each row (or group) carries a scale (and optional zero‑point if affine).</para>
</listitem><listitem><para><bold>Packing</bold>: INT4 packing integrates with the existing <bold>pretranspose / blocked‑K</bold> pipeline. Packing order: float → (optional) pretranspose → quantize to int4 → pack.</para>
</listitem><listitem><para><bold>Dequantization</bold>: fused in the matmul path; scale is broadcast per row (or group) to recover FP32 accumulators.</para>
</listitem><listitem><para><bold>Manifests</bold>: a <computeroutput>q4_manifest.json</computeroutput> enumerates which tensors use INT4 and their scale metadata. <computeroutput><ref refid="hf__to__iebin_8py" kindref="compound">scripts/hf_to_iebin.py</ref></computeroutput> consumes this manifest via <computeroutput>--q4-map</computeroutput> to emit <computeroutput>model.ie.bin</computeroutput>/<computeroutput>.json</computeroutput>.</para>
</listitem><listitem><para><bold>Selection</bold>: at runtime choose <computeroutput>IE_PRECISION=int4w</computeroutput> (or <computeroutput>--precision int4w</computeroutput>), leaving activations in float. This is <bold>bandwidth‑oriented</bold> and preserves compute simplicity.</para>
</listitem></itemizedlist>
</para>
</sect2>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md37">
<title>Threading model</title>
<para><itemizedlist>
<listitem><para>Fixed thread‑pool over <computeroutput>pthread</computeroutput>, contiguous sharding, grainsize control.</para>
</listitem><listitem><para>Affinity (Linux): <computeroutput>IE_TP_USE_AFFINITY=1</computeroutput> enables <computeroutput>auto|compact|scatter</computeroutput>.</para>
</listitem><listitem><para>NUMA:<itemizedlist>
<listitem><para><computeroutput><ref refid="set__numa_8sh" kindref="compound">scripts/set_numa.sh</ref></computeroutput> can set OS policy (<computeroutput>interleave|node:X|strict</computeroutput>).</para>
</listitem><listitem><para>In‑repo probe reads <computeroutput>/sys/devices/system/node/online</computeroutput> to annotate reports.</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md38">
<title>Layout and caching</title>
<para><itemizedlist>
<listitem><para>Blocked‑K packing with optional on‑disk caching (content‑addressed by shape + block size).</para>
</listitem><listitem><para>CLI flag <computeroutput>--pretranspose</computeroutput> controls packing scope (<computeroutput>none|woh|wxh|all</computeroutput>). INT4 can be cached per layout variant.</para>
</listitem></itemizedlist>
</para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md39">
<title>Metrics</title>
<para><itemizedlist>
<listitem><para>Per‑token latency ring (p50/p95).</para>
</listitem><listitem><para>True TPS (<computeroutput>generated_tokens / wall_time_s</computeroutput>).</para>
</listitem><listitem><para><bold>Peak RSS</bold> (Linux <computeroutput>/proc/self/status:VmHWM</computeroutput> → MiB; fallback <computeroutput>getrusage</computeroutput>).</para>
</listitem><listitem><para>KV hits/misses counter stubs aggregated per round.</para>
</listitem></itemizedlist>
</para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md40">
<title>GPU integration (CUDA path)</title>
<para><itemizedlist>
<listitem><para>Device layer: <computeroutput><ref refid="ie__device__cuda_8cu" kindref="compound">engine/src/devices/ie_device_cuda.cu</ref></computeroutput>, kernels in <computeroutput><ref refid="ie__kernels__cuda_8cu" kindref="compound">engine/src/kernels/ie_kernels_cuda.cu</ref></computeroutput>.</para>
</listitem><listitem><para>Build: <computeroutput>make build-cuda</computeroutput> → <computeroutput>build/inference-engine.cuda</computeroutput>.</para>
</listitem><listitem><para>INT4 weight‑only support mirrors the CPU path; packing and scales are shared in <computeroutput>model.ie.json</computeroutput>.</para>
</listitem></itemizedlist>
</para>
<para><hruler/>
 </para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md42">
<title>INT4 Weight-Only Path — Design Addendum (2025-10-24 21:04:23 UTC)</title>
<sect2 id="md_docs_DESIGN_1autotoc_md43">
<title>Goals</title>
<para><itemizedlist>
<listitem><para>Introduce an <bold>optional</bold> path for <emphasis>weight-only</emphasis> INT4 (<computeroutput>int4w</computeroutput>) that: 1) Packs HF weights into IEBIN using a <bold>manifest-driven</bold> policy. 2) Leaves tokenization, shapes, and scheduling untouched. 3) Preserves benchmark comparability via <emphasis>work-touch</emphasis> instrumentation.</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md44">
<title>Design Choices</title>
<para><itemizedlist>
<listitem><para><bold>Manifest-driven packing</bold>: <computeroutput>--q4-map</computeroutput> lets us target only GEMV-heavy matrices (attn/MLP projections) and keep sensitive tensors (embeddings, layernorms) in FP formats.</para>
</listitem><listitem><para><bold>Separation of concerns</bold>:<itemizedlist>
<listitem><para>Storage precision (<computeroutput>IE_PRECISION</computeroutput>) is passed through <computeroutput><ref refid="structie__engine__params_1a92b02bad12cb4e8173728311c00960b7" kindref="member">ie_engine_params_t::precision</ref></computeroutput> untouched.</para>
</listitem><listitem><para>Host math precision (FP32/BF16/FP16) remains a separate selection.</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para><bold>Compat with harness</bold>: The CLI accepts soft hints (<computeroutput>--device</computeroutput>, <computeroutput>--model-dir</computeroutput>, <computeroutput>--rounds</computeroutput>) so existing scripts don’t break.</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md45">
<title>Data Flow (INT4 path)</title>
<para>HF shards → <computeroutput><ref refid="hf__to__iebin_8py" kindref="compound">hf_to_iebin.py</ref> --q4-map</computeroutput> → IEBIN (<computeroutput>model.ie.json</computeroutput> + <computeroutput>model.ie.bin</computeroutput> with INT4-packed tensors) → Runtime <computeroutput>IE_PRECISION=int4w</computeroutput> → GEMV kernels read packed weights (or dequant on load), semantics unchanged.</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md46">
<title>Metrics Integrity</title>
<para><itemizedlist>
<listitem><para>The timed window is <bold>only</bold>: <computeroutput>ie_engine_generate(...)</computeroutput> + optional <emphasis>work-touch</emphasis> loop.</para>
</listitem><listitem><para>RSS peak and KV counters are sampled <bold>after</bold> the window to avoid skewing TPS.</para>
</listitem></itemizedlist>
</para>
<para><hruler/>
</para>
</sect2>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md48">
<title>Appendix — INT4 (Weight‑Only) Step (Summary)</title>
<para><itemizedlist>
<listitem><para>Convert HF shards → IEBIN with an INT4 manifest: <programlisting filename=".bash"><codeline><highlight class="normal">python3<sp/>scripts/hf_to_iebin.py<sp/><sp/><sp/><sp/><sp/>--hf-dir<sp/>models/gpt-oss-20b/hf<sp/><sp/><sp/><sp/><sp/>--out-dir<sp/>models/gpt-oss-20b<sp/><sp/><sp/><sp/><sp/>--q4-map<sp/>quant/q4_manifest.json</highlight></codeline>
</programlisting></para>
</listitem><listitem><para>Run benchmarks in strict mode with a <bold>64 MB/token</bold> work‑touch: <programlisting filename=".bash"><codeline><highlight class="normal">PROMPTS=benchmarks/prompts_10..txt<sp/><sp/><sp/>IE_PRECISION=int4w<sp/>IE_REQUIRE_MODEL=1<sp/><sp/><sp/>IE_BYTES_PER_TOKEN=64000000<sp/>IE_STRIDE_BYTES=256<sp/>RUNS=3<sp/><sp/><sp/>make<sp/>bench<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>#<sp/>or:<sp/>make<sp/>bench-cuda</highlight></codeline>
</programlisting></para>
</listitem><listitem><para>Precision hints: <computeroutput>PRECISION=fp32</computeroutput> (activates float path) and <computeroutput>IE_PRECISION=int4w</computeroutput> (weight‑only path).</para>
</listitem></itemizedlist>
</para>
<para><hruler/>
 </para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md50">
<title>Updates — 2025-11-10</title>
<sect2 id="md_docs_DESIGN_1autotoc_md51">
<title>NUMA‑aware topology (&lt;tt&gt;ie_topology&lt;/tt&gt;)</title>
<para><itemizedlist>
<listitem><para>Discovers sockets and CPUs from Linux sysfs and exposes a compact API:<itemizedlist>
<listitem><para><computeroutput>ie_topology_init/destroy</computeroutput> — lifetime.</para>
</listitem><listitem><para><computeroutput><ref refid="ie__topology_8h_1ae9fec2d245fb73d6c3e8e3cba38d4471" kindref="member">ie_topology_sockets()</ref></computeroutput> — number of sockets.</para>
</listitem><listitem><para><computeroutput>ie_topology_first_cpu_on_socket(s)</computeroutput> — first CPU index on socket <computeroutput>s</computeroutput> (for pinning).</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Integration:<itemizedlist>
<listitem><para>Thread‑pool honors <computeroutput>IE_TP_USE_AFFINITY=1</computeroutput> with <computeroutput>AFFINITY=auto|compact|scatter</computeroutput>.</para>
</listitem><listitem><para><computeroutput>ie_hot_replicate_by_socket(...)</computeroutput> uses topology for binding.</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md52">
<title>Hot weights replication</title>
<para><itemizedlist>
<listitem><para>For “hot” tensors (frequently touched), we can replicate pages <bold>per socket</bold> to reduce remote memory hits.</para>
</listitem><listitem><para>Implementation sketch:<itemizedlist>
<listitem><para><computeroutput>mmap</computeroutput> replica per socket → optional <computeroutput>madvise(..., MADV_WILLNEED)</computeroutput> → worker binding → socket‑local access.</para>
</listitem><listitem><para>Controlled by <computeroutput>IE_HOT_REPLICATE=1</computeroutput> and an optional cap <computeroutput>IE_HOT_REPL_LIMIT_MB</computeroutput>.</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Trade‑offs: additional memory; on single‑socket machines, the feature is a no‑op with negligible overhead.</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md53">
<title>Activation precision hint</title>
<para><itemizedlist>
<listitem><para>Runtime hint <computeroutput>IE_ACT_PREC=int8|fp8|fp16|bf16|fp32</computeroutput> allows experimenting with lower‑precision activations while <bold>keeping FP32 accumulators</bold>.</para>
</listitem><listitem><para>Weight precision remains independent (e.g., <computeroutput>IE_PRECISION=int4w</computeroutput> for nibble‑packed weights).</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md54">
<title>Timing discipline (unchanged semantics)</title>
<para><itemizedlist>
<listitem><para>The benchmark <bold>measured window</bold> contains only <computeroutput>ie_engine_generate(...)</computeroutput> + optional work‑touch loop.</para>
</listitem><listitem><para>All metrics collection (RSS, KV, JSON print) happens <bold>after</bold> the window.</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md55">
<title>Example configurations</title>
<para><itemizedlist>
<listitem><para>INT4 weights, FP8 activations, NUMA‑aware with hot replication (CPU): <programlisting filename=".bash"><codeline><highlight class="normal">export<sp/>IE_REQUIRE_MODEL=1<sp/>IE_PRECISION=int4w<sp/>IE_ACT_PREC=fp8</highlight></codeline>
<codeline><highlight class="normal">export<sp/>IE_BYTES_PER_TOKEN=$((64*1024*1024))<sp/>IE_STRIDE_BYTES=256<sp/>IE_VERIFY_TOUCH=1</highlight></codeline>
<codeline><highlight class="normal">export<sp/>IE_TP_USE_AFFINITY=1<sp/>AFFINITY=compact<sp/>IE_HOT_REPLICATE=1</highlight></codeline>
<codeline><highlight class="normal">PROMPTS=benchmarks/prompts_10..txt<sp/>RUNS=3<sp/>make<sp/>bench</highlight></codeline>
</programlisting></para>
</listitem><listitem><para>Same with CUDA: </para>
</listitem></itemizedlist>
</para>
</sect2>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md56">
<title>@code{bash}</title>
<para>PROMPTS=benchmarks/prompts_10..txt RUNS=3 make bench-cuda </para>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md57">
<title>Memory Phase Design Addendum (updated 2025-11-12 18:01:19 UTC)</title>
<sect2 id="md_docs_DESIGN_1autotoc_md58">
<title>Goals</title>
<para><orderedlist>
<listitem><para>Reduce <bold>DRAM traffic</bold> on weight fetch via layout (<computeroutput>blocked‑K</computeroutput>), NUMA locality, and selective non‑temporal loads.</para>
</listitem><listitem><para>Enable <bold>activation down‑precision</bold> (INT8/FP8) orthogonally to weight storage (e.g., INT4 weight‑only).</para>
</listitem><listitem><para>Measure and visualize <bold>spatial metrics</bold> alongside TPS: MB/token, bytes touched, model coverage, effective bandwidth.</para>
</listitem></orderedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md59">
<title>Components</title>
<para><itemizedlist>
<listitem><para>**Topology &amp; Binding (<computeroutput><ref refid="structie__topology" kindref="compound">ie_topology</ref></computeroutput>)**: discovers sockets/CPUs from Linux sysfs. Exposes helpers for pinning (compact/scatter).</para>
</listitem><listitem><para>**Hot replication (<computeroutput><ref refid="replicate__hot_8c" kindref="compound">replicate_hot.c</ref></computeroutput>)**: optional per‑socket replicas for frequently‑touched weights; uses <computeroutput>mmap</computeroutput> + <computeroutput>madvise</computeroutput>.</para>
</listitem><listitem><para><bold>Blocked‑K Pretranspose</bold>: builds and caches a row‑major, <bold>K‑blocked</bold> layout; improves sequentiality and prefetch efficacy.</para>
</listitem><listitem><para><bold>Streaming heuristics</bold>: <computeroutput>IE_PREFETCH_DISTANCE</computeroutput>, <computeroutput>IE_NT_LOADS</computeroutput>, and <computeroutput>IE_NT_RATIO</computeroutput> drive prefetch and non‑temporal load decisions.</para>
</listitem><listitem><para><bold>Activation precision</bold>: runtime hint <computeroutput>IE_ACT_PREC</computeroutput> selects decode path (INT8 per‑tensor/per‑group, FP8 E4M3/E5M2). Accumulation is FP32.</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md60">
<title>Measurement</title>
<para>The benchmark window includes <bold>generation</bold> and the <bold>work‑touch</bold> loop (controlled by <computeroutput>IE_BYTES_PER_TOKEN</computeroutput>, <computeroutput>IE_STRIDE_BYTES</computeroutput>). After the window, the engine samples <bold>peak RSS (VmHWM)</bold>. The docs generator now derives:<itemizedlist>
<listitem><para><bold>MB/token</bold> from <computeroutput>IE_BYTES_PER_TOKEN</computeroutput></para>
</listitem><listitem><para><bold>Total bytes touched</bold> = <computeroutput>tokens_sum * bytes_per_token</computeroutput></para>
</listitem><listitem><para><bold>Coverage</bold> = <computeroutput>bytes_per_token / size(model.ie.bin)</computeroutput></para>
</listitem><listitem><para><bold>Effective bandwidth</bold> = <computeroutput>bytes_touched / wall_time</computeroutput> (GB/s)</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md61">
<title>Backward Compatibility &amp; Fallbacks</title>
<para><itemizedlist>
<listitem><para>Single‑socket hosts: topology collapses to one socket; binding is a no‑op.</para>
</listitem><listitem><para>Unsupported backends ignore <computeroutput>IE_ACT_PREC</computeroutput>, <computeroutput>IE_NT_LOADS</computeroutput>, etc., without failing.</para>
</listitem><listitem><para>When <computeroutput>IE_REQUIRE_MODEL</computeroutput> is unset, CI stub mode continues to work (no mmap or spatial metrics).</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md62">
<title>Risks &amp; Mitigations</title>
<para><itemizedlist>
<listitem><para><bold>Over‑eager NT loads</bold> can hurt on small working sets → guard via <computeroutput>auto</computeroutput> heuristics and <computeroutput>IE_NT_RATIO</computeroutput> throttle.</para>
</listitem><listitem><para><bold>Replica memory cost</bold> on multi‑socket servers → gate with <computeroutput>IE_HOT_REPLICATE</computeroutput> and <computeroutput>IE_HOT_REPL_LIMIT_MB</computeroutput>.</para>
</listitem></itemizedlist>
</para>
</sect2>
</sect1>
<sect1 id="md_docs_DESIGN_1autotoc_md63">
<title>Block‑sparse weights (Phase 2, CPU only)</title>
<para>This chapter describes the <bold>block‑sparse weights prototype</bold> implemented in the second phase of the memory work. The goal is to make <emphasis>algorithmic sparsity</emphasis> concrete and measurable while keeping the dense engine and IEBIN format intact.</para>
<para>At this stage the implementation is <bold>CPU‑only</bold>, FP32‑only, and is exercised through C unit tests and a dedicated microbenchmark. It is deliberately small and self‑contained so that we can iterate on formats and policies without destabilizing the main inference path.</para>
<sect2 id="md_docs_DESIGN_1autotoc_md64">
<title>Goals</title>
<para><itemizedlist>
<listitem><para>Provide a <bold>well‑defined in‑memory descriptor</bold> for block‑sparse matrices (<computeroutput>ie_block_sparse_matrix_t</computeroutput>).</para>
</listitem><listitem><para>Define a <bold>compact on‑disk format</bold> that can be produced by a simple C tool (<computeroutput><ref refid="convert__to__block__sparse_8c" kindref="compound">tools/convert_to_block_sparse.c</ref></computeroutput>) and loaded by the engine.</para>
</listitem><listitem><para>Implement a <bold>reference GEMV kernel</bold> for block‑sparse matrices on CPU: numerically equivalent to dense GEMV (modulo FP roundoff).</para>
</listitem><listitem><para>Wire this into the device abstraction so that:<itemizedlist>
<listitem><para>the CPU backend can execute block‑sparse GEMV; and</para>
</listitem><listitem><para>other backends can safely report “unimplemented” and trigger a CPU fallback.</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Keep the feature fully <bold>opt‑in</bold>:<itemizedlist>
<listitem><para>No changes to <computeroutput>model.ie.bin</computeroutput> or the CLI.</para>
</listitem><listitem><para>No new runtime flags required for existing workflows.</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md65">
<title>In‑memory layout: &lt;tt&gt;ie_block_sparse_matrix_t&lt;/tt&gt;</title>
<para>The new public descriptor lives in <computeroutput><ref refid="sparse__format_8h" kindref="compound">engine/include/sparse_format.h</ref></computeroutput>:</para>
<para><itemizedlist>
<listitem><para>Global dimensions:<itemizedlist>
<listitem><para><computeroutput>rows</computeroutput>, <computeroutput>cols</computeroutput> — dense matrix shape.</para>
</listitem><listitem><para><computeroutput>block_rows</computeroutput>, <computeroutput>block_cols</computeroutput> — tile shape (same for all blocks).</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Block‑row CSR (BSR) structure:<itemizedlist>
<listitem><para><computeroutput>n_block_rows</computeroutput> — number of block rows (typically <computeroutput>ceil(rows / block_rows)</computeroutput>).</para>
</listitem><listitem><para><computeroutput>row_ptr</computeroutput> — length <computeroutput>n_block_rows + 1</computeroutput>; <computeroutput>row_ptr[br]..row_ptr[br+1]-1</computeroutput> indexes the non‑zero blocks (<computeroutput>nnzb</computeroutput> total).</para>
</listitem><listitem><para><computeroutput>col_idx</computeroutput> — length <computeroutput>nnzb</computeroutput>; column index in block coordinates (<computeroutput>0..ceil(cols / block_cols)-1</computeroutput>).</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Values:<itemizedlist>
<listitem><para><computeroutput>values</computeroutput> — contiguous FP32 array of length <computeroutput>nnzb * block_rows * block_cols</computeroutput>, stored in row‑major order <emphasis>within</emphasis> each block.</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>
<para>Semantics:</para>
<para><itemizedlist>
<listitem><para>Conceptually the matrix is partitioned into <computeroutput>block_rows x block_cols</computeroutput> tiles. For each block row <computeroutput>br</computeroutput> we list all non‑zero tiles in ascending block column order.</para>
</listitem><listitem><para>The actual dense dimensions are always taken from <computeroutput>rows</computeroutput> / <computeroutput>cols</computeroutput>. Tail blocks near the bottom/right edges are automatically clipped in the GEMV kernel.</para>
</listitem></itemizedlist>
</para>
<para>The helpers in <computeroutput><ref refid="sparse__format_8h" kindref="compound">sparse_format.h</ref></computeroutput> cover:</para>
<para><itemizedlist>
<listitem><para>sanity checks for header fields;</para>
</listitem><listitem><para>allocation/free helpers; and</para>
</listitem><listitem><para>small utilities to compute block counts and strides.</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md66">
<title>On‑disk format and loader (&lt;tt&gt;engine/src/sparse_io.c&lt;/tt&gt;)</title>
<para>To keep experiments reproducible without touching the IEBIN format, we use a separate, compact binary format for block‑sparse matrices:</para>
<para><itemizedlist>
<listitem><para>A fixed‑size header that records:<itemizedlist>
<listitem><para>magic / version;</para>
</listitem><listitem><para><computeroutput>rows</computeroutput>, <computeroutput>cols</computeroutput>, <computeroutput>block_rows</computeroutput>, <computeroutput>block_cols</computeroutput>;</para>
</listitem><listitem><para><computeroutput>n_block_rows</computeroutput>, <computeroutput>nnzb</computeroutput>;</para>
</listitem><listitem><para>sizes of the three payload arrays (<computeroutput>row_ptr</computeroutput>, <computeroutput>col_idx</computeroutput>, <computeroutput>values</computeroutput>).</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Payload sections, tightly packed:<orderedlist>
<listitem><para><computeroutput>row_ptr</computeroutput> (<computeroutput>uint32_t</computeroutput> × <computeroutput>n_block_rows + 1</computeroutput>);</para>
</listitem><listitem><para><computeroutput>col_idx</computeroutput> (<computeroutput>uint32_t</computeroutput> × <computeroutput>nnzb</computeroutput>);</para>
</listitem><listitem><para><computeroutput>values</computeroutput> (<computeroutput>float</computeroutput> × <computeroutput>nnzb * block_rows * block_cols</computeroutput>).</para>
</listitem></orderedlist>
</para>
</listitem></itemizedlist>
</para>
<para>The loader <computeroutput><ref refid="sparse__io_8c_1a3f5428268012e4d5e4e9d8a58c01a008" kindref="member">ie_block_sparse_load(const char *path, ie_block_sparse_matrix_t *out)</ref></computeroutput> performs:</para>
<para><orderedlist>
<listitem><para>open + read header;</para>
</listitem><listitem><para>validate fields (non‑zero dimensions, monotonically increasing <computeroutput>row_ptr</computeroutput>, etc.);</para>
</listitem><listitem><para>allocate arrays for <computeroutput>row_ptr</computeroutput>, <computeroutput>col_idx</computeroutput>, <computeroutput>values</computeroutput>;</para>
</listitem><listitem><para>read the three payload sections; and</para>
</listitem><listitem><para>on success, fill <computeroutput>out</computeroutput> with owned pointers and return <computeroutput>IE_SPARSE_OK</computeroutput>.</para>
</listitem></orderedlist>
</para>
<para>Error paths:</para>
<para><itemizedlist>
<listitem><para>Any structural or I/O error returns a specific <computeroutput>ie_sparse_status_t</computeroutput> (e.g. <computeroutput>IE_SPARSE_ERR_IO</computeroutput>, <computeroutput>IE_SPARSE_ERR_FORMAT</computeroutput>).</para>
</listitem><listitem><para>On error, partially allocated buffers are freed and <computeroutput>out</computeroutput> is zeroed.</para>
</listitem></itemizedlist>
</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md67">
<title>CPU kernel (&lt;tt&gt;engine/src/gemm_block_sparse.c&lt;/tt&gt;)</title>
<para>The reference GEMV implementation:</para>
<para><programlisting filename=".c"><codeline><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="sparse__format_8h_1ae9a2aad0ec5332237097030acf034961" kindref="member">ie_gemv_block_sparse_f32</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structie__block__sparse__matrix" kindref="compound">ie_block_sparse_matrix_t</ref><sp/>*m,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*x,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*y,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*bias);</highlight></codeline>
</programlisting></para>
<para>Design:</para>
<para><itemizedlist>
<listitem><para>Single‑threaded, straightforward loop structure:<itemizedlist>
<listitem><para>iterate over block rows (<computeroutput>br</computeroutput>);</para>
</listitem><listitem><para>for each local row in the block (<computeroutput>local_r</computeroutput>), compute the dense row index <computeroutput>row = br * block_rows + local_r</computeroutput>;</para>
</listitem><listitem><para>iterate over non‑zero blocks in that block row using <computeroutput>row_ptr[br]..row_ptr[br+1]</computeroutput>;</para>
</listitem><listitem><para>for each block, compute the starting column and take an inner product between the block row and the corresponding slice of <computeroutput>x</computeroutput>.</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Tail safety:<itemizedlist>
<listitem><para>rows with <computeroutput>row &gt;= rows</computeroutput> are skipped;</para>
</listitem><listitem><para>columns with <computeroutput>col &gt;= cols</computeroutput> are skipped inside the innermost loop.</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Bias:<itemizedlist>
<listitem><para><computeroutput>bias == NULL</computeroutput> is allowed; in that case the accumulator starts at <computeroutput>0.0f</computeroutput>;</para>
</listitem><listitem><para>otherwise we seed <computeroutput>acc</computeroutput> with <computeroutput>bias[row]</computeroutput>.</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>
<para>This function is small and easy to inspect, prioritizing correctness and debuggability over clever micro‑optimizations. Higher‑level code can decide whether and how to shard block rows across threads.</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md68">
<title>Device abstraction (&lt;tt&gt;engine/src/devices/ie_device_common.c&lt;/tt&gt;)</title>
<para>The <computeroutput><ref refid="structie__device" kindref="compound">ie_device</ref></computeroutput> vtable gains a new entry:</para>
<para><programlisting filename=".c"><codeline><highlight class="normal">int<sp/><sp/>(*gemv_block_sparse_f32)(</highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>*</highlight><highlight class="keyword">self</highlight><highlight class="normal">,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structie__block__sparse__matrix" kindref="compound">ie_block_sparse_matrix_t</ref><sp/>*m,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*x,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*y,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*bias);</highlight></codeline>
</programlisting></para>
<para>Backend implementations:</para>
<para><itemizedlist>
<listitem><para><bold>CPU:</bold><itemizedlist>
<listitem><para><computeroutput>cpu_gemv_block_sparse_f32</computeroutput> simply forwards to <computeroutput>ie_gemv_block_sparse_f32</computeroutput>.</para>
</listitem><listitem><para><computeroutput>ie_device_gemv_block_sparse_f32</computeroutput> (public helper) routes through the vtable and, on failure, can fall back to a CPU device if the current device is not already CPU.</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para><bold>CUDA / Level Zero:</bold><itemizedlist>
<listitem><para>for this phase they return an “unimplemented” error code;</para>
</listitem><listitem><para>callers that use <computeroutput>ie_device_gemv_block_sparse_f32</computeroutput> will see the error and can choose to fall back to CPU.</para>
</listitem><listitem><para>No GPU kernels are required for tests to pass.</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>
<para>This layout keeps the public API stable while allowing future ADRs to add true GPU implementations under the same method.</para>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md69">
<title>Tools and tests</title>
<sect3 id="md_docs_DESIGN_1autotoc_md70">
<title>Offline converter (&lt;tt&gt;tools/convert_to_block_sparse.c&lt;/tt&gt;)</title>
<para>The converter takes a dense, row‑major FP32 matrix and produces the block‑sparse binary format:</para>
<para><itemizedlist>
<listitem><para>Inputs:<itemizedlist>
<listitem><para>path to a dense <computeroutput>.bin</computeroutput> (raw <computeroutput>float</computeroutput> array of shape <computeroutput>rows × cols</computeroutput>);</para>
</listitem><listitem><para><computeroutput>rows</computeroutput>, <computeroutput>cols</computeroutput>, <computeroutput>block_rows</computeroutput>, <computeroutput>block_cols</computeroutput>;</para>
</listitem><listitem><para>optional threshold / sparsification policy (for now, the prototype typically uses <emphasis>exact</emphasis> sparsity patterns produced upstream).</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Steps:<orderedlist>
<listitem><para>read dense matrix into memory;</para>
</listitem><listitem><para>scan it by blocks, classify non‑zero blocks;</para>
</listitem><listitem><para>build <computeroutput>row_ptr</computeroutput> / <computeroutput>col_idx</computeroutput>;</para>
</listitem><listitem><para>emit the header + payload to an output path.</para>
</listitem></orderedlist>
</para>
</listitem></itemizedlist>
</para>
<para>This keeps sparsification an explicit, offline step: the engine never modifies weights at load time.</para>
</sect3>
<sect3 id="md_docs_DESIGN_1autotoc_md71">
<title>C unit tests (&lt;tt&gt;tests/c/test_block_sparse.c&lt;/tt&gt;)</title>
<para>The tests validate both the loader and the GEMV kernel:</para>
<para><itemizedlist>
<listitem><para>Small 4×4 and 8×8 matrices with hand‑written dense values and known products.</para>
</listitem><listitem><para>Construction of the corresponding block‑sparse structures in memory, followed by calls to <computeroutput>ie_gemv_block_sparse_f32</computeroutput>.</para>
</listitem><listitem><para>Round‑trip tests for the on‑disk format: write block‑sparse payloads, load via <computeroutput>ie_block_sparse_load</computeroutput>, compare against the in‑memory structures, and re‑run GEMV.</para>
</listitem></itemizedlist>
</para>
<para>The test target is wired into <computeroutput>make test</computeroutput> alongside the existing C unit tests so regressions are caught early.</para>
</sect3>
<sect3 id="md_docs_DESIGN_1autotoc_md72">
<title>Microbenchmark (&lt;tt&gt;benchmarks/src/microbench_gemv_block_sparse.c&lt;/tt&gt;)</title>
<para>A dedicated microbenchmark compares dense vs block‑sparse GEMV on CPU:</para>
<para><itemizedlist>
<listitem><para>Synthesizes a dense matrix and a block‑sparse version with a chosen sparsity pattern.</para>
</listitem><listitem><para>Runs timed loops for both kernels and prints:<itemizedlist>
<listitem><para>runtime, ns/element, and effective GB/s;</para>
</listitem><listitem><para>any basic correctness statistics (e.g. max absolute difference).</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Built and run via <computeroutput>make microbench-block-sparse</computeroutput>.</para>
</listitem></itemizedlist>
</para>
<para>This is a <bold>local</bold> measurement tool; it does not depend on real model weights or the CLI.</para>
</sect3>
</sect2>
<sect2 id="md_docs_DESIGN_1autotoc_md73">
<title>Integration strategy and future work</title>
<para>This phase intentionally stops short of wiring block‑sparse weights into <computeroutput>model.ie.bin</computeroutput> and the inference CLI:</para>
<para><itemizedlist>
<listitem><para>existing users see no change in behavior;</para>
</listitem><listitem><para>sparsity experiments use their own binaries and scripts; and</para>
</listitem><listitem><para>the code paths remain small enough to refactor without churn.</para>
</listitem></itemizedlist>
</para>
<para>Follow‑up work (future ADRs) may cover:</para>
<para><itemizedlist>
<listitem><para>extending the IEBIN format (or adding a sidecar) to carry block‑sparse weights for specific layers;</para>
</listitem><listitem><para>heuristics for which layers to sparsify (e.g. MLP vs attention);</para>
</listitem><listitem><para>GPU kernels for popular architectures; and</para>
</listitem><listitem><para>interaction with quantization and activation formats.</para>
</listitem></itemizedlist>
</para>
<para>For now, the block‑sparse prototype gives us a solid, CPU‑only baseline to reason about algorithmic sparsity independently of lower‑level memory and topology tricks introduced in the first phase. </para>
</sect2>
</sect1>
    </detaileddescription>
    <location file="docs/DESIGN.md"/>
  </compounddef>
</doxygen>
