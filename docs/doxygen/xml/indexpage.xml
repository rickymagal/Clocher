<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.13.2" xml:lang="en-US">
  <compounddef id="indexpage" kind="page">
    <compoundname>index</compoundname>
    <title>Inference Engine (Clocher)</title>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para><anchor id="index_1md_README"/></para>
<para><emphasis>A minimal C11 inference baseline with strict metrics &amp; a Python harness.</emphasis> <linebreak/>
 <bold>Last updated:</bold> 2025-10-24 21:00:48 UTC</para>
<para><hruler/>
</para>
<sect1 id="index_1autotoc_md49">
<title>Quick start</title><para><programlisting filename=".bash"><codeline><highlight class="normal">#<sp/>Build<sp/>CPU<sp/>and<sp/>(optionally)<sp/>CUDA<sp/>binaries</highlight></codeline>
<codeline><highlight class="normal">make<sp/>build</highlight></codeline>
<codeline><highlight class="normal">make<sp/>build-cuda<sp/><sp/><sp/>#<sp/>requires<sp/>a<sp/>CUDA<sp/>toolchain;<sp/>produces<sp/>build/inference-engine.cuda</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">#<sp/>Sanity:<sp/>show<sp/>CLI</highlight></codeline>
<codeline><highlight class="normal">./build/inference-engine<sp/>--help</highlight></codeline>
</programlisting></para>
<sect2 id="index_1autotoc_md50">
<title>Model format (IEBIN v1)</title><para>The engine consumes a pair of files in the current working directory:</para>
<para><programlisting><codeline><highlight class="normal">model.ie.json<sp/><sp/><sp/>#<sp/>metadata<sp/>(tensor<sp/>names,<sp/>shapes,<sp/>dtypes,<sp/>scales)</highlight></codeline>
<codeline><highlight class="normal">model.ie.bin<sp/><sp/><sp/><sp/>#<sp/>raw,<sp/>mmap‑friendly<sp/>tensor<sp/>blob</highlight></codeline>
</programlisting></para>
<para>You can pack from a Hugging Face checkpoint using the helper script below.</para>
<para><hruler/>
</para>
</sect2>
</sect1>
<sect1 id="index_1autotoc_md52">
<title>NEW: INT4 <bold>weight‑only</bold> PTQ path (Q4)</title><para>This repository now includes a <bold>4‑bit (INT4) weight‑only</bold> path that trades a small accuracy budget for <bold>4× smaller weights</bold> and a substantial <bold>memory‑bandwidth reduction</bold>. It is designed to be drop‑in with the existing build and harness.</para>
<sect2 id="index_1autotoc_md53">
<title>Pipeline overview</title><para>1) <bold>Prepare/locate a HF model</bold> (already sharded is fine):</para>
<para><programlisting><codeline><highlight class="normal">models/gpt-oss-20b/hf/</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>├──<sp/>config.json</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>├──<sp/>tokenizer.json<sp/>/<sp/>vocab.json<sp/>/<sp/>merges.txt</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>└──<sp/>pytorch_model-00001-of-00046.bin<sp/>…<sp/>pytorch_model-00046-of-00046.bin</highlight></codeline>
</programlisting></para>
<para>2) <bold>(Calibrate) produce the INT4 manifest</bold> <linebreak/>
 Use one of the PTQ helper scripts to create a manifest describing which tensors are quantized to 4‑bit and their per‑row/per‑tensor scales:</para>
<para><programlisting filename=".bash"><codeline><highlight class="normal">#<sp/>Choose<sp/>one<sp/>depending<sp/>on<sp/>your<sp/>source<sp/>of<sp/>truth<sp/>and<sp/>available<sp/>samples.</highlight></codeline>
<codeline><highlight class="normal">#<sp/>See:<sp/>python3<sp/>scripts/ptq_from_hf.py<sp/>--help</highlight></codeline>
<codeline><highlight class="normal">#<sp/><sp/><sp/><sp/><sp/><sp/>python3<sp/>scripts/ptq_from_bin.py<sp/>--help</highlight></codeline>
<codeline><highlight class="normal">#<sp/><sp/><sp/><sp/><sp/><sp/>python3<sp/>scripts/ptq_from_source.py<sp/>--help</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">python3<sp/>scripts/ptq_from_hf.py<sp/><sp/><sp/>--hf-dir<sp/>models/gpt-oss-20b/hf<sp/><sp/><sp/>--out<sp/>quant/q4_manifest.json<sp/><sp/><sp/>--bits<sp/>4<sp/>--weights-only<sp/>1</highlight></codeline>
</programlisting></para>
<para>Notes:<itemizedlist>
<listitem><para>The manifest (JSON) maps tensor names to <bold>INT4 packing + scale params</bold>.</para>
</listitem><listitem><para>Calib options (group size, symmetric/affine, clamp, percentile) are exposed by the script; pick values that satisfy your accuracy budget.</para>
</listitem></itemizedlist>
</para>
<para>3) <bold>Pack Hugging Face → IEBIN (with INT4)</bold></para>
<para><programlisting filename=".bash"><codeline><highlight class="normal">python3<sp/>scripts/hf_to_iebin.py<sp/><sp/><sp/>--hf-dir<sp/>models/gpt-oss-20b/hf<sp/><sp/><sp/>--out-dir<sp/>models/gpt-oss-20b<sp/><sp/><sp/>--q4-map<sp/>quant/q4_manifest.json</highlight></codeline>
</programlisting></para>
<para>This writes <computeroutput>model.ie.json</computeroutput> and <computeroutput>model.ie.bin</computeroutput> in <computeroutput>models/gpt-oss-20b/</computeroutput> (or as configured).</para>
<para>4) <bold>Run the benchmark (CPU or CUDA) with INT4 weights</bold></para>
<para>The engine selects kernels by <bold>precision</bold>. For INT4 <bold>weight‑only</bold>, use <computeroutput>int4w</computeroutput>.</para>
<para><blockquote><para><bold>64 MB per token</bold> = <computeroutput>IE_BYTES_PER_TOKEN=64000000</computeroutput> (decimal bytes). </para>
</blockquote></para>
<para><bold>CPU:</bold></para>
<para><programlisting filename=".bash"><codeline><highlight class="normal">cd<sp/>models/gpt-oss-20b</highlight></codeline>
<codeline><highlight class="normal">PROMPTS=../../benchmarks/prompts_10..txt<sp/>IE_PRECISION=int4w<sp/>IE_REQUIRE_MODEL=1<sp/>IE_BYTES_PER_TOKEN=64000000<sp/>IE_STRIDE_BYTES=256<sp/>RUNS=3<sp/>make<sp/>-C<sp/>../..<sp/>bench</highlight></codeline>
</programlisting></para>
<para><bold>CUDA:</bold></para>
<para><programlisting filename=".bash"><codeline><highlight class="normal">cd<sp/>models/gpt-oss-20b</highlight></codeline>
<codeline><highlight class="normal">PROMPTS=../../benchmarks/prompts_10..txt<sp/>IE_PRECISION=int4w<sp/>IE_REQUIRE_MODEL=1<sp/>IE_BYTES_PER_TOKEN=64000000<sp/>IE_STRIDE_BYTES=256<sp/>RUNS=3<sp/>make<sp/>-C<sp/>../..<sp/>bench-cuda</highlight></codeline>
</programlisting></para>
<para>The CLI will emit a <bold>single JSON line</bold> per run, which the harness merges into <computeroutput><ref refid="PERFORMANCE_8md" kindref="compound">docs/PERFORMANCE.md</ref></computeroutput>.</para>
<para><hruler/>
</para>
</sect2>
</sect1>
<sect1 id="index_1autotoc_md55">
<title>Operational notes</title><para><itemizedlist>
<listitem><para>The <computeroutput>--device</computeroutput> flag is accepted by the CLI as a <bold>no‑op hint</bold> (selection is a build‑time concern). CPU: <computeroutput>build/inference-engine</computeroutput>, CUDA: <computeroutput>build/inference-engine.cuda</computeroutput>.</para>
</listitem><listitem><para><bold>Strict mode</bold>: set <computeroutput>IE_REQUIRE_MODEL=1</computeroutput> to require a valid <computeroutput>model.ie.json</computeroutput> + <computeroutput>model.ie.bin</computeroutput>. Otherwise the engine can operate in a deterministic <bold>stub</bold> mode for CI.</para>
</listitem><listitem><para><bold>Work‑touch</bold>: to emulate memory pressure, set <computeroutput>IE_BYTES_PER_TOKEN</computeroutput> (e.g. <computeroutput>64000000</computeroutput>) and <computeroutput>IE_STRIDE_BYTES</computeroutput> (e.g. <computeroutput>256</computeroutput>). The measured window includes generation <bold>and</bold> this per‑token touch over the mmap’d <computeroutput>model.ie.bin</computeroutput>.</para>
</listitem><listitem><para><bold>RSS reporting</bold>: the CLI samples peak RSS after the timed window (Linux: <computeroutput>/proc/self/status</computeroutput> <computeroutput>VmHWM</computeroutput>, fallback <computeroutput>getrusage</computeroutput>).</para>
</listitem></itemizedlist>
</para>
<para><hruler/>
</para>
</sect1>
<sect1 id="index_1autotoc_md57">
<title>Troubleshooting</title><para><itemizedlist>
<listitem><para><computeroutput>ERROR: --q4-map not found</computeroutput>: pass a real path to your manifest, e.g. <computeroutput>quant/q4_manifest.json</computeroutput>.</para>
</listitem><listitem><para><lsquo/>error: unknown flag <rsquo/><ndash/>model-dir&apos;<computeroutput>or</computeroutput>&apos;<ndash/>rounds&apos;<computeroutput>: you are using an older binary; rebuild with</computeroutput>make clean &amp;&amp; make build<computeroutput>. -</computeroutput>RSS peak = 0<computeroutput>: ensure the process reads enough memory while resident (set</computeroutput>IE_BYTES_PER_TOKEN<computeroutput>to a non‑zero value) and you are not running inside a constrained container namespace that suppresses</computeroutput>VmHWM<computeroutput>.</computeroutput></para>
</listitem><listitem><para><computeroutput>Prompts file not found:</computeroutput>PROMPTS=benchmarks/prompts_10..txt` (note the <bold>double dot</bold> in the demo file).</para>
</listitem></itemizedlist>
</para>
<para><hruler/>
</para>
</sect1>
<sect1 id="index_1autotoc_md59">
<title>What INT4 (weight‑only) means here</title><para><itemizedlist>
<listitem><para><bold>Activations</bold> remain floating‑point; only <bold>weights</bold> are nibble‑packed (2 weights per byte) with per‑row scales.</para>
</listitem><listitem><para>Dequantization is fused in the matmul kernels (see <computeroutput><ref refid="int4__ptq_8c" kindref="compound">engine/src/quant/int4_ptq.c</ref></computeroutput> and GPU equivalents). Pretranspose/blocked‑K packing are applied before/after quantization as configured.</para>
</listitem><listitem><para>Accuracy is safeguarded by a <bold>calibration gate</bold> (cosine similarity or task‑level eval), configurable in the PTQ scripts.</para>
</listitem></itemizedlist>
</para>
<para><hruler/>
</para>
</sect1>
<sect1 id="index_1autotoc_md61">
<title>See also</title><para><itemizedlist>
<listitem><para>Detailed design and optimization path: <computeroutput><ref refid="DESIGN_8md" kindref="compound">docs/DESIGN.md</ref></computeroutput>, <computeroutput><ref refid="adr-00060-optimization-path_8md" kindref="compound">docs/adr-00060-optimization-path.md</ref></computeroutput></para>
</listitem><listitem><para>Decision log: <computeroutput><ref refid="DECISIONS_8md" kindref="compound">docs/DECISIONS.md</ref></computeroutput> </para>
</listitem></itemizedlist>
</para>
</sect1>
    </detaileddescription>
    <location file="README.md"/>
  </compounddef>
</doxygen>
