<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.8" xml:lang="en-US">
  <compounddef id="mlp__cuda_8cu" kind="file" language="C++">
    <compoundname>mlp_cuda.cu</compoundname>
    <includes local="no">cuda_runtime.h</includes>
    <includes local="no">math.h</includes>
    <includes local="no">stddef.h</includes>
    <includes local="no">stdint.h</includes>
    <incdepgraph>
      <node id="1">
        <label>engine/src/kernels/mlp_cuda.cu</label>
        <link refid="mlp__cuda_8cu"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="5" relation="include">
        </childnode>
      </node>
      <node id="2">
        <label>cuda_runtime.h</label>
      </node>
      <node id="3">
        <label>math.h</label>
      </node>
      <node id="4">
        <label>stddef.h</label>
      </node>
      <node id="5">
        <label>stdint.h</label>
      </node>
    </incdepgraph>
    <sectiondef kind="func">
      <memberdef kind="function" id="mlp__cuda_8cu_1a48b01dec850b9e750b031fe61c470f34" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__device__ __forceinline__ float</type>
        <definition>static __device__ __forceinline__ float silu_f32</definition>
        <argsstring>(float x)</argsstring>
        <name>silu_f32</name>
        <param>
          <type>float</type>
          <declname>x</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/mlp_cuda.cu" line="26" column="41" bodyfile="engine/src/kernels/mlp_cuda.cu" bodystart="26" bodyend="28"/>
        <referencedby refid="mlp__cuda_8cu_1a19234e6093b69446e4c6851cb9ce0986" compoundref="mlp__cuda_8cu" startline="42" endline="46">ie_swiglu_fuse_kernel</referencedby>
      </memberdef>
      <memberdef kind="function" id="mlp__cuda_8cu_1ad6c334dff4c2fa555e1676bd05cd6da8" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__global__ void</type>
        <definition>__global__ void ie_matvec_f32_kernel</definition>
        <argsstring>(const float *W, const float *x, const float *bias, float *y, size_t rows, size_t cols)</argsstring>
        <name>ie_matvec_f32_kernel</name>
        <param>
          <type>const float *</type>
          <declname>W</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>x</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>bias</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>y</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>rows</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>cols</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/mlp_cuda.cu" line="30" column="17" bodyfile="engine/src/kernels/mlp_cuda.cu" bodystart="30" bodyend="40"/>
      </memberdef>
      <memberdef kind="function" id="mlp__cuda_8cu_1a19234e6093b69446e4c6851cb9ce0986" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>__global__ void</type>
        <definition>__global__ void ie_swiglu_fuse_kernel</definition>
        <argsstring>(const float *gate, const float *up, float *act, size_t n)</argsstring>
        <name>ie_swiglu_fuse_kernel</name>
        <param>
          <type>const float *</type>
          <declname>gate</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>up</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>act</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>n</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/mlp_cuda.cu" line="42" column="17" bodyfile="engine/src/kernels/mlp_cuda.cu" bodystart="42" bodyend="46"/>
        <references refid="mlp__cuda_8cu_1a48b01dec850b9e750b031fe61c470f34" compoundref="mlp__cuda_8cu" startline="26" endline="28">silu_f32</references>
      </memberdef>
      <memberdef kind="function" id="mlp__cuda_8cu_1abe7437e3cad585d46e89612af42b1fc2" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>int</type>
        <definition>int ie_mlp_cuda_swiglu_f32</definition>
        <argsstring>(const float *W_gate, const float *W_up, const float *W_down, const float *x, size_t in_dim, size_t hidden_dim, size_t out_dim, const float *b_gate, const float *b_up, const float *b_down, float *out, float *tmp_gate, float *tmp_up)</argsstring>
        <name>ie_mlp_cuda_swiglu_f32</name>
        <param>
          <type>const float *</type>
          <declname>W_gate</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>W_up</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>W_down</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>x</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>in_dim</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>hidden_dim</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>out_dim</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>b_gate</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>b_up</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>b_down</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>out</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>tmp_gate</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>tmp_up</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/src/kernels/mlp_cuda.cu" line="48" column="16" bodyfile="engine/src/kernels/mlp_cuda.cu" bodystart="48" bodyend="92"/>
      </memberdef>
    </sectiondef>
    <briefdescription>
<para>Reference CUDA MLP kernels (FP32). </para>
    </briefdescription>
    <detaileddescription>
<para>Implements a common &quot;SwiGLU&quot; MLP: gate = W_gate * x + b_gate up = W_up * x + b_up act = silu(gate) * up out = W_down * act + b_down</para>
<para>All matrices are row-major: W rows are contiguous, W[r, c] at W[r*cols + c].</para>
<para>This is correctness-first; caller supplies device buffers tmp_gate/tmp_up. </para>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="comment">/*<sp/>============================================================================</highlight></codeline>
<codeline lineno="2"><highlight class="comment"><sp/>*<sp/>File:<sp/>engine/src/kernels/mlp_cuda.cu</highlight></codeline>
<codeline lineno="3"><highlight class="comment"><sp/>*<sp/>============================================================================</highlight></codeline>
<codeline lineno="4"><highlight class="comment"><sp/>*/</highlight></codeline>
<codeline lineno="21"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;cuda_runtime.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;math.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="23"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stddef.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="24"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stdint.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="25"><highlight class="normal"></highlight></codeline>
<codeline lineno="26" refid="mlp__cuda_8cu_1a48b01dec850b9e750b031fe61c470f34" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>__device__<sp/>__forceinline__<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/><ref refid="mlp__cuda_8cu_1a48b01dec850b9e750b031fe61c470f34" kindref="member">silu_f32</ref>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>x)<sp/>{</highlight></codeline>
<codeline lineno="27"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>x<sp/>/<sp/>(1.0f<sp/>+<sp/>expf(-x));</highlight></codeline>
<codeline lineno="28"><highlight class="normal">}</highlight></codeline>
<codeline lineno="29"><highlight class="normal"></highlight></codeline>
<codeline lineno="30" refid="mlp__cuda_8cu_1ad6c334dff4c2fa555e1676bd05cd6da8" refkind="member"><highlight class="normal">__global__<sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="mlp__cuda_8cu_1ad6c334dff4c2fa555e1676bd05cd6da8" kindref="member">ie_matvec_f32_kernel</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*W,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*x,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*bias,</highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*y,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>rows,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>cols)<sp/>{</highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>r<sp/>=<sp/>(size_t)blockIdx.x<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)blockDim.x<sp/>+<sp/>(size_t)threadIdx.x;</highlight></codeline>
<codeline lineno="33"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(r<sp/>&gt;=<sp/>rows)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="34"><highlight class="normal"></highlight></codeline>
<codeline lineno="35"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*Wr<sp/>=<sp/>W<sp/>+<sp/>r<sp/>*<sp/>cols;</highlight></codeline>
<codeline lineno="36"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>acc<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="37"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>c<sp/>=<sp/>0;<sp/>c<sp/>&lt;<sp/>cols;<sp/>++c)<sp/>acc<sp/>+=<sp/>Wr[c]<sp/>*<sp/>x[c];</highlight></codeline>
<codeline lineno="38"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(bias)<sp/>acc<sp/>+=<sp/>bias[r];</highlight></codeline>
<codeline lineno="39"><highlight class="normal"><sp/><sp/>y[r]<sp/>=<sp/>acc;</highlight></codeline>
<codeline lineno="40"><highlight class="normal">}</highlight></codeline>
<codeline lineno="41"><highlight class="normal"></highlight></codeline>
<codeline lineno="42" refid="mlp__cuda_8cu_1a19234e6093b69446e4c6851cb9ce0986" refkind="member"><highlight class="normal">__global__<sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="mlp__cuda_8cu_1a19234e6093b69446e4c6851cb9ce0986" kindref="member">ie_swiglu_fuse_kernel</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*gate,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*up,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*act,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>n)<sp/>{</highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>(size_t)blockIdx.x<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)blockDim.x<sp/>+<sp/>(size_t)threadIdx.x;</highlight></codeline>
<codeline lineno="44"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(i<sp/>&gt;=<sp/>n)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/>act[i]<sp/>=<sp/><ref refid="mlp__cuda_8cu_1a48b01dec850b9e750b031fe61c470f34" kindref="member">silu_f32</ref>(gate[i])<sp/>*<sp/>up[i];</highlight></codeline>
<codeline lineno="46"><highlight class="normal">}</highlight></codeline>
<codeline lineno="47"><highlight class="normal"></highlight></codeline>
<codeline lineno="48" refid="mlp__cuda_8cu_1abe7437e3cad585d46e89612af42b1fc2" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">extern</highlight><highlight class="normal"><sp/></highlight><highlight class="stringliteral">&quot;C&quot;</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/><ref refid="mlp__cuda_8cu_1abe7437e3cad585d46e89612af42b1fc2" kindref="member">ie_mlp_cuda_swiglu_f32</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*W_gate,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*W_up,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*W_down,</highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*x,</highlight></codeline>
<codeline lineno="50"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>in_dim,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>hidden_dim,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>out_dim,</highlight></codeline>
<codeline lineno="51"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*b_gate,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*b_up,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*b_down,</highlight></codeline>
<codeline lineno="52"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out,</highlight></codeline>
<codeline lineno="53"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*tmp_gate,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*tmp_up)<sp/>{</highlight></codeline>
<codeline lineno="54"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!W_gate<sp/>||<sp/>!W_up<sp/>||<sp/>!W_down<sp/>||<sp/>!x<sp/>||<sp/>!out<sp/>||<sp/>!tmp_gate<sp/>||<sp/>!tmp_up)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-1;</highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(in_dim<sp/>==<sp/>0<sp/>||<sp/>hidden_dim<sp/>==<sp/>0<sp/>||<sp/>out_dim<sp/>==<sp/>0)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-1;</highlight></codeline>
<codeline lineno="56"><highlight class="normal"></highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>threads<sp/>=<sp/>256;</highlight></codeline>
<codeline lineno="58"><highlight class="normal"></highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/>{</highlight></codeline>
<codeline lineno="60"><highlight class="normal"><sp/><sp/><sp/><sp/>dim3<sp/>grid((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)((hidden_dim<sp/>+<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threads<sp/>-<sp/>1u)<sp/>/<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threads),<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/><sp/><sp/>dim3<sp/>block((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)threads,<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/>ie_matvec_f32_kernel&lt;&lt;&lt;grid,<sp/>block,<sp/>0,<sp/>0&gt;&gt;&gt;(W_gate,<sp/>x,<sp/>b_gate,<sp/>tmp_gate,<sp/>hidden_dim,<sp/>in_dim);</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/><sp/><sp/>cudaError_t<sp/>e<sp/>=<sp/>cudaGetLastError();</highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(e<sp/>!=<sp/>cudaSuccess)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-2;</highlight></codeline>
<codeline lineno="65"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="66"><highlight class="normal"></highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/>{</highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/><sp/><sp/>dim3<sp/>grid((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)((hidden_dim<sp/>+<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threads<sp/>-<sp/>1u)<sp/>/<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threads),<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/>dim3<sp/>block((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)threads,<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/><sp/><sp/>ie_matvec_f32_kernel&lt;&lt;&lt;grid,<sp/>block,<sp/>0,<sp/>0&gt;&gt;&gt;(W_up,<sp/>x,<sp/>b_up,<sp/>tmp_up,<sp/>hidden_dim,<sp/>in_dim);</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/><sp/><sp/>cudaError_t<sp/>e<sp/>=<sp/>cudaGetLastError();</highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(e<sp/>!=<sp/>cudaSuccess)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-3;</highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="74"><highlight class="normal"></highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/>{</highlight></codeline>
<codeline lineno="76"><highlight class="normal"><sp/><sp/><sp/><sp/>dim3<sp/>grid((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)((hidden_dim<sp/>+<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threads<sp/>-<sp/>1u)<sp/>/<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threads),<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="77"><highlight class="normal"><sp/><sp/><sp/><sp/>dim3<sp/>block((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)threads,<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/><sp/><sp/>ie_swiglu_fuse_kernel&lt;&lt;&lt;grid,<sp/>block,<sp/>0,<sp/>0&gt;&gt;&gt;(tmp_gate,<sp/>tmp_up,<sp/>tmp_gate,<sp/>hidden_dim);</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/>cudaError_t<sp/>e<sp/>=<sp/>cudaGetLastError();</highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(e<sp/>!=<sp/>cudaSuccess)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-4;</highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="82"><highlight class="normal"></highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/>{</highlight></codeline>
<codeline lineno="84"><highlight class="normal"><sp/><sp/><sp/><sp/>dim3<sp/>grid((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)((out_dim<sp/>+<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threads<sp/>-<sp/>1u)<sp/>/<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)threads),<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="85"><highlight class="normal"><sp/><sp/><sp/><sp/>dim3<sp/>block((</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)threads,<sp/>1u,<sp/>1u);</highlight></codeline>
<codeline lineno="86"><highlight class="normal"><sp/><sp/><sp/><sp/>ie_matvec_f32_kernel&lt;&lt;&lt;grid,<sp/>block,<sp/>0,<sp/>0&gt;&gt;&gt;(W_down,<sp/>tmp_gate,<sp/>b_down,<sp/>out,<sp/>out_dim,<sp/>hidden_dim);</highlight></codeline>
<codeline lineno="87"><highlight class="normal"><sp/><sp/><sp/><sp/>cudaError_t<sp/>e<sp/>=<sp/>cudaGetLastError();</highlight></codeline>
<codeline lineno="88"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(e<sp/>!=<sp/>cudaSuccess)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>-5;</highlight></codeline>
<codeline lineno="89"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="90"><highlight class="normal"></highlight></codeline>
<codeline lineno="91"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>0;</highlight></codeline>
<codeline lineno="92"><highlight class="normal">}</highlight></codeline>
    </programlisting>
    <location file="engine/src/kernels/mlp_cuda.cu"/>
  </compounddef>
</doxygen>
