<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.8" xml:lang="en-US">
  <compounddef id="tokenizer__hf_8h" kind="file" language="C++">
    <compoundname>tokenizer_hf.h</compoundname>
    <includes local="no">stddef.h</includes>
    <includes local="no">stdint.h</includes>
    <includedby refid="tokenizer__hf_8c" local="yes">engine/src/io/tokenizer_hf.c</includedby>
    <incdepgraph>
      <node id="1">
        <label>engine/include/tokenizer_hf.h</label>
        <link refid="tokenizer__hf_8h"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="3" relation="include">
        </childnode>
      </node>
      <node id="2">
        <label>stddef.h</label>
      </node>
      <node id="3">
        <label>stdint.h</label>
      </node>
    </incdepgraph>
    <invincdepgraph>
      <node id="1">
        <label>engine/include/tokenizer_hf.h</label>
        <link refid="tokenizer__hf_8h"/>
        <childnode refid="2" relation="include">
        </childnode>
      </node>
      <node id="2">
        <label>engine/src/io/tokenizer_hf.c</label>
        <link refid="tokenizer__hf_8c"/>
      </node>
    </invincdepgraph>
    <innerclass refid="structtokenizer__hf__s" prot="public">tokenizer_hf_s</innerclass>
    <sectiondef kind="typedef">
      <memberdef kind="typedef" id="tokenizer__hf_8h_1a45c6bd2320bc99112e69f0d3029a56a9" prot="public" static="no">
        <type>struct <ref refid="structtokenizer__hf__s" kindref="compound">tokenizer_hf_s</ref></type>
        <definition>typedef struct tokenizer_hf_s tokenizer_hf_t</definition>
        <argsstring></argsstring>
        <name>tokenizer_hf_t</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/include/tokenizer_hf.h" line="30" column="16"/>
      </memberdef>
    </sectiondef>
    <sectiondef kind="func">
      <memberdef kind="function" id="tokenizer__hf_8h_1a6c73528277d1bd3dde69bf18932b636e" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>int</type>
        <definition>int tokenizer_hf_load</definition>
        <argsstring>(const char *path, tokenizer_hf_t *out)</argsstring>
        <name>tokenizer_hf_load</name>
        <param>
          <type>const char *</type>
          <declname>path</declname>
        </param>
        <param>
          <type><ref refid="tokenizer__hf_8h_1a45c6bd2320bc99112e69f0d3029a56a9" kindref="member">tokenizer_hf_t</ref> *</type>
          <declname>out</declname>
        </param>
        <briefdescription>
<para>Load tokenizer.json from disk. </para>
        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>path</parametername>
</parameternamelist>
<parameterdescription>
<para>Path to HuggingFace tokenizer.json </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>out</parametername>
</parameternamelist>
<parameterdescription>
<para>Tokenizer object to initialize </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>0 on success, non-zero on failure </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/include/tokenizer_hf.h" line="43" column="5" bodyfile="engine/src/io/tokenizer_hf.c" bodystart="155" bodyend="223" declfile="engine/include/tokenizer_hf.h" declline="43" declcolumn="5"/>
        <references refid="tokenizer__hf_8c_1a74c06de0233a28981c20d6e6959ffaf0" compoundref="tokenizer__hf_8c" startline="111" endline="139">build_gpt2_byte_decoder</references>
        <references refid="tokenizer__hf_8c_1a3dae92b1c084251e956a5773e53869b5" compoundref="tokenizer__hf_8c" startline="46" endline="86">parse_string</references>
        <references refid="tokenizer__hf_8c_1a4c2d349d9c8ef75000fe0db29269c538" compoundref="tokenizer__hf_8c" startline="88" endline="98">parse_u32</references>
        <references refid="tokenizer__hf_8c_1aa86f66b905282039d676a528db4eabb2" compoundref="tokenizer__hf_8c" startline="21" endline="40">read_file</references>
        <references refid="tokenizer__hf_8c_1ae19e0ad12742fe7fdff22f60436aadc7" compoundref="tokenizer__hf_8c" startline="16" endline="19">skip_ws</references>
      </memberdef>
      <memberdef kind="function" id="tokenizer__hf_8h_1a098c566b08c52a4ae083cbe19d553740" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void tokenizer_hf_free</definition>
        <argsstring>(tokenizer_hf_t *tok)</argsstring>
        <name>tokenizer_hf_free</name>
        <param>
          <type><ref refid="tokenizer__hf_8h_1a45c6bd2320bc99112e69f0d3029a56a9" kindref="member">tokenizer_hf_t</ref> *</type>
          <declname>tok</declname>
        </param>
        <briefdescription>
<para>Free tokenizer resources. </para>
        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>tok</parametername>
</parameternamelist>
<parameterdescription>
<para>Tokenizer object </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/include/tokenizer_hf.h" line="50" column="6" bodyfile="engine/src/io/tokenizer_hf.c" bodystart="225" bodyend="231" declfile="engine/include/tokenizer_hf.h" declline="50" declcolumn="6"/>
        <references refid="structtokenizer__hf__s_1a8cdc2a2fd11f2438974bef850cd75632" compoundref="tokenizer__hf_8h" startline="27">tokenizer_hf_s::id_to_token</references>
        <references refid="structtokenizer__hf__s_1a0282656f7ae00e33acd7745946083488" compoundref="tokenizer__hf_8h" startline="28">tokenizer_hf_s::vocab_size</references>
      </memberdef>
      <memberdef kind="function" id="tokenizer__hf_8h_1aa050c5c35be7c2273401f27a810eb93e" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>int</type>
        <definition>int tokenizer_hf_decode</definition>
        <argsstring>(const tokenizer_hf_t *tok, const int *ids, size_t n_ids, char *out, size_t out_sz)</argsstring>
        <name>tokenizer_hf_decode</name>
        <param>
          <type>const <ref refid="tokenizer__hf_8h_1a45c6bd2320bc99112e69f0d3029a56a9" kindref="member">tokenizer_hf_t</ref> *</type>
          <declname>tok</declname>
        </param>
        <param>
          <type>const int *</type>
          <declname>ids</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>n_ids</declname>
        </param>
        <param>
          <type>char *</type>
          <declname>out</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>out_sz</declname>
        </param>
        <briefdescription>
<para>Decode token IDs into UTF-8 text. </para>
        </briefdescription>
        <detaileddescription>
<para>Uses GPT-2 byte-level decoding.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>tok</parametername>
</parameternamelist>
<parameterdescription>
<para>Loaded tokenizer </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>ids</parametername>
</parameternamelist>
<parameterdescription>
<para>Token ID array </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>n_ids</parametername>
</parameternamelist>
<parameterdescription>
<para>Number of token IDs </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>out</parametername>
</parameternamelist>
<parameterdescription>
<para>Output buffer </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>out_sz</parametername>
</parameternamelist>
<parameterdescription>
<para>Output buffer capacity </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>0 on success, non-zero on failure </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="engine/include/tokenizer_hf.h" line="68" column="5" bodyfile="engine/src/io/tokenizer_hf.c" bodystart="233" bodyend="263" declfile="engine/include/tokenizer_hf.h" declline="68" declcolumn="5"/>
        <references refid="tokenizer__hf_8c_1a1e5281873f71ec2b33183af656ccf197" compoundref="tokenizer__hf_8c" startline="141" endline="149">gpt2_cp_to_byte</references>
        <references refid="structtokenizer__hf__s_1a8cdc2a2fd11f2438974bef850cd75632" compoundref="tokenizer__hf_8h" startline="27">tokenizer_hf_s::id_to_token</references>
        <references refid="structtokenizer__hf__s_1a9dd42472c2e0669be9e9d4c893e63453" compoundref="tokenizer__hf_8h" startline="29">tokenizer_hf_s::loaded</references>
        <references refid="structtokenizer__hf__s_1a0282656f7ae00e33acd7745946083488" compoundref="tokenizer__hf_8h" startline="28">tokenizer_hf_s::vocab_size</references>
      </memberdef>
    </sectiondef>
    <briefdescription>
<para>HuggingFace GPT-style tokenizer (decode-focused). </para>
    </briefdescription>
    <detaileddescription>
<para>This module loads a HuggingFace <computeroutput>tokenizer.json</computeroutput> file and supports decoding token IDs into real UTF-8 text using the GPT-2 byte decoder.</para>
<para>Encoding is optional and intentionally omitted here; this is meant to unblock REAL TEXT GENERATION from model token outputs. </para>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="preprocessor">#ifndef<sp/>TOKENIZER_HF_H_</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="preprocessor">#define<sp/>TOKENIZER_HF_H_</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="preprocessor">#ifdef<sp/>__cplusplus</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight><highlight class="keyword">extern</highlight><highlight class="normal"><sp/></highlight><highlight class="stringliteral">&quot;C&quot;</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stddef.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stdint.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>-------------------------------------------------------------------------<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="23"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>Tokenizer<sp/>handle<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="24"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>-------------------------------------------------------------------------<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="25"><highlight class="normal"></highlight></codeline>
<codeline lineno="26" refid="structtokenizer__hf__s" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">typedef</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal"><ref refid="structtokenizer__hf__s" kindref="compound">tokenizer_hf_s</ref><sp/>{</highlight></codeline>
<codeline lineno="27" refid="structtokenizer__hf__s_1a8cdc2a2fd11f2438974bef850cd75632" refkind="member"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">char</highlight><highlight class="normal"><sp/><sp/><sp/>**<ref refid="structtokenizer__hf__s_1a8cdc2a2fd11f2438974bef850cd75632" kindref="member">id_to_token</ref>;<sp/><sp/><sp/></highlight><highlight class="comment">/*<sp/>token_id<sp/>-&gt;<sp/>UTF-8<sp/>token<sp/>string<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="28" refid="structtokenizer__hf__s_1a0282656f7ae00e33acd7745946083488" refkind="member"><highlight class="normal"><sp/><sp/>uint32_t<sp/><ref refid="structtokenizer__hf__s_1a0282656f7ae00e33acd7745946083488" kindref="member">vocab_size</ref>;</highlight></codeline>
<codeline lineno="29" refid="structtokenizer__hf__s_1a9dd42472c2e0669be9e9d4c893e63453" refkind="member"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/><ref refid="structtokenizer__hf__s_1a9dd42472c2e0669be9e9d4c893e63453" kindref="member">loaded</ref>;</highlight></codeline>
<codeline lineno="30" refid="tokenizer__hf_8h_1a45c6bd2320bc99112e69f0d3029a56a9" refkind="member"><highlight class="normal">}<sp/><ref refid="tokenizer__hf_8h_1a45c6bd2320bc99112e69f0d3029a56a9" kindref="member">tokenizer_hf_t</ref>;</highlight></codeline>
<codeline lineno="31"><highlight class="normal"></highlight></codeline>
<codeline lineno="32"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>-------------------------------------------------------------------------<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="33"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>Lifecycle<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="34"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>-------------------------------------------------------------------------<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="35"><highlight class="normal"></highlight></codeline>
<codeline lineno="43"><highlight class="normal"></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/><ref refid="tokenizer__hf_8h_1a6c73528277d1bd3dde69bf18932b636e" kindref="member">tokenizer_hf_load</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">char</highlight><highlight class="normal"><sp/>*path,<sp/><ref refid="structtokenizer__hf__s" kindref="compound">tokenizer_hf_t</ref><sp/>*out);</highlight></codeline>
<codeline lineno="44"><highlight class="normal"></highlight></codeline>
<codeline lineno="50"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="tokenizer__hf_8h_1a098c566b08c52a4ae083cbe19d553740" kindref="member">tokenizer_hf_free</ref>(<ref refid="structtokenizer__hf__s" kindref="compound">tokenizer_hf_t</ref><sp/>*tok);</highlight></codeline>
<codeline lineno="51"><highlight class="normal"></highlight></codeline>
<codeline lineno="52"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>-------------------------------------------------------------------------<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="53"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>Decode<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="54"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>-------------------------------------------------------------------------<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="55"><highlight class="normal"></highlight></codeline>
<codeline lineno="68"><highlight class="normal"></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/><ref refid="tokenizer__hf_8h_1aa050c5c35be7c2273401f27a810eb93e" kindref="member">tokenizer_hf_decode</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structtokenizer__hf__s" kindref="compound">tokenizer_hf_t</ref><sp/>*tok,</highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>*ids,</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>n_ids,</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">char</highlight><highlight class="normal"><sp/>*out,</highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>out_sz);</highlight></codeline>
<codeline lineno="73"><highlight class="normal"></highlight></codeline>
<codeline lineno="74"><highlight class="normal"></highlight><highlight class="preprocessor">#ifdef<sp/>__cplusplus</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="75"><highlight class="normal">}</highlight></codeline>
<codeline lineno="76"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="77"><highlight class="normal"></highlight></codeline>
<codeline lineno="78"><highlight class="normal"></highlight><highlight class="preprocessor">#endif<sp/></highlight><highlight class="comment">/*<sp/>TOKENIZER_HF_H_<sp/>*/</highlight><highlight class="preprocessor"></highlight></codeline>
    </programlisting>
    <location file="engine/include/tokenizer_hf.h"/>
  </compounddef>
</doxygen>
